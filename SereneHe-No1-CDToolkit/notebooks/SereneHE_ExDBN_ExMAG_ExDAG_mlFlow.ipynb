{"cells":[{"cell_type":"markdown","metadata":{"id":"SDLZmdluZsAT"},"source":["# Ready To Start"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","os.chdir(\"/content/drive/My Drive/Colab Notebooks/Causality/cliquewidth/ExDAG-ExDBN-ExMAG/Pavel-GitLab/\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sblG0yYPsrck","executionInfo":{"status":"ok","timestamp":1748516412757,"user_tz":-60,"elapsed":23313,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"}},"outputId":"48bad39b-b3d0-4bb2-c359-414c89106eef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!apt-get update\n","!apt-get install -y graphviz libgraphviz-dev\n","\n","!pip install numpy==1.23.5 scipy==1.10.1\n","!pip install pygraphviz\n","!pip install pygobnilp\n","!pip install lingam bnlearn gurobipy==10.0.0 networkx omegaconf scikit-learn sympy igraph matplotlib pgmpy cplex\n","# !pip install hydra-core hydra-joblib-launcher mlflow\n","# !pip install cplex\n","\n","import igraph\n","import gurobipy as gp\n","\n","!export PYTHONPATH=\"$PYTHONPATH:/content/drive/MyDrive/Colab Notebooks/NCPOP-Colab Notebooks-data\"\n","import os\n","os.environ['GRB_LICENSE_FILE'] = '/content/drive/MyDrive/gurobi.lic'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8knGFUe5jFQ9","executionInfo":{"status":"ok","timestamp":1747154598610,"user_tz":-120,"elapsed":84131,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"}},"outputId":"f6295f4f-00cb-48cf-9481-442ddcea9ea4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n","Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Hit:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n","Hit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Hit:6 http://security.ubuntu.com/ubuntu jammy-security InRelease\n","Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n","Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","graphviz is already the newest version (2.42.2-6ubuntu0.1).\n","libgraphviz-dev is already the newest version (2.42.2-6ubuntu0.1).\n","0 upgraded, 0 newly installed, 0 to remove and 36 not upgraded.\n","Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.11/dist-packages (1.23.5)\n","Collecting scipy==1.10.1\n","  Using cached scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n","Using cached scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.1 MB)\n","Installing collected packages: scipy\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.11.4\n","    Uninstalling scipy-1.11.4:\n","      Successfully uninstalled scipy-1.11.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","pygam 0.9.1 requires numpy>=1.25; python_version >= \"3.9\" and python_version < \"3.13\", but you have numpy 1.23.5 which is incompatible.\n","pygam 0.9.1 requires scipy<1.12,>=1.11.1; python_version >= \"3.9\" and python_version < \"3.13\", but you have scipy 1.10.1 which is incompatible.\n","bnlearn 0.11.1 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n","scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n","scikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.10.1 which is incompatible.\n","imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n","pymc 5.22.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n","cvxpy 1.6.5 requires scipy>=1.11.0, but you have scipy 1.10.1 which is incompatible.\n","jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n","jaxlib 0.5.1 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\n","albumentations 2.0.6 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n","tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.10.1 which is incompatible.\n","jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n","jax 0.5.2 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed scipy-1.10.1\n","Requirement already satisfied: pygraphviz in /usr/local/lib/python3.11/dist-packages (1.14)\n","Requirement already satisfied: pygobnilp in /usr/local/lib/python3.11/dist-packages (1.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pygobnilp) (1.10.1)\n","Requirement already satisfied: pygraphviz in /usr/local/lib/python3.11/dist-packages (from pygobnilp) (1.14)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from pygobnilp) (3.10.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pygobnilp) (3.4.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from pygobnilp) (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pygobnilp) (1.23.5)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from pygobnilp) (1.6.1)\n","Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from pygobnilp) (0.60.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygobnilp) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygobnilp) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygobnilp) (4.57.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygobnilp) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygobnilp) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygobnilp) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygobnilp) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygobnilp) (2.9.0.post0)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->pygobnilp) (0.43.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->pygobnilp) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->pygobnilp) (2025.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pygobnilp) (1.5.0)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pygobnilp) (3.6.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->pygobnilp) (1.17.0)\n","Requirement already satisfied: lingam in /usr/local/lib/python3.11/dist-packages (1.9.1)\n","Requirement already satisfied: bnlearn in /usr/local/lib/python3.11/dist-packages (0.11.1)\n","Requirement already satisfied: gurobipy==10.0.0 in /usr/local/lib/python3.11/dist-packages (10.0.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.4.2)\n","Requirement already satisfied: omegaconf in /usr/local/lib/python3.11/dist-packages (2.3.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n","Requirement already satisfied: igraph in /usr/local/lib/python3.11/dist-packages (0.11.8)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Requirement already satisfied: pgmpy in /usr/local/lib/python3.11/dist-packages (0.1.25)\n","Requirement already satisfied: cplex in /usr/local/lib/python3.11/dist-packages (22.1.2.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from lingam) (1.23.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lingam) (1.10.1)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from lingam) (0.20.3)\n","Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from lingam) (0.14.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from lingam) (2.2.2)\n","Requirement already satisfied: pygam in /usr/local/lib/python3.11/dist-packages (from lingam) (0.9.1)\n","Requirement already satisfied: psy in /usr/local/lib/python3.11/dist-packages (from lingam) (0.0.1)\n","Requirement already satisfied: semopy in /usr/local/lib/python3.11/dist-packages (from lingam) (2.3.11)\n","Collecting numpy (from lingam)\n","  Using cached numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from bnlearn) (4.67.1)\n","Requirement already satisfied: ismember in /usr/local/lib/python3.11/dist-packages (from bnlearn) (1.0.6)\n","Requirement already satisfied: funcsigs in /usr/local/lib/python3.11/dist-packages (from bnlearn) (1.0.2)\n","Requirement already satisfied: python-louvain in /usr/local/lib/python3.11/dist-packages (from bnlearn) (0.16)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from bnlearn) (24.2)\n","Requirement already satisfied: df2onehot in /usr/local/lib/python3.11/dist-packages (from bnlearn) (1.0.8)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from bnlearn) (2025.3.2)\n","Requirement already satisfied: pypickle in /usr/local/lib/python3.11/dist-packages (from bnlearn) (1.1.5)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from bnlearn) (0.9.0)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from bnlearn) (7.7.1)\n","Requirement already satisfied: datazets>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from bnlearn) (1.1.2)\n","Requirement already satisfied: setgraphviz>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from bnlearn) (1.0.2)\n","Requirement already satisfied: pyarrow<20.0.0 in /usr/local/lib/python3.11/dist-packages (from bnlearn) (18.1.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from pgmpy) (3.2.3)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from pgmpy) (2.6.0+cu124)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from pgmpy) (1.5.0)\n","Requirement already satisfied: opt-einsum in /usr/local/lib/python3.11/dist-packages (from pgmpy) (3.4.0)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf) (4.9.3)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf) (6.0.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy) (1.3.0)\n","Requirement already satisfied: texttable>=1.6.2 in /usr/local/lib/python3.11/dist-packages (from igraph) (1.7.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from datazets>=1.1.2->bnlearn) (2.32.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n","  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->bnlearn) (6.17.1)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->bnlearn) (0.2.0)\n","Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->bnlearn) (5.7.1)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->bnlearn) (3.6.10)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->bnlearn) (7.34.0)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->bnlearn) (3.0.15)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->lingam) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->lingam) (2025.2)\n","Requirement already satisfied: progressbar2 in /usr/local/lib/python3.11/dist-packages (from psy->lingam) (4.5.0)\n","Collecting scipy (from lingam)\n","  Using cached scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","Requirement already satisfied: numdifftools in /usr/local/lib/python3.11/dist-packages (from semopy->lingam) (0.9.41)\n","Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->lingam) (1.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (4.13.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (3.2.0)\n","Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->bnlearn) (1.8.0)\n","Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->bnlearn) (6.1.12)\n","Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->bnlearn) (0.1.7)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->bnlearn) (1.6.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->bnlearn) (5.9.5)\n","Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->bnlearn) (24.0.1)\n","Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->bnlearn) (6.4.2)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->bnlearn) (75.2.0)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->bnlearn) (0.19.2)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->bnlearn) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->bnlearn) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->bnlearn) (3.0.51)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->bnlearn) (2.19.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->bnlearn) (0.2.0)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->bnlearn) (4.9.0)\n","Requirement already satisfied: python-utils>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from progressbar2->psy->lingam) (3.9.1)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->bnlearn) (6.5.7)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->pgmpy) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->datazets>=1.1.2->bnlearn) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->datazets>=1.1.2->bnlearn) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->datazets>=1.1.2->bnlearn) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->datazets>=1.1.2->bnlearn) (2025.4.26)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets->bnlearn) (0.8.4)\n","Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->bnlearn) (5.7.2)\n","Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->bnlearn) (23.1.0)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->bnlearn) (5.10.4)\n","Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->bnlearn) (7.16.6)\n","Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->bnlearn) (1.8.3)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->bnlearn) (0.18.1)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->bnlearn) (0.21.1)\n","Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->bnlearn) (1.3.1)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets->bnlearn) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->bnlearn) (0.2.13)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->bnlearn) (4.3.8)\n","Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->bnlearn) (0.2.4)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->bnlearn) (4.13.4)\n","Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->bnlearn) (6.2.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->bnlearn) (0.7.1)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->bnlearn) (0.3.0)\n","Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->bnlearn) (3.1.3)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->bnlearn) (0.10.2)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->bnlearn) (1.5.1)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->bnlearn) (2.21.1)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->bnlearn) (4.23.0)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->bnlearn) (21.2.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->bnlearn) (0.5.1)\n","Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->bnlearn) (1.4.0)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->bnlearn) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->bnlearn) (2025.4.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->bnlearn) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->bnlearn) (0.24.0)\n","Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->bnlearn) (1.16.0)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->bnlearn) (1.17.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->bnlearn) (2.7)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->bnlearn) (2.22)\n","Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->bnlearn) (4.9.0)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->bnlearn) (1.8.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->bnlearn) (1.3.1)\n","Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","Using cached scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n","Installing collected packages: numpy, scipy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.23.5\n","    Uninstalling numpy-1.23.5:\n","      Successfully uninstalled numpy-1.23.5\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.10.1\n","    Uninstalling scipy-1.10.1:\n","      Successfully uninstalled scipy-1.10.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n","tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.11.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.26.4 scipy-1.11.4\n"]}]},{"cell_type":"code","source":["!pip install cplex"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xwN3x3VyXP1U","executionInfo":{"status":"ok","timestamp":1747151826201,"user_tz":-120,"elapsed":6848,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"}},"outputId":"fbd9f2bc-8b74-4355-cad1-7d89135355af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting cplex\n","  Downloading cplex-22.1.2.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (56 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/57.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cplex-22.1.2.0-cp311-cp311-manylinux2014_x86_64.whl (44.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: cplex\n","Successfully installed cplex-22.1.2.0\n"]}]},{"cell_type":"code","source":["!pip install numpy==1.23.5\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":583},"id":"RjlLhRR_gVdg","executionInfo":{"status":"ok","timestamp":1747154494343,"user_tz":-120,"elapsed":9089,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"}},"outputId":"c648cc95-0ccf-47cc-f3f0-e9c6c316edf9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting numpy==1.23.5\n","  Using cached numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n","Using cached numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n","Installing collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.26.4\n","    Uninstalling numpy-1.26.4:\n","      Successfully uninstalled numpy-1.26.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","pygam 0.9.1 requires numpy>=1.25; python_version >= \"3.9\" and python_version < \"3.13\", but you have numpy 1.23.5 which is incompatible.\n","bnlearn 0.11.1 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n","chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n","treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n","scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n","imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n","xarray 2025.3.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n","pymc 5.22.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n","bigframes 2.1.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n","jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n","albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n","albumentations 2.0.6 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n","tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n","tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.11.4 which is incompatible.\n","blosc2 3.3.2 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n","jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.23.5\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"1305b3f6327546aaab32c215689f0186"}},"metadata":{}}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1066,"status":"ok","timestamp":1747054525816,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"},"user_tz":-120},"id":"6lUXGcicOkSs","outputId":"7ec50d32-f960-4fa1-db8d-54d0d4978118"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","os.chdir(\"/content/drive/My Drive/Colab Notebooks/Causality/cliquewidth/ExDAG-ExDBN-ExMAG/Pavel-GitLab/\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9742,"status":"ok","timestamp":1747054535559,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"},"user_tz":-120},"id":"9gA3pTWo0Wcl","outputId":"30061e6b-f841-4eca-e10a-6480b8cdb911"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting numpy==1.23.5\n","  Using cached numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n","Collecting scipy==1.10.1\n","  Using cached scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n","Using cached numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n","Using cached scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.1 MB)\n","Installing collected packages: numpy, scipy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.26.4\n","    Uninstalling numpy-1.26.4:\n","      Successfully uninstalled numpy-1.26.4\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0m^C\n"]}],"source":["pip install numpy==1.23.5 scipy==1.10.1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10168,"status":"ok","timestamp":1747054545728,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"},"user_tz":-120},"id":"9ZEvqeHUwMCw","outputId":"a29d1233-509e-4914-ed7d-8a38c14a171b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pygraphviz in /usr/local/lib/python3.11/dist-packages (1.14)\n","Requirement already satisfied: pygobnilp in /usr/local/lib/python3.11/dist-packages (1.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pygobnilp) (1.11.4)\n","Requirement already satisfied: pygraphviz in /usr/local/lib/python3.11/dist-packages (from pygobnilp) (1.14)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from pygobnilp) (3.10.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pygobnilp) (3.4.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from pygobnilp) (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pygobnilp) (1.23.5)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from pygobnilp) (1.6.1)\n","Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from pygobnilp) (0.60.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygobnilp) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygobnilp) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygobnilp) (4.57.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygobnilp) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygobnilp) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygobnilp) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygobnilp) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygobnilp) (2.9.0.post0)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->pygobnilp) (0.43.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->pygobnilp) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->pygobnilp) (2025.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pygobnilp) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pygobnilp) (3.6.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->pygobnilp) (1.17.0)\n"]}],"source":["# !apt-get install -y graphviz libgraphviz-dev\n","!pip install pygraphviz\n","!pip install pygobnilp"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6377,"status":"ok","timestamp":1747054552106,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"},"user_tz":-120},"id":"hPBHsHQBr2hr","outputId":"b37c4c4f-d89b-4a24-fe15-d93c206b7f1c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: lingam in /usr/local/lib/python3.11/dist-packages (1.9.1)\n","Requirement already satisfied: bnlearn in /usr/local/lib/python3.11/dist-packages (0.11.1)\n","Requirement already satisfied: gurobipy in /usr/local/lib/python3.11/dist-packages (12.0.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.4.2)\n","Requirement already satisfied: omegaconf in /usr/local/lib/python3.11/dist-packages (2.3.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n","Requirement already satisfied: igraph in /usr/local/lib/python3.11/dist-packages (0.11.8)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Requirement already satisfied: pgmpy in /usr/local/lib/python3.11/dist-packages (0.1.25)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from lingam) (1.23.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lingam) (1.11.4)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from lingam) (0.20.3)\n","Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from lingam) (0.14.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from lingam) (2.2.2)\n","Requirement already satisfied: pygam in /usr/local/lib/python3.11/dist-packages (from lingam) (0.9.1)\n","Requirement already satisfied: psy in /usr/local/lib/python3.11/dist-packages (from lingam) (0.0.1)\n","Requirement already satisfied: semopy in /usr/local/lib/python3.11/dist-packages (from lingam) (2.3.11)\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n","    status = run_func(*args)\n","             ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n","    return func(self, options, args)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n","    requirement_set = resolver.resolve(\n","                      ^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 95, in resolve\n","    result = self._result = resolver.resolve(\n","                            ^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 546, in resolve\n","    state = resolution.resolve(requirements, max_rounds=max_rounds)\n","            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 427, in resolve\n","    failure_causes = self._attempt_to_pin_criterion(name)\n","                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 239, in _attempt_to_pin_criterion\n","    criteria = self._get_updated_criteria(candidate)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 230, in _get_updated_criteria\n","    self._add_to_criteria(criteria, requirement, parent=candidate)\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 173, in _add_to_criteria\n","    if not criterion.candidates:\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/resolvelib/structs.py\", line 156, in __bool__\n","    return bool(self._sequence)\n","           ^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 174, in __bool__\n","    return any(self)\n","           ^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 162, in <genexpr>\n","    return (c for c in iterator if id(c) not in self._incompatible_ids)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 49, in _iter_built\n","    for version, func in infos:\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 300, in iter_index_candidate_infos\n","    result = self._finder.find_best_candidate(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/index/package_finder.py\", line 884, in find_best_candidate\n","    candidates = self.find_all_candidates(project_name)\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/index/package_finder.py\", line 825, in find_all_candidates\n","    page_candidates = list(page_candidates_it)\n","                      ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/index/sources.py\", line 194, in page_candidates\n","    yield from self._candidates_from_page(self._link)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/index/package_finder.py\", line 792, in process_project_url\n","    package_links = self.evaluate_links(\n","                    ^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/index/package_finder.py\", line 772, in evaluate_links\n","    candidate = self.get_install_candidate(link_evaluator, link)\n","                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/index/package_finder.py\", line 750, in get_install_candidate\n","    result, detail = link_evaluator.evaluate_link(link)\n","                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/index/package_finder.py\", line 191, in evaluate_link\n","    wheel = Wheel(link.filename)\n","            ^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/models/wheel.py\", line 36, in __init__\n","    self.pyversions = wheel_info.group(\"pyver\").split(\".\")\n","                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/pip3\", line 10, in <module>\n","    sys.exit(main())\n","             ^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n","    return command.main(cmd_args)\n","           ^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n","    return self._main(args)\n","           ^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n","    return run(options, args)\n","           ^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n","    logger.critical(\"Operation cancelled by user\")\n","  File \"/usr/lib/python3.11/logging/__init__.py\", line 1526, in critical\n","    def critical(self, msg, *args, **kwargs):\n","\n","KeyboardInterrupt\n","^C\n"]}],"source":["!pip install lingam bnlearn gurobipy networkx omegaconf scikit-learn sympy igraph matplotlib pgmpy\n","# hydra-core hydra-joblib-launcher mlflow"]},{"cell_type":"code","source":["!pip install cplex"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ssYuCelhSyBQ","executionInfo":{"status":"ok","timestamp":1747054556027,"user_tz":-120,"elapsed":3917,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"}},"outputId":"1b3a2eb2-7341-44b9-d634-a07e43388ea8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting cplex\n","  Downloading cplex-22.1.2.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (56 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/57.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cplex-22.1.2.0-cp311-cp311-manylinux2014_x86_64.whl (44.3 MB)\n","\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m44.3/44.3 MB\u001b[0m \u001b[31m113.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n","\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0m^C\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_SmFwk-wKnhy"},"outputs":[],"source":["#import hydra\n","#import mlflow\n","import igraph\n","import gurobipy as gp"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qelpvL58UTZJ"},"outputs":[],"source":["!export PYTHONPATH=\"$PYTHONPATH:/content/drive/MyDrive/Colab Notebooks/NCPOP-Colab Notebooks-data\"\n","import os\n","os.environ['GRB_LICENSE_FILE'] = '/content/drive/MyDrive/gurobi.lic'  # Update this path with the actual license location\n"]},{"cell_type":"markdown","metadata":{"id":"xR7KRrjOXJqA"},"source":["# Utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UnKa8vb5rUpN"},"outputs":[],"source":["import functools\n","import logging\n","\n","def log_exceptions(function):\n","    \"\"\"\n","    A decorator that wraps the passed in function and logs\n","    exceptions should one occur\n","    \"\"\"\n","    @functools.wraps(function)\n","    def wrapper(*args, **kwargs):\n","        try:\n","            return function(*args, **kwargs)\n","        except:\n","            # log the exception\n","            err = \"There was an exception in  \"\n","            err += function.__name__\n","            logging.exception(err)\n","            # re-raise the exception\n","            raise\n","    return wrapper"]},{"cell_type":"markdown","metadata":{"id":"sbPRy7MNM85c"},"source":["## notears.utils\n","\n","包括：\n","\n","*  DAG生成和判定: is_dag, simulate_dag, simulate_parameter\n","\n","*  数据模拟: simulate_linear_sem, simulate_nonlinear_sem\n","\n","*  准确性评估: count_accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qvid8ve-M9EU"},"outputs":[],"source":["import numpy as np\n","from scipy.special import expit as sigmoid\n","import igraph as ig\n","import random\n","\n","class notears_utils():\n","\n","    def set_random_seed(seed):\n","        random.seed(seed)\n","        np.random.seed(seed)\n","\n","\n","    def is_dag(W):\n","        G = ig.Graph.Weighted_Adjacency(W.tolist())\n","        return G.is_dag()\n","\n","\n","    def simulate_dag(d, s0, graph_type):\n","        \"\"\"Simulate random DAG with some expected number of edges.\n","\n","        Args:\n","            d (int): num of nodes\n","            s0 (int): expected num of edges\n","            graph_type (str): ER, SF, BP\n","\n","        Returns:\n","            B (np.ndarray): [d, d] binary adj matrix of DAG\n","        \"\"\"\n","        def _random_permutation(M):\n","            # np.random.permutation permutes first axis only\n","            P = np.random.permutation(np.eye(M.shape[0]))\n","            return P.T @ M @ P\n","\n","        def _random_acyclic_orientation(B_und):\n","            return np.tril(_random_permutation(B_und), k=-1)\n","\n","        def _graph_to_adjmat(G):\n","            return np.array(G.get_adjacency().data)\n","\n","        if graph_type == 'ER':\n","            # Erdos-Renyi\n","            G_und = ig.Graph.Erdos_Renyi(n=d, m=s0)\n","            B_und = _graph_to_adjmat(G_und)\n","            B = _random_acyclic_orientation(B_und)\n","        elif graph_type == 'SF':\n","            # Scale-free, Barabasi-Albert\n","            G = ig.Graph.Barabasi(n=d, m=int(round(s0 / d)), directed=True)\n","            B = _graph_to_adjmat(G)\n","        elif graph_type == 'BP':\n","            # Bipartite, Sec 4.1 of (Gu, Fu, Zhou, 2018)\n","            top = int(0.2 * d)\n","            G = ig.Graph.Random_Bipartite(top, d - top, m=s0, directed=True, neimode=ig.OUT)\n","            B = _graph_to_adjmat(G)\n","        elif graph_type == 'PATH':\n","            # Path graph for generating counter examples\n","            G = ig.Graph(directed=True) #   Random_Bipartite(top, d - top, m=s0, directed=True, neimode=ig.OUT)\n","            G.add_vertices(d)\n","            for v in range(d-1):\n","                G.add_edge(v, v + 1)\n","            B = _graph_to_adjmat(G)\n","            assert ig.Graph.Adjacency(B.tolist()).is_dag()\n","            return B\n","        elif graph_type == 'PATHPERM':\n","            # Path graph for generating counter examples\n","            G = ig.Graph(directed=True) #   Random_Bipartite(top, d - top, m=s0, directed=True, neimode=ig.OUT)\n","            G.add_vertices(d)\n","            for v in range(d-1):\n","                G.add_edge(v, v + 1)\n","            B = _graph_to_adjmat(G)\n","        elif graph_type == 'G2':\n","            # Path graph for generating counter examples\n","            G = ig.Graph(directed=True) #   Random_Bipartite(top, d - top, m=s0, directed=True, neimode=ig.OUT)\n","            G.add_vertices(d)\n","            for v in range(d-1):\n","                G.add_edge(v, v + 1)\n","        else:\n","            raise ValueError('unknown graph type')\n","        B_perm = _random_permutation(B)\n","        assert ig.Graph.Adjacency(B_perm.tolist()).is_dag()\n","        return B_perm\n","\n","\n","    def simulate_parameter(B, w_ranges=((-2.0, -0.5), (0.5, 2.0))):\n","        \"\"\"Simulate SEM parameters for a DAG.\n","\n","        Args:\n","            B (np.ndarray): [d, d] binary adj matrix of DAG\n","            w_ranges (tuple): disjoint weight ranges\n","\n","        Returns:\n","            W (np.ndarray): [d, d] weighted adj matrix of DAG\n","        \"\"\"\n","        W = np.zeros(B.shape)\n","        S = np.random.randint(len(w_ranges), size=B.shape)  # which range\n","        for i, (low, high) in enumerate(w_ranges):\n","            U = np.random.uniform(low=low, high=high, size=B.shape)\n","            W += B * (S == i) * U\n","        return W\n","\n","\n","    def simulate_linear_sem(W, n, sem_type, noise_scale=None):\n","        \"\"\"Simulate samples from linear SEM with specified type of noise.\n","\n","        For uniform, noise z ~ uniform(-a, a), where a = noise_scale.\n","\n","        Args:\n","            W (np.ndarray): [d, d] weighted adj matrix of DAG\n","            n (int): num of samples, n=inf mimics population risk\n","            sem_type (str): gauss, exp, gumbel, uniform, logistic, poisson\n","            noise_scale (np.ndarray): scale parameter of additive noise, default all ones\n","\n","        Returns:\n","            X (np.ndarray): [n, d] sample matrix, [d, d] if n=inf\n","        \"\"\"\n","        def _simulate_single_equation(X, w, scale):\n","            \"\"\"X: [n, num of parents], w: [num of parents], x: [n]\"\"\"\n","            if sem_type == 'gauss':\n","                z = np.random.normal(scale=scale, size=n)\n","                #print(z.sum()/ z.size)\n","                x = X @ w + z\n","            elif sem_type == 'exp':\n","                z = np.random.exponential(scale=scale, size=n)\n","                x = X @ w + z\n","            elif sem_type == 'gumbel':\n","                z = np.random.gumbel(scale=scale, size=n)\n","                x = X @ w + z\n","            elif sem_type == 'uniform':\n","                z = np.random.uniform(low=-scale, high=scale, size=n)\n","                #print(z.sum()/ z.size)\n","                x = X @ w + z\n","            elif sem_type == 'logistic':\n","                x = np.random.binomial(1, sigmoid(X @ w)) * 1.0\n","            elif sem_type == 'poisson':\n","                x = np.random.poisson(np.exp(X @ w)) * 1.0\n","            else:\n","                raise ValueError('unknown sem type')\n","            return x\n","\n","        d = W.shape[0]\n","        if noise_scale is None:\n","            scale_vec = np.ones(d)\n","        elif np.isscalar(noise_scale):\n","            scale_vec = noise_scale * np.ones(d)\n","        else:\n","            if len(noise_scale) != d:\n","                raise ValueError('noise scale must be a scalar or has length d')\n","            scale_vec = noise_scale\n","        if not notears_utils.is_dag(W):\n","            raise ValueError('W must be a DAG')\n","        if np.isinf(n):  # population risk for linear gauss SEM\n","            if sem_type == 'gauss':\n","                # make 1/d X'X = true cov\n","                X = np.sqrt(d) * np.diag(scale_vec) @ np.linalg.inv(np.eye(d) - W)\n","                return X\n","            else:\n","                raise ValueError('population risk not available')\n","        # empirical risk\n","        G = ig.Graph.Weighted_Adjacency(W.tolist())\n","        ordered_vertices = G.topological_sorting()\n","        assert len(ordered_vertices) == d\n","        X = np.zeros([n, d])\n","        for j in ordered_vertices:\n","            parents = G.neighbors(j, mode=ig.IN)\n","            X[:, j] = _simulate_single_equation(X[:, parents], W[parents, j], scale_vec[j])\n","        return X\n","\n","\n","    def simulate_nonlinear_sem(B, n, sem_type, noise_scale=None):\n","        \"\"\"Simulate samples from nonlinear SEM.\n","\n","        Args:\n","            B (np.ndarray): [d, d] binary adj matrix of DAG\n","            n (int): num of samples\n","            sem_type (str): mlp, mim, gp, gp-add\n","            noise_scale (np.ndarray): scale parameter of additive noise, default all ones\n","\n","        Returns:\n","            X (np.ndarray): [n, d] sample matrix\n","        \"\"\"\n","        def _simulate_single_equation(X, scale):\n","            \"\"\"X: [n, num of parents], x: [n]\"\"\"\n","            z = np.random.normal(scale=scale, size=n)\n","            pa_size = X.shape[1]\n","            if pa_size == 0:\n","                return z\n","            if sem_type == 'mlp':\n","                hidden = 100\n","                W1 = np.random.uniform(low=0.5, high=2.0, size=[pa_size, hidden])\n","                W1[np.random.rand(*W1.shape) < 0.5] *= -1\n","                W2 = np.random.uniform(low=0.5, high=2.0, size=hidden)\n","                W2[np.random.rand(hidden) < 0.5] *= -1\n","                x = sigmoid(X @ W1) @ W2 + z\n","            elif sem_type == 'mim':\n","                w1 = np.random.uniform(low=0.5, high=2.0, size=pa_size)\n","                w1[np.random.rand(pa_size) < 0.5] *= -1\n","                w2 = np.random.uniform(low=0.5, high=2.0, size=pa_size)\n","                w2[np.random.rand(pa_size) < 0.5] *= -1\n","                w3 = np.random.uniform(low=0.5, high=2.0, size=pa_size)\n","                w3[np.random.rand(pa_size) < 0.5] *= -1\n","                x = np.tanh(X @ w1) + np.cos(X @ w2) + np.sin(X @ w3) + z\n","            elif sem_type == 'gp':\n","                from sklearn.gaussian_process import GaussianProcessRegressor\n","                gp = GaussianProcessRegressor()\n","                x = gp.sample_y(X, random_state=None).flatten() + z\n","            elif sem_type == 'gp-add':\n","                from sklearn.gaussian_process import GaussianProcessRegressor\n","                gp = GaussianProcessRegressor()\n","                x = sum([gp.sample_y(X[:, i, None], random_state=None).flatten()\n","                        for i in range(X.shape[1])]) + z\n","            else:\n","                raise ValueError('unknown sem type')\n","            return x\n","\n","        d = B.shape[0]\n","        scale_vec = noise_scale if noise_scale else np.ones(d)\n","        X = np.zeros([n, d])\n","        G = ig.Graph.Adjacency(B.tolist())\n","        ordered_vertices = G.topological_sorting()\n","        assert len(ordered_vertices) == d\n","        for j in ordered_vertices:\n","            parents = G.neighbors(j, mode=ig.IN)\n","            X[:, j] = _simulate_single_equation(X[:, parents], scale_vec[j])\n","        return X\n","\n","\n","    def count_accuracy(B_true, B_est):\n","        \"\"\"Compute various accuracy metrics for B_est.\n","\n","        true positive = predicted association exists in condition in correct direction\n","        reverse = predicted association exists in condition in opposite direction\n","        false positive = predicted association does not exist in condition\n","\n","        Args:\n","            B_true (np.ndarray): [d, d] ground truth graph, {0, 1}\n","            B_est (np.ndarray): [d, d] estimate, {0, 1, -1}, -1 is undirected edge in CPDAG\n","\n","        Returns:\n","            fdr: (reverse + false positive) / prediction positive\n","            tpr: (true positive) / condition positive\n","            fpr: (reverse + false positive) / condition negative\n","            shd: undirected extra + undirected missing + reverse\n","            nnz: prediction positive\n","        \"\"\"\n","        if (B_est == -1).any():  # cpdag\n","            if not ((B_est == 0) | (B_est == 1) | (B_est == -1)).all():\n","                raise ValueError('B_est should take value in {0,1,-1}')\n","            if ((B_est == -1) & (B_est.T == -1)).any():\n","                raise ValueError('undirected edge should only appear once')\n","        else:  # dag\n","            if not ((B_est == 0) | (B_est == 1)).all():\n","                raise ValueError('B_est should take value in {0,1}')\n","            if not is_dag(B_est):\n","                raise ValueError('B_est should be a DAG')\n","        d = B_true.shape[0]\n","        # linear index of nonzeros\n","        pred_und = np.flatnonzero(B_est == -1)\n","        pred = np.flatnonzero(B_est == 1)\n","        cond = np.flatnonzero(B_true)\n","        cond_reversed = np.flatnonzero(B_true.T)\n","        cond_skeleton = np.concatenate([cond, cond_reversed])\n","        # true pos\n","        true_pos = np.intersect1d(pred, cond, assume_unique=True)\n","        # treat undirected edge favorably\n","        true_pos_und = np.intersect1d(pred_und, cond_skeleton, assume_unique=True)\n","        true_pos = np.concatenate([true_pos, true_pos_und])\n","        # false pos\n","        false_pos = np.setdiff1d(pred, cond_skeleton, assume_unique=True)\n","        false_pos_und = np.setdiff1d(pred_und, cond_skeleton, assume_unique=True)\n","        false_pos = np.concatenate([false_pos, false_pos_und])\n","        # reverse\n","        extra = np.setdiff1d(pred, cond, assume_unique=True)\n","        reverse = np.intersect1d(extra, cond_reversed, assume_unique=True)\n","        # compute ratio\n","        pred_size = len(pred) + len(pred_und)\n","        cond_neg_size = 0.5 * d * (d - 1) - len(cond)\n","        fdr = float(len(reverse) + len(false_pos)) / max(pred_size, 1)\n","        tpr = float(len(true_pos)) / max(len(cond), 1)\n","        fpr = float(len(reverse) + len(false_pos)) / max(cond_neg_size, 1)\n","        # structural hamming distance\n","        pred_lower = np.flatnonzero(np.tril(B_est + B_est.T))\n","        cond_lower = np.flatnonzero(np.tril(B_true + B_true.T))\n","        extra_lower = np.setdiff1d(pred_lower, cond_lower, assume_unique=True)\n","        missing_lower = np.setdiff1d(cond_lower, pred_lower, assume_unique=True)\n","        shd = len(extra_lower) + len(missing_lower) + len(reverse)\n","        precision = len(true_pos) / max((len(true_pos) + len(false_pos)), 1)\n","        f1 = 2 * (tpr*precision)/max((tpr+precision), 1)\n","        g_score = max((len(true_pos)-len(false_pos),0))/max(len(cond), 1)\n","        return {\n","            'fdr': fdr,\n","            'tpr': tpr, # recall, sensitivity\n","            'fpr': fpr,\n","            'shd': shd,\n","            'nnz': pred_size,\n","            'true_pos': len(true_pos),\n","            'false_pos': len(false_pos),\n","            'false_neg': len(cond) - len(true_pos),\n","            'cond': len(cond),\n","            'precision': precision,\n","            'f1score': f1,\n","            'g_score': g_score\n","        }\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2L7d89uLNv1B"},"source":["## dagsolver_utils\n","\n","*  apply_threshold, compute_shd, find_minimal_dag_threshold, find_optimal_threshold"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lq3YQS_ONwCl"},"outputs":[],"source":["import networkx as nx\n","import numpy as np\n","from networkx import from_numpy_array, DiGraph\n","\n","# import notears.utils as notears_utils\n","\n","\n","def apply_threshold(W, w_threshold):\n","    W_t = np.copy(W)\n","    W_t[np.abs(W) < w_threshold] = 0\n","    return W_t\n","\n","\n","def compute_shd(W_true, W_est):\n","    acc = notears_utils.count_accuracy(W_true != 0, W_est != 0)\n","    return acc['shd'], acc\n","\n","\n","def find_minimal_dag_threshold(W):\n","    if notears_utils.is_dag(W):\n","        return 0, W\n","    possible_thresholds = sorted((abs(t) for t in W.flatten() if abs(t) > 0))\n","    for t_candidate in possible_thresholds:\n","        W[np.abs(W) < t_candidate] = 0\n","        if notears_utils.is_dag(W):\n","            return t_candidate, W\n","    assert False  # Should always find a dag\n","\n","\n","def find_optimal_threshold(W_true, W_est):\n","    possible_thresholds = sorted((abs(t) for t in W_est.flatten() if abs(t) > 0))\n","    best_t = max(possible_thresholds) if possible_thresholds else 0\n","    best_shd = W_true.shape[0]**2\n","    _, best_acc = compute_shd(W_true, W_est)\n","    best_W = W_est\n","    for t_candidate in possible_thresholds:\n","        W_est_t = apply_threshold(W_est, t_candidate)\n","        shd, acc = compute_shd(W_true, W_est_t)\n","        if shd < best_shd:\n","            best_t = t_candidate\n","            best_shd = shd\n","            best_acc = acc\n","            best_W = W_est_t\n","    return best_t, best_shd, best_W, best_acc\n","\n","\n","def least_square_cost(X, W):\n","    n, d = X.shape\n","    val = sum((X[i,j] - sum(X[i, k] * W[k, j] for k in range(d) if k != j))**2 for i in range(n) for j in range(d))\n","    return val\n","\n","\n","def plot(W, filename=None):\n","    import matplotlib.pyplot as plt\n","    # if abbrev:\n","    #     ls = dict((x,x[:3]) for x in self.nodes)\n","    # else:\n","    #     ls = None\n","    # try:\n","    #     edge_colors = [self._edge_colour[compelled] for (u,v,compelled) in self.edges.data('compelled')]\n","    # except KeyError:\n","    #     edge_colors = 'k'\n","    graph = from_numpy_array(W, create_using=DiGraph)\n","    fig, ax = plt.subplots()\n","    nx.draw_networkx(graph, ax=ax, pos=nx.drawing.nx_agraph.graphviz_layout(graph,prog='dot'),\n","                     node_color=\"white\",arrowsize=15)\n","    if filename is not None:\n","        fig.savefig(filename,format='png', bbox_inches='tight')\n","    else:\n","        plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"tIYruWoVnW6A"},"source":["## metrics_utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YneGVs1MnXGD"},"outputs":[],"source":["import numpy as np\n","\n","from dagsolvers.dagsolver_utils import least_square_cost, apply_threshold, count_accuracy, compute_norm_distance, \\\n","    find_optimal_threshold_for_shd, find_optimal_multiple_thresholds, compute_combined_shd\n","from notears import utils\n","from numpy.linalg import norm\n","\n","\n","def log_acc_metrics(acc, run, prefix):\n","    for key in ['shd', 'shd_w', 'shd_a', 'fdr', 'least_square_cost', 'norm_distance', 'cond', 'true_pos', 'tpr', 'false_pos', 'nnz', 'false_neg', 'precision', 'f1score', 'g_score']:\n","        if key in acc:\n","            run.log_metric(f'{prefix}_{key}', acc[key])\n","\n","\n","def calculate_metrics(X, Y, W_true, B_true, A_true, W_est, A_est, W_bi_true, W_bi_est, run, cfg):\n","    cost_W_true = least_square_cost(X, W_true, Y, A_true)\n","    run.log_metric('true_least_square_cost', cost_W_true)\n","\n","    if W_bi_est is None:\n","        W_bi_est = np.zeros_like(W_true)\n","        W_bi_true = np.zeros_like(W_true)\n","    W_bi_est = np.triu(W_bi_est, k=1)\n","    W_bi_true = np.triu(W_bi_true, k=1)\n","    B_bi_true = (W_bi_true != 0)\n","    B_all_true = B_true - B_bi_true\n","\n","    best_t, best_shd = find_optimal_threshold_for_shd(B_true, W_est, A_true, A_est, W_bi_true, W_bi_est)\n","\n","    thresholds = [0.5, 0.3, 0.15, 0.05, best_t]\n","    best_W = None\n","    best_Wbi = None\n","    best_A = None\n","    for threshold in thresholds:\n","        W_est_t = apply_threshold(W_est, threshold)\n","        B_est_t = W_est_t != 0\n","        W_bi_est_t = apply_threshold(W_bi_est, threshold)\n","        B_bi_est_t = (W_bi_est_t != 0)\n","        B_all_est_t = B_est_t + (-1 * B_bi_est_t) # CPDAG - undirected edges have -1\n","        A_est_t = [apply_threshold(A_i_est, threshold) for A_i_est in A_est]\n","        acc_all = count_accuracy(B_all_true, B_all_est_t, A_true, A_est_t)\n","        acc_all['least_square_cost'] = least_square_cost(X, W_est_t, Y, A_est_t) - cost_W_true\n","        acc_all['norm_distance'] = compute_norm_distance(W_true, W_est_t, A_true, A_est_t)\n","        if threshold == best_t:\n","            best_W = W_est_t\n","            best_Wbi = W_bi_est_t\n","            best_A = A_est_t\n","        metric_infix = 'best' if threshold == best_t else f't{threshold}'\n","        log_acc_metrics(acc_all, run, f'{metric_infix}')\n","        acc_dir = count_accuracy(B_true, B_est_t, A_true, A_est_t)\n","        log_acc_metrics(acc_dir, run, f'dir_{metric_infix}')\n","        acc_bi = count_accuracy(B_bi_true, B_bi_est_t, A_true, A_est_t)\n","        log_acc_metrics(acc_bi, run, f'bi_{metric_infix}')\n","        print(metric_infix)\n","        print(acc_all)\n","\n","    assert best_W is not None\n","\n","    run.log_metric('best_threshold', best_t)\n","    #run.log_metric('best_shd', best_shd)\n","    #run.log_metric('best_shd_w', best_acc['shd_w'])\n","    #run.log_metric('best_shd_a', best_acc['shd_a'])\n","    #run.log_metric('best_least_square_cost', least_square_cost(X, best_W, Y, best_A_est) - cost_W_true)\n","    #run.log_metric('best_norm_distance', compute_norm_distance(W_true, best_W, A_true, best_A_est))\n","    #run.log_metric('best_true_positive', best_acc['true_pos'])\n","    # run.log_metric('best_tpr_recall', best_acc['tpr'])\n","    # run.log_metric('best_false_positive', best_acc['false_pos'])\n","    # run.log_metric('best_nnz', best_acc['nnz'])\n","    # run.log_metric('best_false_negative', best_acc['false_neg'])\n","    # run.log_metric('best_precision', best_acc['precision'])\n","    # run.log_metric('best_f1score', best_acc['f1score'])\n","    # run.log_metric('best_gscore', best_acc['g_score'])\n","\n","    # print('best')\n","    # print(best_acc)\n","\n","    # if A_true:\n","    #     best_w_t, best_a_t, best_shd_var, best_W_var, best_a_var, best_acc_var = find_optimal_multiple_thresholds(B_true, W_est, A_true, A_est, W_bi_true, Wbi)\n","    #     run.log_metric('best_shd_var', best_shd_var)\n","    #     run.log_metric('best_norm_distance_var', compute_norm_distance(W_true, best_W_var, A_true, best_a_var))\n","    #     run.log_metric('best_f1score_var', best_acc_var['f1score'])\n","    #     run.log_metric('best_gscore_var', best_acc_var['g_score'])\n","    #     run.log_metric('best_least_square_cost_var', least_square_cost(X, best_W_var, Y, best_a_var) - cost_W_true)\n","    #     print(f'best var shd: {best_shd_var}')\n","    #\n","    #\n","    #\n","    # if A_true:\n","    #     combined_best_t, combined_best_shd, combined_best_W, combined_best_acc = compute_combined_shd(W_true, W_est, A_true, A_est, W_bi_true, Wbi)\n","    #     run.log_metric('combined_best_shd_var', combined_best_shd)\n","    #     print(f'combined best shd: {combined_best_shd}')\n","\n","    return best_W, best_Wbi, best_A\n","\n","\n","\n"]},{"cell_type":"markdown","source":["## BN_IP4AncADMG_utils"],"metadata":{"id":"-UE_v8_vQVDY"}},{"cell_type":"code","source":["import numpy as np\n","import torch\n","from torch.utils.data.dataset import TensorDataset\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import numpy as np\n","import scipy.linalg as slin\n","import scipy.sparse as sp\n","import networkx as nx\n","import pandas as pd\n","from pandas import ExcelWriter\n","from pandas import ExcelFile\n","import os\n","import glob\n","import re\n","import pickle\n","import math\n","from torch.optim.adam import Adam\n","from sklearn.linear_model import LinearRegression\n","import sys\n","\n","# data generating functions\n","\n","def simulate_random_dag(d: int,\n","                        degree: float,\n","                        graph_type: str,\n","                        w_range: tuple = (0.5, 2.0)) -> nx.DiGraph:\n","    \"\"\"Simulate random DAG with some expected degree.\n","\n","    Args:\n","        d: number of nodes\n","        degree: expected node degree, in + out\n","        graph_type: {erdos-renyi, barabasi-albert, full}\n","        w_range: weight range +/- (low, high)\n","\n","    Returns:\n","        G: weighted DAG\n","    \"\"\"\n","    if graph_type == 'erdos-renyi':\n","        prob = float(degree) / (d - 1)\n","        B = np.tril((np.random.rand(d, d) < prob).astype(float), k=-1)\n","    elif graph_type == 'barabasi-albert':\n","        m = int(round(degree / 2))\n","        B = np.zeros([d, d])\n","        bag = [0]\n","        for ii in range(1, d):\n","            dest = np.random.choice(bag, size=m)\n","            for jj in dest:\n","                B[ii, jj] = 1\n","            bag.append(ii)\n","            bag.extend(dest)\n","    elif graph_type == 'full':  # ignore degree, only for experimental use\n","        B = np.tril(np.ones([d, d]), k=-1)\n","    else:\n","        raise ValueError('unknown graph type')\n","    # random permutation\n","    P = np.random.permutation(np.eye(d, d))  # permutes first axis only\n","    B_perm = P.T.dot(B).dot(P)\n","    U = np.random.uniform(low=w_range[0], high=w_range[1], size=[d, d])\n","    U[np.random.rand(d, d) < 0.5] *= -1\n","    W = (B_perm != 0).astype(float) * U\n","    G = nx.DiGraph(W)\n","    return G\n","\n","\n","def simulate_sem(G: nx.DiGraph,\n","                 n: int, x_dims: int,\n","                 sem_type: str,\n","                 noise_scale: float = 1.0) -> np.ndarray:\n","    \"\"\"Simulate samples from SEM with specified type of noise.\n","\n","    Args:\n","        G: weigthed DAG\n","        n: number of samples\n","        sem_type: {linear-gauss,linear-exp,linear-gumbel}\n","        noise_scale: scale parameter of noise distribution in linear SEM\n","\n","    Returns:\n","        X: [n,d] sample matrix\n","    \"\"\"\n","    W = nx.to_numpy_array(G)\n","    d = W.shape[0]\n","    X = np.zeros([n, d, x_dims])\n","    ordered_vertices = list(nx.topological_sort(G))\n","    assert len(ordered_vertices) == d\n","    for j in ordered_vertices:\n","        parents = list(G.predecessors(j))\n","        # eta = (np.sin(X[:, parents])+1.).dot(W[parents, j])  # [n,]\n","        eta = X[:, parents, 0].dot(W[parents, j])\n","        if sem_type == 'linear-gauss':\n","            X[:, j, 0] = eta + np.random.normal(scale=noise_scale, size=n)\n","        elif sem_type == 'linear-exp':\n","            X[:, j, 0] = eta + np.random.exponential(scale=noise_scale, size=n)\n","        elif sem_type == 'linear-gumbel':\n","            X[:, j, 0] = eta + np.random.gumbel(scale=noise_scale, size=n)\n","        else:\n","            raise ValueError('unknown sem type')\n","    for i in range(x_dims-1):\n","        X[:, :, i+1] = np.random.normal(scale=noise_scale, size=1)*X[:, :, 0] + np.random.normal(scale=noise_scale, size=1) + np.random.normal(scale=noise_scale, size=(n, d))\n","    X[:, :, 0] = np.random.normal(scale=noise_scale, size=1) * X[:, :, 0] + np.random.normal(scale=noise_scale, size=1) + np.random.normal(scale=noise_scale, size=(n, d))\n"," #       for j in ordered_vertices:\n"," #           parents = list(G.predecessors(j))\n","#            eta = X[:, parents, i].dot(W[parents, j])\n","#            if sem_type == 'linear-gauss':\n","#                X[:, j, i] = eta + np.random.normal(scale=noise_scale, size=n)\n","#            elif sem_type == 'linear-exp':\n","#                X[:, j, i] = eta + np.random.exponential(scale=noise_scale, size=n)\n","#            elif sem_type == 'linear-gumbel':\n","#                X[:, j, i] = eta + np.random.gumbel(scale=noise_scale, size=n)\n","#            else:\n","#                raise ValueError('unknown sem type')\n","    return X\n","\n","def import_sem(G: nx.DiGraph,\n","                 n: int,\n","                 sem_type: str,\n","                 noise_scale: float = 1.0) -> np.ndarray:\n","    \"\"\"Simulate samples from SEM with specified type of noise.\n","\n","    Args:\n","        G: weigthed DAG\n","        n: number of samples\n","        sem_type: {linear-gauss,linear-exp,linear-gumbel}\n","        noise_scale: scale parameter of noise distribution in linear SEM\n","\n","    Returns:\n","        X: [n,d] sample matrix\n","    \"\"\"\n","    W = nx.to_numpy_array(G)\n","    d = W.shape[0]\n","    X = np.zeros([n, d])\n","\n","\n","    df1 = pd.read_excel('../Sachs_data/1.xls', header=None)\n","    d_train1 = df1.as_matrix()\n","    df2 = pd.read_excel('../Sachs_data/2.xls', header=None)\n","    d_train2 = df2.as_matrix()\n","    df3 = pd.read_excel('../Sachs_data/3.xls', header=None)\n","    d_train3 = df3.as_matrix()\n","    df4 = pd.read_excel('../Sachs_data/4.xls', header=None)\n","    d_train4 = df4.as_matrix()\n","    df5 = pd.read_excel('../Sachs_data/5.xls', header=None)\n","    d_train5 = df5.as_matrix()\n","    df6 = pd.read_excel('../Sachs_data/6.xls', header=None)\n","    d_train6 = df6.as_matrix()\n","    df7 = pd.read_excel('../Sachs_data/7.xls', header=None)\n","    d_train7 = df7.as_matrix()\n","    df8 = pd.read_excel('../Sachs_data/8.xls', header=None)\n","    d_train8 = df8.as_matrix()\n","    df9 = pd.read_excel('../Sachs_data/9.xls', header=None)\n","    d_train9 = df9.as_matrix()\n","    df10 = pd.read_excel('../Sachs_data/10.xls', header=None)\n","    d_train10 = df10.as_matrix()\n","    df11 = pd.read_excel('../Sachs_data/11.xls', header=None)\n","    d_train11 = df11.as_matrix()\n","    df12 = pd.read_excel('../Sachs_data/12.xls', header=None)\n","    d_train12 = df12.as_matrix()\n","    df13 = pd.read_excel('../Sachs_data/13.xls', header=None)\n","    d_train13 = df13.as_matrix()\n","    df14 = pd.read_excel('../Sachs_data/14.xls', header=None)\n","    d_train14 = df14.as_matrix()\n","\n","    d_train=np.vstack((d_train1[1:,:], d_train2[1:,:], d_train3[1:,:], d_train4[1:,:], d_train5[1:,:], d_train6[1:,:], d_train7[1:,:], d_train8[1:,:], d_train9[1:,:]))#, d_train10[1:,:], d_train11[1:,:], d_train12[1:,:], d_train13[1:,:], d_train14[1:,:]))\n","\n","    #return (d_train[0:11650,:]).astype(np.float64)\n","    return (d_train[0:7464, :]).astype(np.float64)\n","\n","\n","def simulate_population_sample(W: np.ndarray,\n","                               Omega: np.ndarray) -> np.ndarray:\n","    \"\"\"Simulate data matrix X that matches population least squares.\n","\n","    Args:\n","        W: [d,d] adjacency matrix\n","        Omega: [d,d] noise covariance matrix\n","\n","    Returns:\n","        X: [d,d] sample matrix\n","    \"\"\"\n","    d = W.shape[0]\n","    X = np.sqrt(d) * slin.sqrtm(Omega).dot(np.linalg.pinv(np.eye(d) - W))\n","    return X\n","\n","\n","def count_accuracy(G_true: nx.DiGraph,\n","                   G: nx.DiGraph,\n","                   G_und: nx.DiGraph = None) -> tuple:\n","    \"\"\"Compute FDR, TPR, and FPR for B, or optionally for CPDAG B + B_und.\n","\n","    Args:\n","        G_true: ground truth graph\n","        G: predicted graph\n","        G_und: predicted undirected edges in CPDAG, asymmetric\n","\n","    Returns:\n","        fdr: (reverse + false positive) / prediction positive\n","        tpr: (true positive) / condition positive\n","        fpr: (reverse + false positive) / condition negative\n","        shd: undirected extra + undirected missing + reverse\n","        nnz: prediction positive\n","    \"\"\"\n","    B_true = nx.to_numpy_array(G_true) != 0\n","    B = nx.to_numpy_array(G) != 0\n","    B_und = None if G_und is None else nx.to_numpy_array(G_und)\n","    d = B.shape[0]\n","    # linear index of nonzeros\n","    if B_und is not None:\n","        pred_und = np.flatnonzero(B_und)\n","    pred = np.flatnonzero(B)\n","    cond = np.flatnonzero(B_true)\n","    cond_reversed = np.flatnonzero(B_true.T)\n","    cond_skeleton = np.concatenate([cond, cond_reversed])\n","    # true pos\n","    true_pos = np.intersect1d(pred, cond, assume_unique=True)\n","    if B_und is not None:\n","        # treat undirected edge favorably\n","        true_pos_und = np.intersect1d(pred_und, cond_skeleton, assume_unique=True)\n","        true_pos = np.concatenate([true_pos, true_pos_und])\n","    # false pos\n","    false_pos = np.setdiff1d(pred, cond_skeleton, assume_unique=True)\n","    if B_und is not None:\n","        false_pos_und = np.setdiff1d(pred_und, cond_skeleton, assume_unique=True)\n","        false_pos = np.concatenate([false_pos, false_pos_und])\n","    # reverse\n","    extra = np.setdiff1d(pred, cond, assume_unique=True)\n","    reverse = np.intersect1d(extra, cond_reversed, assume_unique=True)\n","    # compute ratio\n","    pred_size = len(pred)\n","    if B_und is not None:\n","        pred_size += len(pred_und)\n","    cond_neg_size = 0.5 * d * (d - 1) - len(cond)\n","    fdr = float(len(reverse) + len(false_pos)) / max(pred_size, 1)\n","    tpr = float(len(true_pos)) / max(len(cond), 1)\n","    fpr = float(len(reverse) + len(false_pos)) / max(cond_neg_size, 1)\n","    # structural hamming distance\n","    B_lower = np.tril(B + B.T)\n","    if B_und is not None:\n","        B_lower += np.tril(B_und + B_und.T)\n","    pred_lower = np.flatnonzero(B_lower)\n","    cond_lower = np.flatnonzero(np.tril(B_true + B_true.T))\n","    extra_lower = np.setdiff1d(pred_lower, cond_lower, assume_unique=True)\n","    missing_lower = np.setdiff1d(cond_lower, pred_lower, assume_unique=True)\n","    shd = len(extra_lower) + len(missing_lower) + len(reverse)\n","    return fdr, tpr, fpr, shd, pred_size\n","\n","\n","\n","\n","\n","'''\n","COMPUTE SCORES FOR BN\n","'''\n","def compute_BiCScore(G, D, is_discrete=True):\n","    '''compute the bic score'''\n","    # score = gm.estimators.BicScore(self.data).score(self.model)\n","    origin_score = []\n","    num_var = G.shape[0]\n","    for i in range(num_var):\n","        parents = np.where(G[:,i] !=0)\n","        if is_discrete:\n","            score_one = compute_local_BiCScore(D, i, parents)\n","        else:\n","            score_one = compute_local_BiCScore_gauss(D, i, parents)\n","        origin_score.append(score_one)\n","\n","    score = sum(origin_score)\n","\n","    return score\n","\n","\n","def compute_local_BiCScore_gauss(np_data, target, parents):\n","    # use dictionary\n","    sample_size = np_data.shape[0]\n","    var_size = np_data.shape[1]\n","\n","    # build dictionary and populate\n","    count_d = dict()\n","    if len(parents) < 1:\n","        a = 1\n","\n","    if parents == []:\n","        sigma_sq = np.var(np_data[:, target]) ** 2\n","        mu = np.mean(np_data[:, target])\n","        loglik = - sample_size / 2 * np.log(2 * np.pi) - sample_size * np.log(np.sqrt(sigma_sq)) \\\n","                 - 1 / (2 * sigma_sq) * np.dot(\n","                (np_data[:, target] - mu), \\\n","                (np_data[:, target] - mu))\n","\n","    else:\n","        reg = LinearRegression().fit(np_data[:,parents], np_data[:,target])\n","        w, w_0 = reg.coef_, reg.intercept_\n","        sigma_sq = 1/ sample_size * (\n","                np.dot((np_data[:, target] - (w_0 + np.dot(np_data[:, parents], w))),(np_data[:, target] - (w_0 + np.dot(np_data[:, parents], w))))\n","                )\n","        loglik = - sample_size / 2 * np.log(2 * np.pi) - sample_size * np.log(np.sqrt(sigma_sq)) \\\n","                 - 1 / (2 * sigma_sq) * np.dot(\n","            (np_data[:, target] - (w_0 + np.dot(np_data[:, parents], w))), \\\n","            (np_data[:, target] - (w_0 + np.dot(np_data[:, parents], w))))\n","\n","    if sigma_sq == 0:\n","        print('error in sigma')\n","\n","    # compute likelihood\n","\n","\n","    # penality\n","    num_param = np.size(parents) + 2  # count_faster(count_d) - len(count_d) - 1 # minus top level and minus one\n","    bic = loglik - 0.5 * math.log(sample_size) * num_param\n","\n","    return bic\n","\n","\n","def compute_local_BiCScore(np_data, target, parents):\n","    # use dictionary\n","    sample_size = np_data.shape[0]\n","    var_size = np_data.shape[1]\n","\n","    # build dictionary and populate\n","    count_d = dict()\n","    if len(parents) < 1:\n","        a = 1\n","\n","    # unique_rows = np.unique(self.np_data, axis=0)\n","    # for data_ind in range(unique_rows.shape[0]):\n","    #     parent_combination = tuple(unique_rows[data_ind,:].reshape(1,-1)[0])\n","    #     count_d[parent_combination] = dict()\n","    #\n","    #     # build children\n","    #     self_value = tuple(self.np_data[data_ind, target].reshape(1,-1)[0])\n","    #     if parent_combination in count_d:\n","    #         if self_value in count_d[parent_combination]:\n","    #             count_d[parent_combination][self_value] += 1.0\n","    #         else:\n","    #             count_d[parent_combination][self_value] = 1.0\n","    #     else:\n","    #         count_d[parent_combination] = dict()\n","    #         count_d\n","\n","    # slower implementation\n","    for data_ind in range(sample_size):\n","        parent_combination = tuple(np_data[data_ind, parents].reshape(1, -1)[0])\n","        self_value = tuple(np_data[data_ind, target].reshape(1, -1)[0])\n","        if parent_combination in count_d:\n","            if self_value in count_d[parent_combination]:\n","                count_d[parent_combination][self_value] += 1.0\n","            else:\n","                count_d[parent_combination][self_value] = 1.0\n","        else:\n","            count_d[parent_combination] = dict()\n","            count_d[parent_combination][self_value] = 1.0\n","\n","    # compute likelihood\n","    loglik = 0.0\n","    # for data_ind in range(sample_size):\n","    # if len(parents) > 0:\n","    num_parent_state = np.prod(np.amax(np_data[:, parents], axis=0) + 1)\n","    # else:\n","    #    num_parent_state = 0\n","    num_self_state = np.amax(np_data[:, target], axis=0) + 1\n","\n","    for parents_state in count_d:\n","        local_count = sum(count_d[parents_state].values())\n","        for self_state in count_d[parents_state]:\n","            loglik += count_d[parents_state][self_state] * (\n","                        math.log(count_d[parents_state][self_state] + 0.1) - math.log(local_count))\n","\n","    # penality\n","    num_param = num_parent_state * (\n","                num_self_state - 1)  # count_faster(count_d) - len(count_d) - 1 # minus top level and minus one\n","    bic = loglik - 0.5 * math.log(sample_size) * num_param\n","\n","    return bic\n","\n","#############\n","#latent variable graph\n","def compute_BiC_c_comps_sets(D, c_components, parent_sets, bidirect_tuple):\n","    '''compute the bic score'''\n","    # TODO fix this\n","    nVars = D.shape[1]\n","    nSamples = D.shape[0]\n","\n","    # find all c components in graph\n","    # c_components, sizes, members = find_c_components(G)\n","    isParent = np.zeros(nVars)\n","\n","    scores = np.zeros( (1, len(c_components)))\n","\n","    covMat = np.cov(D.T)\n","    tol = 10e-2\n","\n","    # for iComp in c_components:\n","        # vars = c_components[iComp]\n","\n","        # convert to mag\n","    [compMag, district, parents] = find_componenet_mag_sets(c_components, nVars, parent_sets, bidirect_tuple)\n","\n","    district = np.where(district)[0] # list(set(c_components) - set(parent_sets)) + list(set(parent_sets))\n","    # scores(iComp) = logdet(2 * pi * covMat(district, district)) + (nSamples - 1) / nSamples;\n","    scores = compute_local_BiC_comp_sets(compMag, c_components, district, len(c_components), covMat, nSamples, tol)\n","\n","    # score_one = compute_local_BiC_c_component(D, iComp, vars)\n","    # origin_score.append(score_one)\n","\n","    score = np.sum(scores)\n","\n","    return score\n","\n","def compute_local_BiC_comp_sets(compMag, component, district, compSize, CovMat, nSamples,  tol):\n","\n","    if district.size == 1:\n","        comCovMat = CovMat[district, district]\n","        sign, logdet = 1, np.log(2 * math.pi * comCovMat) #  np.linalg.slogdet(2 * math.pi * comCovMat)\n","        sc = sign * logdet + (nSamples - 1) / nSamples\n","    else:\n","        nVar = CovMat.shape[0]\n","        curCovMat = CovMat[np.ix_(district, district)]\n","        compMag = compMag[np.ix_(district, district)]\n","        _, _, curHatCovMat, _ = RICF_fit(compMag, curCovMat, tol)\n","\n","        remParents = np.zeros(nVar)\n","        remParents[district] = 1\n","        remParents[list(component)] = 0\n","        parInds = np.where(remParents[district].astype(int))[0]\n","\n","        sign, logdet = np.linalg.slogdet(curHatCovMat)\n","        logdet_signed = sign* logdet\n","        if np.sum(remParents) > 0:\n","            l1 = compSize * math.log(2 * math.pi)\n","            l2 = logdet_signed - math.log(np.prod(np.diag(curHatCovMat[np.ix_(parInds, parInds)])))\n","            l3 = (nSamples - 1) / nSamples * (np.trace( matrix_division_left(curHatCovMat,curCovMat)) - np.sum(remParents))\n","            sc = l1 + l2 +l3\n","        else:\n","            l1 = compSize * math.log(2 * math.pi)\n","            l2 = logdet_signed\n","            l3 = (nSamples - 1) / nSamples * np.trace(matrix_division_left(curHatCovMat,curCovMat))\n","            sc = l1 + l2 + l3\n","\n","    # complexity\n","    # nsf = -nSamples / 2\n","    # curScore = -2 * tmpSll + log(nSamples) * (nVars + nEdges)\n","\n","    nVars  = np.size(component)\n","    # nEdges = 0\n","    nEdges = np.where(compMag)[0].size/2\n","    bp = math.log(nSamples)/2 * (2 * nVars + nEdges)\n","    sc = - sc * nSamples/2 - bp\n","\n","    return sc\n","\n","\n","def find_componenet_mag_sets(component, nVars, parent_sets, bidirect_tuple):\n","    compMag = np.zeros((nVars,nVars))\n","    if len(component) > 1:  # fix this for more than size 2, per edges\n","        # compMag[component[0], component[1]] =  2 # assume 1 here - mag[component, component]\n","        # compMag[component[1], component[0]] = 2\n","        for edge_ind, (parent, child) in enumerate(bidirect_tuple):\n","            compMag[parent, child] = 2\n","            compMag[child, parent] = 2\n","\n","    district, parents = np.zeros(( nVars,)), np.zeros((nVars,))\n","    district[list(component)] = True\n","    for index, iVar in enumerate(component):\n","        iParents = list(parent_sets[index]) #isParent[:, iVar]\n","        compMag[iParents, iVar] = 2\n","        compMag[iVar, iParents] = 3\n","        district[iParents] = True\n","        parents[iParents] = True\n","\n","    return compMag, district, parents\n","\n","def compute_BiC_c_component(G, D):\n","    '''compute the bic score'''\n","    # score = gm.estimators.BicScore(self.data).score(self.model)\n","    origin_score = []\n","    nVars = G.shape[0]\n","    nSamples = D.size()[0]\n","\n","    # find all c components in graph\n","    c_components, sizes, members = find_c_components(G)\n","    isParent = np.zeros(nVars)\n","\n","    scores = np.zeros( (1, len(c_components)))\n","\n","    covMat = np.cov(D.T)\n","    tol = 10e-3\n","\n","    for iComp in c_components:\n","        vars = c_components[iComp]\n","\n","        # convert to mag\n","        [compMag, district] = find_componenet_mag(vars, nVars, G, isParent)\n","        # scores(iComp) = logdet(2 * pi * covMat(district, district)) + (nSamples - 1) / nSamples;\n","        scores[iComp] = compute_local_BiC_c_component(compMag, vars, district, sizes(iComp), covMat, nSamples, tol)\n","\n","        # score_one = compute_local_BiC_c_component(D, iComp, vars)\n","        # origin_score.append(score_one)\n","\n","    score = sum(scores)\n","\n","    return score\n","\n","def find_componenet_mag(component, nVars, mag, isParent):\n","    compMag = np.zeros((nVars,nVars))\n","    compMag[component, component] = mag[component, component]\n","    district, parents = np.zeros(nVars), np.zeros( nVars)\n","    district[component] = True\n","    for iVar in component:\n","        iParents = isParent[:, iVar]\n","        compMag[iParents, iVar] = 2\n","        compMag[iVar, iParents] = 3\n","        district[iParents] = True\n","        parents[iParents] = True\n","\n","    return compMag, district, parents\n","\n","def find_c_components(A):\n","    #\n","    # Number of nodes\n","    N = A.size()[0] # size(A, 1)\n","    # Remove diagonals\n","    for i in range(N):\n","        A[i, i] = 0 # A(1: N + 1:end) = 0\n","    # make symmetric, just in case i isn't\n","    A = A + np.transpose(A)\n","    # Have we visited a particular node yet?\n","    isDiscovered = np.zeros(N)\n","    inComponent = np.zeros( N)\n","    # Empty members cell\n","    members = dict.fromkeys(range(N))\n","    # check every node\n","    for n in range(N):\n","        if ~isDiscovered[n]:\n","            # started a new group so add  it to  members\n","            members[n]= n\n","            inComponent[n] = n # members[n]  # size(members, 2)\n","            # account for discovering n\n","            isDiscovered[n] = 1\n","            # set the ptr to 1\n","            ptr = 0\n","            while (ptr < len(members[n])):\n","                # find neighbors\n","                nbrs = A[:, members[n][ptr]] # np.where(A[:, members[n][ptr]])\n","                # here are the neighbors that are undiscovered\n","                newNbrs = nbrs[isDiscovered[nbrs] == 0]\n","                # we can now mark them as discovered\n","                isDiscovered[newNbrs] = 1\n","                # add them to member list\n","                members[n][n + 1: n + len(newNbrs)] = newNbrs\n","                inComponent[nbrs] = n # size(members, 2)\n","                # increment ptr so  we check the next member of this component\n","                ptr = ptr + 1\n","\n","    # number of  components\n","    nComponents = len(members)\n","    sizes = np.zeros(nComponents)\n","    for n in range(nComponents):\n","        # compute sizes of components\n","        sizes[n] = len(members[n])\n","\n","    #[sizes, idx] = sort(sizes, 'descend');\n","    # members = members(idx);\n","\n","\n","    return nComponents, sizes, members\n","\n","def compute_local_BiC_c_component(compMag, component, district, compSize, covMat, nSamples,  tol):\n","\n","    if sum(district) == 1:\n","        sc = np.linalg.slogdet(2 * math.pi * covMat[district, district]) + (nSamples - 1) / nSamples\n","    else:\n","        curCovMat = covMat[district, district]\n","        compMag = compMag[district, district]\n","        _, _, curHatCovMat, _ = RICF_fit(compMag, curCovMat, tol)\n","        remParents = district\n","        remParents[component] = False\n","        parInds = remParents[district]\n","\n","        sign, logdet = np.linalg.slogdet(curHatCovMat)\n","        logdet_signed = sign* np.exp(logdet)\n","        if any(remParents):\n","            l1 = compSize * math.log(2 * math.pi)\n","            l2 = logdet_signed - math.log(np.prod(np.diag(curHatCovMat[parInds, parInds])))\n","            l3 = (nSamples - 1) / nSamples * (np.trace( matrix_division_left(curHatCovMat,curCovMat) - np.sum(remParents)))\n","            sc = l1 + l2 +l3\n","        else:\n","            l1 = compSize * math.log(2 * math.pi)\n","            l2 = logdet_signed\n","            l3 = (nSamples - 1) / nSamples * np.trace(matrix_division_left(curHatCovMat,curCovMat))\n","            sc = l1 + l2 + l3\n","\n","    return sc\n","\n","def compute_local_BiC_c_component_node(compMag, component, district, compSize, covMat, nSamples,  tol):\n","\n","    if sum(district) == 1:\n","        sc = np.linalg.slogdet(2 * math.pi * covMat[district, district]) + (nSamples - 1) / nSamples\n","    else:\n","        curCovMat = covMat[district, district]\n","        compMag = compMag[district, district]\n","        _, _, curHatCovMat, _ = RICF_fit(compMag, curCovMat, tol)\n","        remParents = district\n","        remParents[component] = False\n","        parInds = remParents[district]\n","\n","        sign, logdet = np.linalg.slogdet(curHatCovMat)\n","        logdet_signed = sign* np.exp(logdet)\n","        if any(remParents):\n","            l1 = compSize * math.log(2 * math.pi)\n","            l2 = logdet_signed - math.log(np.prod(np.diag(curHatCovMat[parInds, parInds])))\n","            l3 = (nSamples - 1) / nSamples * (np.trace( matrix_division_left(curHatCovMat,curCovMat) - np.sum(remParents)))\n","            sc = l1 + l2 +l3\n","        else:\n","            l1 = compSize * math.log(2 * math.pi)\n","            l2 = logdet_signed\n","            l3 = (nSamples - 1) / nSamples * np.trace(matrix_division_left(curHatCovMat,curCovMat))\n","            sc = l1 + l2 + l3\n","\n","    return sc\n","\n","def RICF_fit(smm, covMat, tol):\n","\n","    # % if any(eig(covMat)<= 0);\n","    # %     errprintf('Covariance matrix is not positive definite\\n')\n","    # % end\n","    if (smm==4).any():\n","        sys.exit('Graph includes bows\\n')\n","\n","    # a=0; b=0; c=0; d=0; e=0;\n","\n","    nVars = covMat.shape[1]\n","    dg = np.multiply(smm == 2, smm.T == 3)\n","    bg = np.multiply(smm == 2, smm.T == 2)\n","    # %\n","    # % dg = (smm ==2 & smm'==3) | (smm==2 & smm'==4);\n","    # % bg = (smm ==2 & smm'==4) | (smm==2 & smm'==2) | (smm==4 & smm'==2);\n","\n","    # starting values\n","    omega = np.diag(np.diag(covMat),0)\n","    beta = np.eye(nVars)\n","\n","    # list of parents, spouses etc\n","    par, sp = np.zeros((nVars, nVars)), np.zeros((nVars, nVars)) #deal(false(nVars));\n","    for iVar in range(nVars):\n","        par[iVar, dg[:, iVar]] = True\n","        sp[iVar, bg[:, iVar]] = True\n","    iter=0\n","\n","    ricf = {}\n","    while True:\n","        iter = iter+1\n","        ricf[iter] = {}\n","        ricf[iter]['omega'] = omega.copy()\n","        ricf[iter]['beta'] = beta.copy()\n","\n","        omega = omega.copy()\n","        beta = beta.copy()\n","        # for each variable\n","        for iVar in range(nVars):\n","\n","           vcomp = list(range(0,iVar)) + list(range(iVar+1, nVars))\n","           iPar= np.where(par[iVar,:])[0]\n","           iSp = np.where(sp[iVar, :])[0]\n","\n","           if iSp.size == 0:\n","               if iPar.size > 0:\n","                   if iter==1:\n","                       if len(vcomp) == 1:\n","                           inv_mat = 1 /  (covMat[iPar, iPar])\n","                       else:\n","                           inv_mat =   np.linalg.inv(covMat[np.ix_(iPar, iPar)])\n","                       beta[iVar, iPar] = np.matmul(-covMat[iVar, iPar],inv_mat) # TODO check this\n","                       omega[iVar, iVar] = covMat[iVar, iVar] + np.matmul(beta[iVar, iPar],covMat[iPar, iVar])\n","\n","           elif iPar.size > 0: # spouses and parents\n","               oInv = np.zeros((nVars, nVars))\n","               if len(vcomp) == 1:\n","                   oInv[vcomp, vcomp] = 1 / oInv[vcomp, vcomp]\n","               else:\n","                   oInv[np.ix_(vcomp, vcomp)] = np.linalg.inv(omega[np.ix_(vcomp, vcomp)]) #; %\\Omega_{-i, -i}^-1\n","               Z = np.matmul(oInv[np.ix_(iSp, vcomp)], beta[vcomp, :])\n","               if Z.ndim == 1:\n","                   Z = Z.reshape(1, -1)\n","               nPar = iPar.size\n","               nSp = iSp.size\n","               range1 = list(range(nPar))\n","               range2= list(range(nPar, nPar+nSp))\n","               # % XX\n","               XX = np.zeros( (nPar+nSp,(nPar+nSp)) )\n","               XX[:] = np.nan\n","               #% Upper left quadrant\n","               XX[np.ix_(range1, range1)] = covMat[np.ix_(iPar, iPar)]\n","               #% Upper right quadrant\n","               XX[np.ix_(range1, range2)] = np.matmul(covMat[iPar, :], Z.T)\n","               #% Lower left quadrant\n","               XX[np.ix_(range2, range1)] = XX[np.ix_(range(nPar), range(nPar,nPar+nSp))].T\n","               #% Lower right quadrant\n","               XX[np.ix_(range2, range2)] = np.matmul(np.matmul(Z,covMat),Z.T)\n","               #% YX <- c(S[v,parv], S[v,]%*%t(Z))\n","               #% temp <- YX %*% solve(XX)\n","               YX = np.hstack((covMat[iVar, iPar].reshape(1,-1), np.array([np.matmul(covMat[iVar, :],Z.T)]).reshape(1,-1)\n","                                    )).reshape((-1,1))\n","               # YX = np.array( [covMat[iVar, iPar], np.matmul(covMat[iVar, :], Z.T)]) #.T\n","\n","               if YX.size == 1:\n","                    temp = YX / XX\n","                    beta[iVar, iPar] = -temp[range1]\n","                    omega[iVar, iSp] = temp[range2]\n","                    omega[iSp, iVar] = omega[iVar, iSp]\n","                    tempVar = covMat[iVar, iVar] - temp * YX\n","                    omega[iVar, iVar] = tempVar + np.matmul(omega[iVar, iSp]/ omega[np.ix_(iSp, iSp)] \\\n","                                                            , omega[iSp, iVar])\n","               else:\n","                   temp = matrix_division_right(YX.T, XX) #np.lin.solve(YX.dot(YX.T), YX).dot(XX)  # YX.T/XX # TODO check\n","                   # % update beta, omega\n","                   beta[iVar, iPar] = -temp[0,range1]\n","                   omega[iVar, iSp] = temp[0, range2]\n","                   omega[iSp, iVar] = omega[iVar, iSp]\n","\n","                   tempVar = covMat[iVar, iVar] - np.matmul(temp, YX)\n","\n","                   if iSp.size == 1:\n","                       omega[iVar, iVar] = tempVar + omega[iVar, iSp]/ omega[np.ix_(iSp, iSp)] * omega[iSp, iVar]\n","                   else:\n","                        omega[iVar, iVar] = tempVar + np.matmul(matrix_division_right(omega[iVar, iSp], omega[np.ix_(iSp, iSp)])\\\n","                                       ,omega[iSp, iVar])\n","\n","           else:\n","               oInv = np.zeros((nVars, nVars))\n","               if len(vcomp) == 1:\n","                    oInv[vcomp, vcomp] = 1/omega[vcomp, vcomp]\n","               else:\n","                    oInv[np.ix_(vcomp, vcomp)] = np.linalg.inv(omega[ np.ix_(vcomp, vcomp)]) # %\\Omega_{-i, -i}^-1\n","               Z = np.matmul(oInv[np.ix_(iSp, vcomp)],beta[vcomp, :])\n","               XX = np.matmul( np.matmul(Z,covMat), Z.T)\n","               YX = np.matmul(covMat[iVar, :], Z.T).T\n","\n","               if YX.size== 1:\n","                   omega[iVar, iSp] =  YX / XX\n","                   omega[iSp, iVar] = omega[iVar, iSp]\n","                   tempVar = covMat[iVar, iVar] -  omega[[iVar],[iSp]] * YX\n","                             # omega[iVar, iSp] * YX\n","                   omega[iVar, iVar] = tempVar + \\\n","                                       np.matmul(np.matmul(omega[[iVar], [iSp]], oInv[np.ix_(iSp,iSp)]), omega[iSp, [iVar]])\n","                                       # omega[iVar, iSp] * oInv[iSp, iSp] * omega[iSp, iVar]\n","\n","               else:\n","                   omega[iVar, iSp] =  matrix_division_right(YX.T, XX) # YX'/XX;\n","                   omega[iSp, iVar] = omega[iVar, iSp]\n","                   tempVar = covMat[iVar, iVar] - np.matmul(omega[iVar,iSp],YX)\n","                   omega[iVar, iVar] = tempVar+ \\\n","                                       np.matmul(np.matmul(omega[iVar, iSp],oInv[np.ix_(iSp,iSp)]),omega[iSp, iVar])\n","\n","        if (sum(sum(abs(ricf[iter]['omega']-omega))) + sum(sum(abs(ricf[iter]['beta']-beta))) < tol):\n","           break\n","\n","        elif iter>50:\n","           print('RICF fit did not converge')\n","           break\n","\n","    # %    if iter>20\n","    # %        display('20')\n","    # %        iter;\n","    # %    end\n","    hatCovMat = np.matmul( np.matmul(np.linalg.inv(beta), omega), np.linalg.inv(beta.T))\n","    # % load('maria.mat')\n","    # % kk = vertcat(kk,[a b c d e]);\n","    # % [a b c d]\n","    # % save maria.mat kk\n","\n","    return beta, omega, hatCovMat, ricf\n","\n","def matrix_division_right(YX, XX):\n","    # solve for YX/XX or x XX = YX\n","\n","    x = np.matmul(np.matmul(YX, XX.T), np.linalg.inv(np.matmul(XX, XX.T)))\n","\n","    return x\n","\n","\n","def matrix_division_left(B, b):\n","    # solves for B\\b or Bx = b\n","    x, resid, rank, s = np.linalg.lstsq(B,b)\n","\n","    # x = np.matmul(np.matmul(YX, XX.T), np.linalg.inv(np.matmul(XX, XX.T)))\n","\n","    return x\n","\n","\n","def score_write_to_file(scores, file_name):\n","    # write scores to find\n","    with open(file_name, 'wb') as handle:\n","        pickle.dump(scores, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","    return\n","\n","def check_connected_component(set, node_ids):\n","    # set is a list of tuples, which consists a tuple of edge tupule\n","    new_set = []\n","\n","    # single set\n","    if len(set)  < 2:\n","        return set\n","\n","    for edge_lists in set:\n","        # check connected\n","        flag = True\n","        for node in node_ids:\n","            if not (any(node in i for i in edge_lists)):\n","                flag = False\n","        if flag:\n","            new_set.append(edge_lists)\n","\n","    return new_set\n","\n","def find_bi_connected_node(iVar, comp_edges):\n","    # find nodes that bi-direct connect to iVar in comp edges\n","\n","    nodes = []\n","\n","    if len(comp_edges)  < 2:\n","        return nodes\n","\n","    for edge_lists in comp_edges:\n","        if iVar in  edge_lists:\n","            bi_node = set( list(edge_lists)) - set([iVar])\n","            nodes.append( list(bi_node)[0])\n","\n","    return nodes\n","\n","def has_cycle_in_c_comp(parent_set_config, vars_in_comp):\n","    # check if parent set has a directed cycle of length 2 only inside a c-comp\n","    num_var_parent = len(parent_set_config)\n","    vars_in_comp_list = list(vars_in_comp)\n","    flag = False\n","\n","    for index_var, iVar in enumerate(vars_in_comp_list): # range(num_var):\n","        iParents = list(parent_set_config[index_var])\n","        for each_parent in iParents:\n","            if each_parent in vars_in_comp_list:\n","                each_parent_index = vars_in_comp_list.index(each_parent)\n","                # if num_var_parent > each_parent:  # has data for that parent\n","                par_parents = list(parent_set_config[each_parent_index])\n","                if iVar in par_parents:\n","                    flag = True\n","                    break\n","\n","        if flag == True:\n","            break\n","\n","    return flag"],"metadata":{"id":"RaW66_H0QVMu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XQZ0to--W_8h"},"source":["# Generate Data"]},{"cell_type":"markdown","metadata":{"id":"hiKVO-arKQDB"},"source":["## Generate_Random_Bowfree"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PpiH_kvjKQMD"},"outputs":[],"source":["import random\n","import numpy as np\n","import networkx as nx\n","\n","def generate_random_bow_free_graph(nnodes, pdir, pbidir):\n","\n","    D = [[0]*nnodes for i in range(nnodes)]\n","    B = [[0]*nnodes for i in range(nnodes)]\n","\n","    for i in range(nnodes-1):\n","        for j in range(i+1, nnodes):\n","            if random.random() < pdir:\n","                D[i][j] = 1\n","            elif random.random() < pbidir:\n","                B[i][j] = 1\n","                B[j][i] = 1\n","\n","    return np.array(D), np.array(B)"]},{"cell_type":"markdown","metadata":{"id":"rZnigK00JOxM"},"source":["## Simulate_SEM_Multivariate_Gaussian"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_7mcNsIc7MYZ"},"outputs":[],"source":["def simulate_sem_multivariate_gaussian(\n","        D,\n","        B,\n","        n: int) -> np.ndarray:\n","\n","    G = nx.DiGraph(np.array(D))\n","    W = nx.to_numpy_array(G)\n","    d = W.shape[0]\n","    x_dims = 1\n","    X = np.zeros([n, d, x_dims])\n","    ordered_vertices = list(nx.topological_sort(G))\n","    assert len(ordered_vertices) == d\n","    delta = np.zeros([d, d])\n","    beta = np.zeros([d, d])\n","    # graph_bhattacharya_fig1c.txt: delta[i][j] in [-2.0,-0.5] union [0.5,2.0]\n","    # graph_6nodes.txt: delta[i][j] in [-0.5,-0.2] union [0.2,0.5]\n","    low = 0.5 #0.2\n","    #    low = 0.1\n","    high = 2.0 #0.5\n","    #    high = 0.5\n","    #    high = 0.9 # this is an attempt to lower the values of delta\n","    #    low = 0.4\n","    #    high = 0.8\n","    diff = high-low\n","    for i in range(d):\n","        for j in range(d):\n","            if D[i][j] > 0:\n","                delta[i][j] = np.random.uniform(-diff, diff)\n","                if delta[i][j] < 0.0:\n","                    delta[i][j] -= low\n","                else:\n","                    delta[i][j] += low\n","    # sample_bhattacharya_fig1c.txt: beta[i][j] in [-0.7,-0.4] union [0.4,0.7]\n","    # graph_6nodes.txt: beta[i][j]=0.0\n","    low = 1.0 #0.4\n","    high = 2.0 #0.7\n","    #    low = 0.2\n","    #    high = 0.6\n","    diff = high-low\n","    #    \"\"\"\n","    for i in range(d-1):\n","        for j in range(i+1, d):\n","            if B[i][j] > 0:\n","                beta[i][j] = np.random.uniform(-diff, diff)\n","                if beta[i][j] < 0.0:\n","                    beta[i][j] -= low\n","                else:\n","                    beta[i][j] += low\n","                beta[j][i] = beta[i][j]\n","    #    \"\"\"\n","    # beta[i][j] in [-1.2,-0.7] union [0.7,1.2] minus or plus sum(beta[i][j]) where j != i\n","    # sample_bhattacharya_fig1c.txt: beta[i][i] in [0.7,1.2]\n","    # graph_6nodes.txt: beta[i][i] in [0.1,0.4]\n","    low = 0.7 #0.1\n","    high = 1.2 #0.4\n","    #    low = 0.6 #0.1\n","    #    high = 0.9 #0.4\n","    #    diff = high-low\n","    for i in range(d):\n","        sum = 0.0\n","        for j in range(d):\n","            if i != j:\n","                sum += abs(beta[i][j])\n","        #        beta[i][i] = np.random.uniform(-diff, diff)\n","        beta[i][i] = np.random.uniform(low, high)\n","        # --------------------------------\n","        # this part ensures that beta[i][i] > sum but not by much\n","        \"\"\"\n","        if abs(beta[i][i]) + low > sum:\n","            sum = 0.0\n","        else:\n","            temp1 = 1.01 * sum\n","            temp2 = sum + abs(beta[i][i]) + low\n","            temp = min(temp1, temp2)\n","            sum = temp - abs(beta[i][i]) - low\n","        \"\"\"\n","        # --------------------------------\n","        if beta[i][i] < 0.0:\n","            beta[i][i] -= (low + sum)\n","        else:\n","            beta[i][i] += (low + sum)\n","    # sample multivariate normal distribution (each column corresponds to the samples of epsilon_i)\n","    epsilon = np.random.multivariate_normal([0]*d,beta,n)\n","    for j in ordered_vertices:\n","        parents = list(G.predecessors(j))\n","        eta = X[:, parents, 0].dot(delta[parents, j])\n","        X[:, j, 0] = eta + epsilon[:,j]\n","\n","    #    return X\n","    return X, delta, beta\n"]},{"cell_type":"markdown","metadata":{"id":"aFKoEFxxKpeH"},"source":["## Generate_Graph_and_Samples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R_2DsCJDKpmc"},"outputs":[],"source":["def generate_graph_and_samples(nnodes, pdir, pbidir, sample_size):\n","    graph_d, graph_b = generate_random_bow_free_graph(nnodes, pdir, pbidir)\n","    tabu_edges = []\n","    for i in range(graph_b.shape[0]):\n","        for j in range(graph_b.shape[1]):\n","            if graph_b[i][j] > 0:\n","                tabu_edges.append((i, j))\n","    data, delta, beta = simulate_sem_multivariate_gaussian(graph_d, graph_b , sample_size)\n","    data = data[:,:,0]\n","    return graph_d, graph_b, tabu_edges, data\n"]},{"cell_type":"markdown","source":["## IP_ADMG-generate"],"metadata":{"id":"xDnWg3RGOvm3"}},{"cell_type":"code","source":["# test latent\n","\n","#\n","# import bnlearn\n","#\n","# df = bnlearn.import_example()\n","#\n","# model = bnlearn.structure_learning.fit(df)\n","#\n","# G = bnlearn.plot(model)\n","\n","from pgmpy.factors.discrete import State\n","from pgmpy.models.BayesianModel import BayesianModel\n","from pgmpy.sampling import BayesianModelSampling\n","from pgmpy.factors.discrete import TabularCPD\n","#from pgmpy.estimators import K2Score, BdeuScore, BicScore\n","import pandas as pd\n","import numpy as np\n","from scipy.special import comb\n","# from utils import compute_local_BiCScore, simulate_sem, compute_local_BiCScore_gauss, \\\n","#    compute_BiC_c_component, score_write_to_file, compute_BiC_c_comps_sets, check_connected_component,\\\n","#    find_bi_connected_node, has_cycle_in_c_comp\n","import networkx as nx\n","import itertools\n","import pickle\n","\n","def build_5_var():\n","    model = BayesianModel([('D', 'A'), ('C', 'A'), ('C','B'), ('E','B')\n","                           ])\n","    cpd_d = TabularCPD('D', 2, [[0.1], [0.9]])\n","    cpd_e = TabularCPD('E', 2, [[0.15], [0.85]])\n","    cpd_c = TabularCPD('C', 2, [[0.3], [0.7]])\n","    cpd_a = TabularCPD('A', 2, [[0.3, 0.25, 0.6, 0.7], [0.7, 0.75, 0.4, 0.3]],\n","                       ['C', 'D'], [2, 2])\n","\n","    cpd_b = TabularCPD('B', 2, [[0.6, 0.75, 0.2, 0.7], [0.4, 0.25, 0.8, 0.3]],\n","                       ['C', 'E'], [2, 2])\n","\n","    # model = BayesianModel([(4, 1), (3, 1), (3, 2), (5, 2)\n","    #                        ])\n","    # cpd_d = TabularCPD(4, 2, [[0.8], [0.2]])\n","    # cpd_e = TabularCPD(5, 2, [[0.15], [0.85]])\n","    # cpd_c = TabularCPD(3, 2, [[0.7], [0.3]])\n","    # cpd_a = TabularCPD(1, 2, [[0.3, 0.25, 0.9, 0.55], [0.7, 0.75, 0.1, 0.45]],\n","    #                    [3, 4], [2, 2])\n","    #\n","    # cpd_b = TabularCPD(2, 2, [[0.6, 0.75, 0.2, 0.7], [0.4, 0.25, 0.8, 0.3]],\n","    #                    [3, 5], [2, 2])\n","\n","    model.add_cpds( cpd_a, cpd_b, cpd_c, cpd_d, cpd_e)\n","    return model\n","\n","def main_gaus():\n","\n","    # W = [[0, 0, 0, 0, 0],\n","    #      [0, 0, 0, 0, 0],\n","    #      [1, 1, 0, 0, 0],\n","    #      [1, 0, 0, 0, 0],\n","    #      [0, 1, 0, 0, 0]]\n","    G = nx.DiGraph()\n","    G.add_edges_from([(3, 0), (2, 0), (2, 1), (4, 1)])\n","\n","    sample_size = 100000\n","    data = simulate_sem(G, sample_size, 1, 'linear-gauss')\n","    data = data[:,:,0]\n","\n","    latent_model_score = compute_local_BiCScore_gauss(data, 0, [2, 3]) + \\\n","                         compute_local_BiCScore_gauss(data, 1, [2, 4]) + \\\n","                         compute_local_BiCScore_gauss(data, 3, []) + \\\n","                         compute_local_BiCScore_gauss(data, 4, []) + \\\n","                         compute_local_BiCScore_gauss(data, 2, [])\n","    print('Full self check  ground truth DAG score', latent_model_score)\n","\n","    # latent_model_score = BicScore(values).local_score('A', ['D']) + \\\n","    #                      BicScore(values).local_score('B', ['E']) + \\\n","    #                      BicScore(values).local_score('D', []) + \\\n","    #                      BicScore(values).local_score('E', []) + \\\n","    #                      BicScore(values).local_score('C', [])\n","    # print('dag  without A-B edge  BIC', latent_model_score)\n","\n","    latent_model_score = compute_local_BiCScore_gauss(data, 0, [3]) + \\\n","                         compute_local_BiCScore_gauss(data, 1, [4]) + \\\n","                         compute_local_BiCScore_gauss(data, 3, []) + \\\n","                         compute_local_BiCScore_gauss(data, 4, []) + \\\n","                         compute_local_BiCScore_gauss(data, 2, [])\n","    print('Full self check dag  without A-B edge  BIC', latent_model_score)\n","\n","    # latent_model_score = BicScore(values).local_score('A', ['D']) + \\\n","    #                      BicScore(values).local_score('B', []) + \\\n","    #                      BicScore(values).local_score('D', []) + \\\n","    #                      BicScore(values).local_score('E', []) + \\\n","    #                      BicScore(values).local_score('C',[])\n","    # print(' Full DAG  without A-B edge  and E-B BIC ', latent_model_score)\n","\n","    latent_model_score = compute_local_BiCScore_gauss(data, 0, [3]) + \\\n","                         compute_local_BiCScore_gauss(data, 1, []) + \\\n","                         compute_local_BiCScore_gauss(data, 3, []) + \\\n","                         compute_local_BiCScore_gauss(data, 4, []) + \\\n","                         compute_local_BiCScore_gauss(data, 2, [])\n","    print('Full self check dag with D-A only BIC', latent_model_score)\n","\n","    # latent_model_score = BicScore(values).local_score('A', []) + \\\n","    #                      BicScore(values).local_score('B', ['E']) + \\\n","    #                      BicScore(values).local_score('D', []) + \\\n","    #                      BicScore(values).local_score('E', []) + \\\n","    #                      BicScore(values).local_score('C', [])\n","    # print(' Full DAG  without A-B edge  and D-A BIC ', latent_model_score)\n","\n","    latent_model_score = compute_local_BiCScore_gauss(data, 0, []) + \\\n","                         compute_local_BiCScore_gauss(data, 1, [4]) + \\\n","                         compute_local_BiCScore_gauss(data, 3, []) + \\\n","                         compute_local_BiCScore_gauss(data, 4, []) + \\\n","                         compute_local_BiCScore_gauss(data, 2, [])\n","    print('Full self check dag with E-B only BIC', latent_model_score)\n","\n","    # latent_model_score = BicScore(values).local_score('A', []) + \\\n","    #                      BicScore(values).local_score('B', []) + \\\n","    #                      BicScore(values).local_score('D', []) + \\\n","    #                      BicScore(values).local_score('E', []) + \\\n","    #                      BicScore(values).local_score('C', [])\n","    # print(' Full empty graph  WITHOUT latent BIC D', latent_model_score)\n","\n","    latent_model_score = compute_local_BiCScore_gauss(data, 0, []) + \\\n","                         compute_local_BiCScore_gauss(data, 1, []) + \\\n","                         compute_local_BiCScore_gauss(data, 3, []) + \\\n","                         compute_local_BiCScore_gauss(data, 4, []) + \\\n","                         compute_local_BiCScore_gauss(data, 2, [])\n","    print('Full self check empty dag  BIC', latent_model_score)\n","\n","    # 4 variable\n","    # slice data into observed\n","\n","    # observed_data = values.loc[:, ['A', 'B', 'D', 'E']]\n","\n","    # score_function = BicScore(observed_data)\n","\n","    # latent_model_score = score_function.local_score('A', ['B', 'D', 'E']) + \\\n","    #                  score_function.local_score('B', ['E']) + \\\n","    #                  score_function.local_score('D', []) + \\\n","    #                  score_function.local_score('E', [])\n","    # print('DAG without C BIC model A ', latent_model_score)\n","    #\n","    # latent_model_score = score_function.local_score('A', ['D']) + \\\n","    #                      score_function.local_score('B', ['A', 'D', 'E']) + \\\n","    #                      score_function.local_score('D', []) + \\\n","    #                      score_function.local_score('E', [])\n","    # print('DAG  without C BIC model B', latent_model_score)\n","\n","    # latent_model_score =  BicScore(values).local_score('A', ['C','D']) + \\\n","    #                       BicScore(values).local_score('B', ['C','E']) + \\\n","    #                       BicScore(values).local_score('D', []) + \\\n","    #                       BicScore(values).local_score('E', [])\n","    # print('DAG  without A-B, given C,  edge  BIC', latent_model_score)\n","\n","    # -------- self compute check : compute_local_BiCScore\n","\n","    latent_model_score = compute_local_BiCScore_gauss(data, 0, [1, 3, 4]) + \\\n","                         compute_local_BiCScore_gauss(data, 1, [4]) + \\\n","                         compute_local_BiCScore_gauss(data, 3, []) + \\\n","                         compute_local_BiCScore_gauss(data, 4, [])\n","    print('4 self check DAG  best graph 1  BIC', latent_model_score)\n","\n","    latent_model_score = compute_local_BiCScore_gauss(data, 0, [1, 3, 4]) + \\\n","                         compute_local_BiCScore_gauss(data, 1, [0, 4]) + \\\n","                         compute_local_BiCScore_gauss(data, 3, []) + \\\n","                         compute_local_BiCScore_gauss(data, 4, [])\n","    print('4 self check DAG  best graph 1, +bidirected A-B,  BIC', latent_model_score)\n","\n","    latent_model_score = compute_local_BiCScore_gauss(data, 0, [3]) + \\\n","                         compute_local_BiCScore_gauss(data, 1, [0, 3, 4]) + \\\n","                         compute_local_BiCScore_gauss(data, 3, []) + \\\n","                         compute_local_BiCScore_gauss(data, 4, [])\n","    print('4 self check DAG  best graph 2  BIC', latent_model_score)\n","\n","    latent_model_score = compute_local_BiCScore_gauss(data, 0, [1, 3]) + \\\n","                         compute_local_BiCScore_gauss(data, 1, [0, 3, 4]) + \\\n","                         compute_local_BiCScore_gauss(data, 3, []) + \\\n","                         compute_local_BiCScore_gauss(data, 4, [])\n","    print('4 self check DAG  best graph 2, +bidirected A-B,  BIC', latent_model_score)\n","\n","    latent_model_score = compute_local_BiCScore_gauss(data, 0, [3]) + \\\n","                         compute_local_BiCScore_gauss(data, 1, [4]) + \\\n","                         compute_local_BiCScore_gauss(data, 3, []) + \\\n","                         compute_local_BiCScore_gauss(data, 4, [])\n","    print('4 self check DAG  without A-B, given C,  edge  BIC', latent_model_score)\n","\n","    # bidrected model score\n","    # bi_model_score = score_function.local_score('A', ['B', 'D']) +\\\n","    #                     score_function.local_score('B', ['A', 'E']) +\\\n","    #                     score_function.local_score('D', []) +\\\n","    #                     score_function.local_score('E', [])\n","    # print('bidrected sparse  graph BIC', bi_model_score)\n","\n","    latent_model_score = compute_local_BiCScore_gauss(data, 0, [1, 3]) + \\\n","                         compute_local_BiCScore_gauss(data, 1, [0, 4]) + \\\n","                         compute_local_BiCScore_gauss(data, 3, []) + \\\n","                         compute_local_BiCScore_gauss(data, 4, [])\n","    print('4 self sparse bidrected   BIC', latent_model_score)\n","\n","    latent_model_score = compute_local_BiCScore_gauss(data, 0, [1, 3, 4]) + \\\n","                         compute_local_BiCScore_gauss(data, 1, [0, 3, 4]) + \\\n","                         compute_local_BiCScore_gauss(data, 3, []) + \\\n","                         compute_local_BiCScore_gauss(data, 4, [])\n","    print('4 self dense bidrected   BIC', latent_model_score)\n","\n","    # bidrected model score\n","    # bi_model_score = score_function.local_score('A', ['B', 'D','E']) + \\\n","    #                  score_function.local_score('B', ['A', 'E', 'D']) + \\\n","    #                  score_function.local_score('D', []) + \\\n","    #                  score_function.local_score('E', [])\n","    # print('bidrected dense  graph BIC', bi_model_score)\n","    #\n","    # # bidrected model score\n","    # bi_model_score = score_function.local_score('A', ['B', 'D']) + \\\n","    #                  score_function.local_score('B', ['A', 'E']) + \\\n","    #                  score_function.local_score('D', []) + \\\n","    #                  score_function.local_score('E', [])\n","    # print('bidrected dense  graph BIC', bi_model_score)\n","\n","    # bic_local_score_a_bidirected =  score_function.local_score('A', ['B', 'D'])\n","    bic_local_score_a_bidirected = compute_local_BiCScore_gauss(data, 0, [1, 3])\n","\n","    # bic_local_score_a_dense = score_function.local_score('A', ['B', 'D', 'E'])\n","    bic_local_score_a_dense = compute_local_BiCScore_gauss(data, 0, [1, 3, 4])\n","\n","    # bic_local_score_b_bidirected = score_function.local_score('B', ['A', 'E'])\n","    bic_local_score_b_bidirected = compute_local_BiCScore_gauss(data, 1, [0, 4])\n","    # bic_local_score_b_dense = score_function.local_score('B', ['A', 'D', 'E'])\n","    bic_local_score_b_dense = compute_local_BiCScore_gauss(data, 1, [0, 3, 4])\n","\n","    print('bidirect edge with sparse connection:',\n","          bic_local_score_a_bidirected,\n","          bic_local_score_b_bidirected,\n","          bic_local_score_a_bidirected + bic_local_score_b_bidirected)\n","\n","    print('bidirect edge with dense connection :',\n","          bic_local_score_a_dense,\n","          bic_local_score_b_dense,\n","          bic_local_score_a_dense + bic_local_score_b_dense)\n","    # print(data)\n","\n","def main():\n","    dataset = '5_gauss'\n","    # dataset = 'data_1000_0.1_3_10_1.txt'\n","    sample_size = 1000\n","    file_name = 'synth_5_test_score_' + str(sample_size) + '.pkl'\n","\n","\n","    num_var = 5\n","    if dataset == '5_discrete':\n","        model = build_5_var()\n","        inference = BayesianModelSampling(model)\n","\n","\n","        data = inference.forward_sample(size=sample_size, return_type='recarray')\n","\n","        values = pd.DataFrame(data)\n","        data = values.to_numpy()\n","        is_discrete = True\n","\n","        # -------- self compute check : compute_local_BiCScore\n","        check_subgraph_scores(values)\n","\n","    elif dataset == '5_gauss':\n","        W = [[0, 0, 0, 0, 0],\n","             [0, 0, 0, 0, 0],\n","             [1, 1, 0, 0, 0],\n","             [1, 0, 0, 0, 0],\n","             [0, 1, 0, 0, 0]]\n","        G = nx.DiGraph(np.array(W))\n","        # sample_size = 1000\n","        data = simulate_sem(G, sample_size, 1, 'linear-gauss')\n","        is_discrete = False\n","        data = data[:,:,0]\n","\n","        # -------- self compute check : compute_local_BiCScore\n","        # check_subgraph_scores(data)\n","\n","        # visible\n","        observed_data = data[:, [0, 1, 3, 4]]\n","\n","    elif dataset == '5_exist':\n","        with open(file_name, 'rb') as f:\n","            data, old_scores = pickle.load(f)\n","\n","        # visible\n","        observed_data = data\n","\n","    elif dataset.endswith('.txt'):\n","        with open(dataset, 'rb') as f:\n","            data = np.loadtxt(f, skiprows=0)\n","\n","        # visible\n","        observed_data = data\n","\n","        # file_name\n","        file_name = 'score_' + dataset[:-4]\n","\n","    # k2_score = K2Score(values).score(model)\n","    # bic_score =  BicScore(values).score(model)\n","    # print('Full ground truth BIC', bic_score)\n","\n","    # check current learner results\n","    # latent_model_score = BicScore(values).local_score('A', ['C', 'D']) + \\\n","    #                      BicScore(values).local_score('B', ['C', 'E']) + \\\n","    #                      BicScore(values).local_score('D', []) + \\\n","    #                      BicScore(values).local_score('E', []) + \\\n","    #                      BicScore(values).local_score('C', [])\n","    # print('Self compute ground truth DAG   BIC', latent_model_score)\n","    c_size = 5\n","    single_parent_size = 3\n","    other_c_parent_size = 2\n","\n","    generate_scores_bidirect(observed_data,\n","                             single_c_parent_size = single_parent_size,\n","                             other_c_parent_size = other_c_parent_size,\n","                             c_size = c_size,\n","                             file_name = file_name)\n","\n","\n","def generate_scores_bidirect(data, single_c_parent_size, other_c_parent_size, c_size, file_name):\n","    # generate data for all bidirected scores\n","    # TODO change c-comp parent size\n","    num_sample, num_var = data.shape\n","\n","    # # generate all possible subgraphs, up to size k\n","    # graphs = gererate_all_bidirected_graphs(num_var, True)\n","\n","    # compute scores for each graph\n","    scores = {}\n","    # c_comps = {}\n","    # for iVar in range(num_var):\n","    all_c_components = gererate_all_c_components(num_var, c_size)\n","\n","    for iComp_size in all_c_components:\n","        c_comps_of_size = all_c_components[iComp_size]\n","        parent_size = single_c_parent_size if iComp_size < 2 else other_c_parent_size\n","        for each_comp in c_comps_of_size: # in a list\n","\n","            edges = gererate_all_bidirected_edges(each_comp)\n","            for each_edge_set in edges:\n","\n","                if iComp_size > 1:\n","                    # scores[each_comp]['bi_edges'] = [each_comp]\n","                    # dic_key = (each_comp, each_edge_set)\n","                    save_edge_set = each_edge_set\n","                else:\n","                    # scores[each_comp]['bi_edges'] = []\n","                    # dic_key = (each_comp, ())\n","                    save_edge_set = ()\n","\n","                dic_key = (each_comp, save_edge_set)\n","                scores[dic_key] = {}\n","\n","                parent_set_list = []\n","                for each_var_in_comp in each_comp:\n","                    # generate parental size\n","                    parent_set_list.append( gererate_all_parent_sets(each_var_in_comp,\n","                                                                     each_comp,\n","                                                                     num_var,\n","                                                                     parent_size,\n","                                                                     save_edge_set) )\n","\n","                # generate parent set combination\n","                all_parent_list = list(itertools.product(*parent_set_list))\n","\n","                # compute scores\n","                for each_parent_set_config in all_parent_list:\n","\n","                    # scores[dic_key][each_parent_set_config] = {}\n","\n","                    # remove certain condition:\n","                    # 1) a->b and a<-b\n","                    if not has_cycle_in_c_comp(each_parent_set_config, each_comp):\n","                    # list all potential bidirected edges\n","                        scores[dic_key][each_parent_set_config] = compute_BiC_c_comps_sets(data,\n","                                                                                            each_comp,\n","                                                                                            each_parent_set_config,\n","                                                                                           each_edge_set)\n","\n","    # save files\n","    print('saving file..\\n')\n","    file_name = './' + file_name # /synth_5_test_score.pkl'\n","    score_write_to_file([data, scores], file_name)\n","\n","    return\n","\n","def generate_scores_bidirect_m3hc(data, single_c_parent_size, other_c_parent_size, c_size, file_name,instance_name):\n","    # generate data for all bidirected scores\n","    # TODO change c-comp parent size\n","    num_sample, num_var = data.shape\n","\n","    # # generate all possible subgraphs, up to size k\n","    # graphs = gererate_all_bidirected_graphs(num_var, True)\n","\n","    # compute scores for each graph\n","    scores = {}\n","    # c_comps = {}\n","    # for iVar in range(num_var):\n","    all_c_components = gererate_all_c_components(num_var, c_size)\n","\n","    for iComp_size in all_c_components:\n","        c_comps_of_size = all_c_components[iComp_size]\n","        parent_size = single_c_parent_size if iComp_size < 2 else other_c_parent_size\n","        for each_comp in c_comps_of_size: # in a list\n","\n","            edges = gererate_all_bidirected_edges(each_comp)\n","            for each_edge_set in edges:\n","\n","                if iComp_size > 1:\n","                    # scores[each_comp]['bi_edges'] = [each_comp]\n","                    # dic_key = (each_comp, each_edge_set)\n","                    save_edge_set = each_edge_set\n","                else:\n","                    # scores[each_comp]['bi_edges'] = []\n","                    # dic_key = (each_comp, ())\n","                    save_edge_set = ()\n","\n","                dic_key = (each_comp, save_edge_set)\n","                scores[dic_key] = {}\n","\n","                parent_set_list = []\n","                for each_var_in_comp in each_comp:\n","                    # generate parental size\n","                    parent_set_list.append( gererate_all_parent_sets(each_var_in_comp,\n","                                                                     each_comp,\n","                                                                     num_var,\n","                                                                     parent_size,\n","                                                                     save_edge_set) )\n","\n","                # generate parent set combination\n","                all_parent_list = list(itertools.product(*parent_set_list))\n","\n","                # compute scores\n","                for each_parent_set_config in all_parent_list:\n","\n","                    # scores[dic_key][each_parent_set_config] = {}\n","\n","                    # remove certain condition:\n","                    # 1) a->b and a<-b\n","                    if not has_cycle_in_c_comp(each_parent_set_config, each_comp):\n","                    # list all potential bidirected edges\n","                        scores[dic_key][each_parent_set_config] = compute_BiC_c_comps_sets(data,\n","                                                                                            each_comp,\n","                                                                                            each_parent_set_config,\n","                                                                                           each_edge_set)\n","    matrix = open('../Instances/m3hcAG/m3hc_'+instance_name).read()\n","    matrix = [item.split() for item in matrix.split('\\n')[:-1]]\n","    dim = len(matrix)\n","    bi = []\n","    di = []\n","    for i in range(dim):\n","        for j in range(dim):\n","            if i<j and matrix[i][j] == '2' and matrix[j][i] == '2':\n","                bi.append((i,j))\n","            if matrix[i][j] == '2' and matrix[j][i] == '3':\n","                di.append((i,j))\n","    Nodes = range(dim)\n","    cNodes = []\n","    cCompEdges = []\n","    cParents = []\n","    inComp = [0]*dim\n","    for biedge in bi:\n","        if inComp[biedge[0]] == 0 and inComp[biedge[1]] == 0:\n","            inComp[biedge[0]] = 1\n","            inComp[biedge[1]] = 1\n","            cNodes.append([biedge[0],biedge[1]])\n","            cCompEdges.append([(biedge[0],biedge[1])])\n","        elif inComp[biedge[0]] == 1:\n","            if inComp[biedge[1]] == 0:\n","                inComp[biedge[1]] = 1\n","                isComp = None\n","                for k in range(len(cNodes)):\n","                    if biedge[0] in cNodes[k]:\n","                        isComp = k\n","                        break\n","                if biedge[1] not in cNodes[isComp]:\n","                    cNodes[isComp].append(biedge[1])\n","                cCompEdges[isComp].append((biedge[0],biedge[1]))\n","            else:\n","                isComp = None\n","                for k in range(len(cNodes)):\n","                    if biedge[0] in cNodes[k]:\n","                        isComp = k\n","                        break\n","                cCompEdges[isComp].append((biedge[0],biedge[1]))\n","                jsComp = None\n","                for k in range(len(cNodes)):\n","                    if biedge[1] in cNodes[k]:\n","                        jsComp = k\n","                        break\n","                if isComp != jsComp:\n","                    for node in cNodes[jsComp]:\n","                        if node not in cNodes[isComp]:\n","                            cNodes[isComp].append(node)\n","                    for biedge in cCompEdges[jsComp]:\n","                        if biedge not in cCompEdges[isComp]:\n","                            cCompEdges[isComp].append(biedge)\n","                    cNodes.remove(cNodes[jsComp])\n","                    cCompEdges.remove(cCompEdges[jsComp])\n","        elif inComp[biedge[1]] == 1:\n","            inComp[biedge[0]] = 1\n","            for k in range(len(cNodes)):\n","                if biedge[1] in cNodes[k]:\n","                    isComp = k\n","                    break\n","            if biedge[0] not in cNodes[isComp]:\n","                cNodes[isComp].append(biedge[0])\n","            cCompEdges[isComp].append((biedge[0],biedge[1]))\n","    for i in range(dim):\n","        if inComp[i] == 0:\n","            cNodes.append([i])\n","            cCompEdges.append([])\n","    for k in range(len(cNodes)):\n","        cNodes[k] = tuple(sorted(cNodes[k]))\n","        cCompEdges[k] = tuple(cCompEdges[k])\n","        cParents.append([])\n","        for i in cNodes[k]:\n","            ciParents = []\n","            for j in range(dim):\n","                if (j,i) in di:\n","                    ciParents.append(j)\n","            cParents[k].append(tuple(ciParents.copy()))\n","        cParents[k] = tuple(cParents[k])\n","        dic_key = (cNodes[k],cCompEdges[k])\n","        each_parent_set_config = cParents[k]\n","        each_comp = cNodes[k]\n","        each_edge_set = cCompEdges[k]\n","        if dic_key not in scores.keys():\n","            scores[dic_key] = {}\n","        scores[dic_key][each_parent_set_config] = compute_BiC_c_comps_sets(data,each_comp,each_parent_set_config,each_edge_set)\n","        #print(str(dic_key)+\",\"+str(each_parent_set_config)+\",\"+str(scores[dic_key][each_parent_set_config]))\n","\n","\n","    # save files\n","    print('saving file..\\n')\n","    file_name = './' + file_name # /synth_5_test_score.pkl'\n","    score_write_to_file([data, scores], file_name)\n","\n","    return\n","\n","def gererate_all_bidirected_edges(each_comp):\n","    # generate all possible bi-directed edges within a c component\n","    # edge_num = len(each_comp)   # max number of edges\n","    edge_num = len(each_comp) - 1\n","    bi_edges = []\n","    edge_num_upper_bound = comb(len(each_comp), 2, exact=True) # scipy.misc.comb\n","\n","    if edge_num < 1:\n","        flatten_list = [-1]  # no bidrected edges\n","\n","    else:\n","        all_edges = list(itertools.combinations( sorted(set(each_comp)), 2))\n","        # for iCsize in range(1, edge_num+1): # size 0 to c_size\n","        for iCsize in range(edge_num, edge_num_upper_bound+1):  # size edge_num to max\n","            # parent_candidates =  list(set(list(range(num_var))) - set(var_in_comp))\n","            # parent_candidates.remove(iVar)\n","            sets = list(itertools.combinations( set(all_edges), iCsize))\n","            # c_comp[iCsize] = sets\n","\n","            # check connected components, make sure nodes are connected to each other in c-comp\n","            sets = check_connected_component(sets, each_comp)\n","            bi_edges.append(sets)\n","\n","        flatten_list = [item for sublist in bi_edges for item in sublist]\n","    return flatten_list\n","\n","def gererate_all_parent_sets(iVar,\n","                             var_in_comp,\n","                             num_var,\n","                             c_size,\n","                             comp_edges):\n","    # generate all possible c components\n","    # comp_edges: edges in a comp\n","\n","    # bi_directed_edge: bi directed edges from iVar\n","    bi_directed_node = find_bi_connected_node(iVar, comp_edges)\n","    candidate_parent_in_comp =  set(list(var_in_comp)) - set([iVar])- \\\n","                                set(list(bi_directed_node))\n","    c_comp = []\n","    for iCsize in range(c_size+1): # size 0 to c_size\n","\n","        # add candiate parental sets\n","        parent_candidates =  list(sorted(\n","            (set(list(range(num_var))) - set(var_in_comp)).union(candidate_parent_in_comp)))\n","        # parent_candidates.remove(iVar)\n","        sets = list(itertools.combinations( sorted(set(parent_candidates)), iCsize))\n","        # c_comp[iCsize] = sets\n","        c_comp.append(sets)\n","\n","    flatten_list = [item for sublist in c_comp for item in sublist]\n","    return flatten_list\n","\n","\n","def gererate_all_c_components(num_var, c_size):\n","    # generate all possible c components\n","    c_comp = {}\n","    for iCsize in range(1, c_size+1):\n","        sets = list(itertools.combinations( sorted(set(range(num_var))), iCsize))\n","        c_comp[iCsize] = sets\n","    return c_comp\n","\n","\n","def gererate_all_bidirected_graphs(num_var, bi_directed = True):\n","    # generate all possible subgraphs with bi-directed edges\n","    # TODO\n","\n","    W = [[0, 0, 0, 0, 0],\n","         [0, 0, 0, 0, 0],\n","         [1, 1, 0, 0, 0],\n","         [1, 0, 0, 0, 0],\n","         [0, 1, 0, 0, 0]]\n","\n","    graph = {}\n","    graph[0] = W\n","    return graph\n","\n","\n","def check_subgraph_scores(values):\n","    data = values.to_numpy()\n","\n","    latent_model_score = compute_local_BiCScore(data, 0, [2, 3]) + \\\n","                         compute_local_BiCScore(data, 1, [2, 4]) + \\\n","                         compute_local_BiCScore(data, 3, []) + \\\n","                         compute_local_BiCScore(data, 4, []) + \\\n","                         compute_local_BiCScore(data, 2, [])\n","    print('Full self check  ground truth DAG score', latent_model_score)\n","\n","\n","    # latent_model_score = BicScore(values).local_score('A', ['D']) + \\\n","    #                      BicScore(values).local_score('B', ['E']) + \\\n","    #                      BicScore(values).local_score('D', []) + \\\n","    #                      BicScore(values).local_score('E', []) + \\\n","    #                      BicScore(values).local_score('C', [])\n","    # print('dag  without A-B edge  BIC', latent_model_score)\n","\n","    latent_model_score = compute_local_BiCScore(data, 0, [ 3]) + \\\n","                         compute_local_BiCScore(data, 1, [4]) + \\\n","                         compute_local_BiCScore(data, 3, []) + \\\n","                         compute_local_BiCScore(data, 4, []) + \\\n","                         compute_local_BiCScore(data, 2, [])\n","    print('Full self check dag  without A-B edge  BIC', latent_model_score)\n","\n","    # latent_model_score = BicScore(values).local_score('A', ['D']) + \\\n","    #                      BicScore(values).local_score('B', []) + \\\n","    #                      BicScore(values).local_score('D', []) + \\\n","    #                      BicScore(values).local_score('E', []) + \\\n","    #                      BicScore(values).local_score('C',[])\n","    # print(' Full DAG  without A-B edge  and E-B BIC ', latent_model_score)\n","\n","    latent_model_score = compute_local_BiCScore(data, 0, [3]) + \\\n","                         compute_local_BiCScore(data, 1, []) + \\\n","                         compute_local_BiCScore(data, 3, []) + \\\n","                         compute_local_BiCScore(data, 4, []) + \\\n","                         compute_local_BiCScore(data, 2, [])\n","    print('Full self check dag with D-A only BIC', latent_model_score)\n","\n","    # latent_model_score = BicScore(values).local_score('A', []) + \\\n","    #                      BicScore(values).local_score('B', ['E']) + \\\n","    #                      BicScore(values).local_score('D', []) + \\\n","    #                      BicScore(values).local_score('E', []) + \\\n","    #                      BicScore(values).local_score('C', [])\n","    # print(' Full DAG  without A-B edge  and D-A BIC ', latent_model_score)\n","\n","    latent_model_score = compute_local_BiCScore(data, 0, []) + \\\n","                         compute_local_BiCScore(data, 1, [4]) + \\\n","                         compute_local_BiCScore(data, 3, []) + \\\n","                         compute_local_BiCScore(data, 4, []) + \\\n","                         compute_local_BiCScore(data, 2, [])\n","    print('Full self check dag with E-B only BIC', latent_model_score)\n","\n","    # latent_model_score = BicScore(values).local_score('A', []) + \\\n","    #                      BicScore(values).local_score('B', []) + \\\n","    #                      BicScore(values).local_score('D', []) + \\\n","    #                      BicScore(values).local_score('E', []) + \\\n","    #                      BicScore(values).local_score('C', [])\n","    # print(' Full empty graph  WITHOUT latent BIC D', latent_model_score)\n","\n","    latent_model_score = compute_local_BiCScore(data, 0, []) + \\\n","                         compute_local_BiCScore(data, 1, []) + \\\n","                         compute_local_BiCScore(data, 3, []) + \\\n","                         compute_local_BiCScore(data, 4, []) + \\\n","                         compute_local_BiCScore(data, 2, [])\n","    print('Full self check empty dag  BIC', latent_model_score)\n","\n","\n","    # 4 variable\n","    # slice data into observed\n","\n","    # observed_data = values.loc[:, ['A','B','D','E']]\n","\n","    # score_function = BicScore(observed_data)\n","\n","\n","    # latent_model_score = score_function.local_score('A', ['B', 'D', 'E']) + \\\n","    #                  score_function.local_score('B', ['E']) + \\\n","    #                  score_function.local_score('D', []) + \\\n","    #                  score_function.local_score('E', [])\n","    # print('DAG without C BIC model A ', latent_model_score)\n","    #\n","    # latent_model_score = score_function.local_score('A', ['D']) + \\\n","    #                      score_function.local_score('B', ['A', 'D', 'E']) + \\\n","    #                      score_function.local_score('D', []) + \\\n","    #                      score_function.local_score('E', [])\n","    # print('DAG  without C BIC model B', latent_model_score)\n","\n","    # latent_model_score =  BicScore(values).local_score('A', ['C','D']) + \\\n","    #                       BicScore(values).local_score('B', ['C','E']) + \\\n","    #                       BicScore(values).local_score('D', []) + \\\n","    #                       BicScore(values).local_score('E', [])\n","    # print('DAG  without A-B, given C,  edge  BIC', latent_model_score)\n","\n","    #-------- self compute check : compute_local_BiCScore\n","\n","    latent_model_score = compute_local_BiCScore(data, 0, [1, 3, 4]) + \\\n","                         compute_local_BiCScore(data, 1, [4]) + \\\n","                         compute_local_BiCScore(data, 3, []) + \\\n","                         compute_local_BiCScore(data, 4, [])\n","    print('4 self check DAG  best graph 1  BIC', latent_model_score)\n","\n","    latent_model_score = compute_local_BiCScore(data, 0, [1, 3, 4]) + \\\n","                         compute_local_BiCScore(data, 1, [0, 4]) + \\\n","                         compute_local_BiCScore(data, 3, []) + \\\n","                         compute_local_BiCScore(data, 4, [])\n","    print('4 self check DAG  best graph 1, +bidirected A-B,  BIC', latent_model_score)\n","\n","    latent_model_score = compute_local_BiCScore(data, 0, [3]) + \\\n","                         compute_local_BiCScore(data, 1, [0, 3, 4]) + \\\n","                         compute_local_BiCScore(data, 3, []) + \\\n","                         compute_local_BiCScore(data, 4, [])\n","    print('4 self check DAG  best graph 2  BIC', latent_model_score)\n","\n","    latent_model_score = compute_local_BiCScore(data, 0, [1, 3]) + \\\n","                         compute_local_BiCScore(data, 1, [0, 3, 4]) + \\\n","                         compute_local_BiCScore(data, 3, []) + \\\n","                         compute_local_BiCScore(data, 4, [])\n","    print('4 self check DAG  best graph 2, +bidirected A-B,  BIC', latent_model_score)\n","\n","    latent_model_score = compute_local_BiCScore(data, 0, [ 3]) + \\\n","                         compute_local_BiCScore(data, 1, [4]) + \\\n","                         compute_local_BiCScore(data, 3, []) + \\\n","                         compute_local_BiCScore(data, 4, [])\n","    print('4 self check DAG  without A-B, given C,  edge  BIC', latent_model_score)\n","\n","    # bidrected model score\n","    # bi_model_score = score_function.local_score('A', ['B', 'D']) +\\\n","    #                     score_function.local_score('B', ['A', 'E']) +\\\n","    #                     score_function.local_score('D', []) +\\\n","    #                     score_function.local_score('E', [])\n","    # print('bidrected sparse  graph BIC', bi_model_score)\n","\n","    latent_model_score = compute_local_BiCScore(data, 0, [1, 3]) + \\\n","                         compute_local_BiCScore(data, 1, [0, 4]) + \\\n","                         compute_local_BiCScore(data, 3, []) + \\\n","                         compute_local_BiCScore(data, 4, [])\n","    print('4 self sparse bidrected   BIC', latent_model_score)\n","\n","    latent_model_score = compute_local_BiCScore(data, 0, [1, 3, 4]) + \\\n","                         compute_local_BiCScore(data, 1, [0, 3, 4]) + \\\n","                         compute_local_BiCScore(data, 3, []) + \\\n","                         compute_local_BiCScore(data, 4, [])\n","    print('4 self dense bidrected   BIC', latent_model_score)\n","\n","\n","\n","    # bidrected model score\n","    # bi_model_score = score_function.local_score('A', ['B', 'D','E']) + \\\n","    #                  score_function.local_score('B', ['A', 'E', 'D']) + \\\n","    #                  score_function.local_score('D', []) + \\\n","    #                  score_function.local_score('E', [])\n","    # print('bidrected dense  graph BIC', bi_model_score)\n","    #\n","    # # bidrected model score\n","    # bi_model_score = score_function.local_score('A', ['B', 'D']) + \\\n","    #                  score_function.local_score('B', ['A', 'E']) + \\\n","    #                  score_function.local_score('D', []) + \\\n","    #                  score_function.local_score('E', [])\n","    # print('bidrected dense  graph BIC', bi_model_score)\n","\n","    # bic_local_score_a_bidirected =  score_function.local_score('A', ['B', 'D'])\n","    bic_local_score_a_bidirected =  compute_local_BiCScore(data, 0, [1, 3])\n","\n","    # bic_local_score_a_dense = score_function.local_score('A', ['B', 'D', 'E'])\n","    bic_local_score_a_dense = compute_local_BiCScore(data, 0, [1, 3, 4])\n","\n","    # bic_local_score_b_bidirected = score_function.local_score('B', ['A', 'E'])\n","    bic_local_score_b_bidirected = compute_local_BiCScore(data, 1, [0, 4])\n","    # bic_local_score_b_dense = score_function.local_score('B', ['A', 'D', 'E'])\n","    bic_local_score_b_dense = compute_local_BiCScore(data, 1, [0, 3, 4])\n","\n","    print('bidirect edge with sparse connection:',\n","          bic_local_score_a_bidirected,\n","          bic_local_score_b_bidirected,\n","          bic_local_score_a_bidirected + bic_local_score_b_bidirected)\n","\n","    print('bidirect edge with dense connection :',\n","          bic_local_score_a_dense,\n","          bic_local_score_b_dense,\n","          bic_local_score_a_dense + bic_local_score_b_dense)\n","    # print(data)\n","\n","if __name__ == \"__main__\":\n","\n","    main()\n","    #\n","    # main_gaus()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":530},"id":"tUkKjSPMOw0D","executionInfo":{"status":"error","timestamp":1747153798261,"user_tz":-120,"elapsed":8162,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"}},"outputId":"723c8f08-d555-4b36-ba17-f2cd8fac2090"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'numpy.strings'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-110-941f54eb9463>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# G = bnlearn.plot(model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpgmpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscrete\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpgmpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBayesianModel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBayesianModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpgmpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBayesianModelSampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pgmpy/factors/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfactor_divide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor_product\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor_sum_product\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mFactorSet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFactorSet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactorset_divide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactorset_product\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mFactorDict\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFactorDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m __all__ = [\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pgmpy/factors/FactorDict.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumbers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOrdinalEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpgmpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscrete\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDiscreteFactor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0m_distributor_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m )\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInconsistentVersionWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HTMLDocumentationLinkMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata_requests\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_MetadataRequester\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_routing_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalidate_parameter_constraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_joblib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata_routing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_bunch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBunch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_chunking\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_chunking.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInterval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0m_fun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0m_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0m_sanity_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_mac_os_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \"\"\"\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy.strings'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"markdown","metadata":{"id":"Bm1yiM3qUZZR"},"source":["# Prune\n","*  compute_treewidth, compute_clique_width, apply_constraints, optimize_causal_inference"]},{"cell_type":"markdown","source":["## 上色"],"metadata":{"id":"bwNcM9zMg1Xu"}},{"cell_type":"code","source":["import networkx as nx\n","import matplotlib.pyplot as plt\n","from networkx.algorithms.approximation import treewidth_min_fill_in\n","\n","\n","# 构造一个 treewidth 为 2 的图（例如一个简单的 cycle graph）\n","G = nx.cycle_graph(5)  # 5-cycle has treewidth 2\n","tw, tree_decomp = treewidth_min_fill_in(G)\n","\n","# 绘制图结构\n","pos = nx.spring_layout(G)\n","plt.figure(figsize=(4, 4))\n","nx.draw(G, pos, with_labels=True, node_color=\"lightblue\", edge_color=\"gray\")\n","plt.title(f\"Cycle Graph with 5 Nodes (Treewidth = {tw})\")\n","plt.show()\n","\n","from itertools import product\n","\n","# 模拟一个简化的“树分解”结构：环的 treewidth = 2，可以用 overlapping triples 构建分解\n","bags = []\n","bag_id_map = {}  # bag节点到编号的映射\n","for i, bag_nodes in enumerate(tree_decomp.nodes()):\n","    bags.append((i, list(bag_nodes)))\n","    bag_id_map[bag_nodes] = i\n","\n","# 构建 bag 之间的树结构（这里人为指定成一个线性结构）\n","# tree_edges = [(0, 1), (1, 2), (2, 3), (3, 4)]\n","tree_edges = []\n","for u, v in tree_decomp.edges():\n","    tree_edges.append((bag_id_map[u], bag_id_map[v]))\n","\n","print(\"树分解的bags:\")\n","for i, nodes in bags:\n","    print(f\"Bag {i}: {nodes}\")\n","print(\"树分解的tree_edges:\")\n","print(tree_edges)\n","\n","# 参数\n","k = 4  # 颜色数\n","colors = range(1, k+1)\n","\n","# DP: 每个 bag 维护一个字典 {state: valid}\n","# state 是一个 tuple 表示该 bag 节点的颜色，如 (1,2,1)\n","dp = [{} for _ in bags]\n","\n","# 初始化第一个 bag 的所有合法染色\n","bag0_nodes = bags[0][1]\n","for color_state in product(colors, repeat=len(bag0_nodes)):\n","    # 检查颜色是否冲突\n","    valid = True\n","    for i in range(len(bag0_nodes)):\n","        for j in range(i + 1, len(bag0_nodes)):\n","            u, v = bag0_nodes[i], bag0_nodes[j]\n","            if G.has_edge(u, v) and color_state[i] == color_state[j]:\n","                valid = False\n","    if valid:\n","        dp[0][color_state] = None  # root, no parent\n","\n","# 动态规划：从第一个 bag 向下处理\n","for i in range(1, len(bags)):\n","    prev_nodes = bags[i - 1][1]\n","    curr_nodes = bags[i][1]\n","\n","    shared = list(set(prev_nodes) & set(curr_nodes))\n","    prev_dp = dp[i - 1]\n","    curr_dp = dp[i]\n","\n","    for color_state in product(colors, repeat=len(curr_nodes)):\n","        # 检查当前状态是否合法（相邻顶点不同色）\n","        valid = True\n","        for x in range(len(curr_nodes)):\n","            for y in range(x + 1, len(curr_nodes)):\n","                u, v = curr_nodes[x], curr_nodes[y]\n","                if G.has_edge(u, v) and color_state[x] == color_state[y]:\n","                    valid = False\n","        if not valid:\n","            continue\n","\n","        # 匹配是否与上一层的状态兼容（在 shared 顶点上颜色一致）\n","        for prev_state in prev_dp:\n","            match = True\n","            for s_node in shared:\n","                i_prev = prev_nodes.index(s_node)\n","                i_curr = curr_nodes.index(s_node)\n","                if prev_state[i_prev] != color_state[i_curr]:\n","                    match = False\n","                    break\n","            if match:\n","                curr_dp[color_state] = prev_state  # 记录前驱状态\n","                break  # 有一个可行就足够\n","\n","# 检查最后一个 bag 是否存在合法染色\n","final_bag_id, final_bag_nodes = bags[-1]\n","final_dp = dp[-1]\n","\n","if final_dp:\n","    result = {\"can_color\": True}\n","\n","    # 回溯染色方案\n","    coloring = {}\n","    state = next(iter(final_dp))\n","    for i in reversed(range(len(bags))):\n","        bag_nodes = bags[i][1]\n","        for idx, node in enumerate(bag_nodes):\n","            if node not in coloring:\n","                coloring[node] = state[idx]\n","        state = dp[i].get(state, None)\n","\n","    result[\"coloring\"] = coloring\n","else:\n","    result = {\"can_color\": False}\n","\n","result\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":584},"id":"L07lizFtptCD","executionInfo":{"status":"ok","timestamp":1748349423936,"user_tz":-60,"elapsed":167,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"}},"outputId":"d988fe57-5da3-4ac8-e381-0e1f371f820d"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 400x400 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["树分解的bags:\n","Bag 0: [2, 3, 4]\n","Bag 1: [1, 2, 4]\n","Bag 2: [0, 1, 4]\n","树分解的tree_edges:\n","[(0, 1), (1, 2)]\n"]},{"output_type":"execute_result","data":{"text/plain":["{'can_color': True, 'coloring': {0: 1, 1: 2, 4: 2, 2: 1, 3: 3}}"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["## bramble"],"metadata":{"id":"PqsIRfMYg5So"}},{"cell_type":"code","source":["pip install gurobipy\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HIZL7P61hQ9g","executionInfo":{"status":"ok","timestamp":1748516556706,"user_tz":-60,"elapsed":3014,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"}},"outputId":"805eebf6-66a0-4011-ef01-797c5b2e9e2a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gurobipy\n","  Downloading gurobipy-12.0.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (16 kB)\n","Downloading gurobipy-12.0.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (14.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.5/14.5 MB\u001b[0m \u001b[31m108.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: gurobipy\n","Successfully installed gurobipy-12.0.2\n"]}]},{"cell_type":"code","source":["import networkx as nx\n","from gurobipy import Model, GRB\n","from itertools import combinations\n","import matplotlib.pyplot as plt\n","\n","class TreewidthLowerBoundEstimator:\n","    def __init__(self, graph: nx.Graph, max_bramble_size=3, max_hitting_set_size=2):\n","        self.G = graph\n","        self.max_bramble_size = max_bramble_size\n","        self.max_hitting_set_size = max_hitting_set_size\n","        self.bramble_elements = self._generate_bramble_elements()\n","        self.hitting_sets = self._generate_hitting_sets()\n","        self.touching_sets = self._compute_touching_sets()\n","\n","    def _generate_bramble_elements(self):\n","        bramble_elements = {}\n","        idx = 1\n","        for size in range(1, self.max_bramble_size + 1):\n","            for subset in combinations(self.G.nodes, size):\n","                subgraph = self.G.subgraph(subset)\n","                if nx.is_connected(subgraph):\n","                    bramble_elements[idx] = set(subset)\n","                    idx += 1\n","        return bramble_elements\n","\n","    def _generate_hitting_sets(self):\n","        hitting_sets = {}\n","        idx = 1\n","        all_nodes = set().union(*self.bramble_elements.values())\n","        for size in range(1, self.max_hitting_set_size + 1):\n","            for combo in combinations(all_nodes, size):\n","                Sk = set(combo)\n","                if any(not Xi.isdisjoint(Sk) for Xi in self.bramble_elements.values()):\n","                    hitting_sets[idx] = Sk\n","                    idx += 1\n","        return hitting_sets\n","\n","    def _compute_touching_sets(self):\n","        T = {}\n","        for i, Xi in self.bramble_elements.items():\n","            Ti = set(Xi)\n","            for u in Xi:\n","                Ti.update(self.G.neighbors(u))\n","            T[i] = Ti\n","        return T\n","\n","    def estimate_lower_bound(self):\n","        model = Model(\"Treewidth_LowerBound\")\n","        model.setParam('OutputFlag', 0)\n","\n","        x = model.addVars(self.bramble_elements.keys(), vtype=GRB.BINARY, name=\"x\")\n","        z = model.addVar(vtype=GRB.INTEGER, name=\"z\")\n","\n","        model.setObjective(z, GRB.MAXIMIZE)\n","\n","        for k, Sk in self.hitting_sets.items():\n","            not_hitting = [i for i, Xi in self.bramble_elements.items() if Xi.isdisjoint(Sk)]\n","            model.addConstr(z <= len(Sk) + sum(x[i] for i in not_hitting), name=f\"hitting_{k}\")\n","\n","        for i in self.bramble_elements:\n","            for j in self.bramble_elements:\n","                if i < j:\n","                    if self.bramble_elements[i].isdisjoint(self.touching_sets[j]) and \\\n","                       self.bramble_elements[j].isdisjoint(self.touching_sets[i]):\n","                        model.addConstr(x[i] + x[j] <= 1, name=f\"conflict_{i}_{j}\")\n","\n","        model.optimize()\n","\n","        if model.status == GRB.OPTIMAL:\n","            z_val = int(z.X)\n","            selected_bramble = [i for i in self.bramble_elements if x[i].X > 0.5]\n","            return z_val - 1, z_val, selected_bramble\n","        else:\n","            return None, None, []\n","\n","    def compare_with_networkx(self):\n","        lower_bound, z_val, bramble_ids = self.estimate_lower_bound()\n","        tw_real, _ = nx.approximation.treewidth_min_fill_in(self.G)\n","        return {\n","            'treewidth_lower_bound': lower_bound,\n","            'z_value': z_val,\n","            'selected_bramble_ids': bramble_ids,\n","            'selected_bramble_elements': [self.bramble_elements[i] for i in bramble_ids],\n","            'networkx_treewidth': tw_real\n","        }\n","\n","    def visualize_graph(self):\n","        pos = nx.spring_layout(self.G, seed=42)\n","        plt.figure(figsize=(8, 6))\n","        nx.draw(self.G, pos, with_labels=True, node_color='skyblue', node_size=600, edge_color='gray')\n","        plt.title(\"Input Graph\")\n","        plt.show()\n","\n","\n","if __name__ == '__main__':\n","    # 示例图\n","    edges = [(1, 2), (2, 3), (2, 5), (3, 4), (4, 5), (1, 6)]\n","    G = nx.Graph()\n","    G.add_edges_from(edges)\n","\n","    estimator = TreewidthLowerBoundEstimator(G, max_bramble_size=3, max_hitting_set_size=2)\n","    results = estimator.compare_with_networkx()\n","\n","    print(\"\\n==== Treewidth Estimation Results ====\")\n","    print(f\"Lower Bound (z - 1): {results['treewidth_lower_bound']}\")\n","    print(f\"Gurobi z Value: {results['z_value']}\")\n","    print(f\"NetworkX Treewidth: {results['networkx_treewidth']}\")\n","    print(\"Selected Bramble Elements:\")\n","    for i, X in zip(results['selected_bramble_ids'], results['selected_bramble_elements']):\n","        print(f\"  X{i} = {X}\")\n","\n","    estimator.visualize_graph()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":980},"id":"HoyeUYG1pK7V","executionInfo":{"status":"ok","timestamp":1748515541006,"user_tz":-60,"elapsed":606,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"}},"outputId":"904d5cf1-5af5-4502-f7c3-7feb2c4ab39a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==== Treewidth Estimation Results ====\n","Lower Bound (z - 1): 2\n","Gurobi z Value: 3\n","NetworkX Treewidth: 2\n","Selected Bramble Elements:\n","  X3 = {3}\n","  X5 = {4}\n","  X9 = {2, 3}\n","  X10 = {2, 5}\n","  X11 = {3, 4}\n","  X12 = {4, 5}\n","  X13 = {1, 2, 3}\n","  X14 = {1, 2, 5}\n","  X16 = {2, 3, 5}\n","  X17 = {2, 3, 4}\n","  X18 = {2, 4, 5}\n","  X19 = {3, 4, 5}\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 800x600 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAzMAAAKCCAYAAADlSofSAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAWyNJREFUeJzt3Xl0Y/ld5/3PtSXLsiV5t+xylXfXZksNSWftbhIC6SSdhQRIZyFwkjBh0iQ9IdBA4HmY0+Ehw2HLhAyBMBAmBAjJJJAEJg10IDMk3Q30dEMi2bV5d7lc3hdZtiRruc8fHV1KXUtbKttXy/t1DodTLunq60rb0ud+f7/vzzBN0xQAAAAAlJgquwsAAAAAgEIQZgAAAACUJMIMAAAAgJJEmAEAAABQkggzAAAAAEoSYQYAAABASSLMAAAAAChJhBkAAAAAJYkwAwAAAKAkEWYAABXNMAy9//3vt7sMAEABCDMAUMQ+/elPyzAMPfXUU3aXIkna3d3Vww8/rP/zf/5PXs9bXl7Whz70IQUCAXk8HtXW1mpwcFDvete79Nhjjx1OsQCAsuewuwAAQOnY3d3Vhz/8YUnSy1/+8n0958knn9RrX/tabW9v661vfave+973yuVyaXp6Wl/+8pf16U9/Wv/4j/+o7/me7znEygEA5YgwAwA4NBsbG3rjG98oh8Ohb33rWzp9+nTO3//Kr/yKPve5z8ntdt/yOjs7O6qvrz/MUgEAJYhlZgBQYt75znfK4/HoypUreuMb3yiPx6O2tjY99NBDSqfT1uNmZmZkGIZ+8zd/U//1v/5X9fT0yO1262Uve5lGR0dzrvnyl7/8hp2Wd77znert7bWu19bWJkn68Ic/LMMwZBiGHn744ZvW+slPflJXr17Vxz72seuCjPTMfpW3ve1tesELXmB97eGHH5ZhGDp37pze/va3q6mpSXfffbckKRQK6Z3vfKf6+/tVW1urjo4Ovfvd79ba2lrOdbPXuHDhgu6//375fD61tLToAx/4gOLx+A1r/fKXv6yRkRG5XC4NDw/rb//2b2/6fQEAigOdGQAoQel0Wq961av0ohe9SL/5m7+pv//7v9dv/dZvaWBgQA888EDOYz/zmc9oe3tb73vf+xSPx/Xbv/3besUrXqFwOCy/37/v12xra9Pv/d7v6YEHHtCb3vQm/eAP/qAkKRgM3vQ5f/3Xfy232209Nh9vfvObNTQ0pP/yX/6LTNOUJH3ta1/T1NSU3vWud6mjo0NjY2P67//9v2tsbEz//M//LMMwcq5x//33q7e3V7/6q7+qf/7nf9bHP/5xbWxs6DOf+UzO4x577DH95V/+pX7yJ39SXq9XH//4x/VDP/RDmpubU0tLS961AwCOBmEGAEpQPB7XW97yFv3SL/2SJOm9732vnve85+lTn/rUdWFmYmJC4+Pj6urqkiS9+tWv1ote9CL92q/9mj760Y/u+zXr6+v1wz/8w3rggQcUDAb1jne84zmfc+HCBZ06dUpOpzPn69vb20okEtaf3W73dcvI7rjjDn32s5/N+dpP/uRP6md+5mdyvvbiF79Yb3vb2/TYY4/pnnvuyfm7vr4+feUrX5Ekve9975PP59Pv/u7v6qGHHsoJYefPn9e5c+c0MDAgSfre7/1e3XHHHfrzP/9zJp0BQBFjmRkAlKj3vve9OX++5557NDU1dd3j3vjGN1pBRpJe+MIX6kUvepEeeeSRQ68xEonI4/Fc9/Uf/dEfVVtbm/V/P//zP3/dY579/UnK2VsTj8e1urqqF7/4xZKkf/3Xf73u8e973/ty/vzggw9K0nXf+/d///dbQUZ6ptvk8/lu+O8JACgehBkAKEG1tbXW/pWspqYmbWxsXPfYoaGh67528uRJzczMHFZ5Fq/Xq2g0et3Xf/mXf1lf+9rX9LWvfe2mz+3r67vua+vr6/rABz4gv98vt9uttrY263FbW1vXPf7Z3/vAwICqqqqu+967u7uve+7N/j0BAMWDZWYAUIKqq6sP9HqGYVj7Uq517UCBQpw+fVrf/va3lUwmc5aa3WqfTdaNJpzdf//9euKJJ/SzP/uz+q7v+i55PB5lMhm9+tWvViaTec5rPntPTdbN/j1v9G8CACgedGYAoMyNj49f97VLly5ZU8qkZ7oQm5ub1z1udnY25883CwM387rXvU6xWExf+tKX8nrejWxsbOgf/uEf9KEPfUgf/vCH9aY3vUmvfOUr1d/ff9PnPPt7n5iYUCaTyfneAQClizADAGXuy1/+sq5cuWL9+cknn9S//Mu/6DWveY31tYGBAV24cEErKyvW17797W/r8ccfz7lWXV2dJN0w+NzIAw88IL/frw9+8IO6dOnSdX+fT+cj2z159nM+9rGP3fQ5n/jEJ3L+/N/+23+TpJzvHQBQulhmBgBlbnBwUHfffbceeOABJRIJfexjH1NLS4t+7ud+znrMu9/9bn30ox/Vq171Kv34j/+4lpeX9clPflLDw8OKRCLW49xut86ePavPf/7zOnnypJqbmzUyMqKRkZEbvnZzc7O+9KUv6fWvf73uuOMOvfWtb9ULXvACOZ1OXb58WV/4whck3XjPyrP5fD59z/d8j379139dyWRSXV1devTRRzU9PX3T50xPT+sNb3iDXv3qV+uf/umf9Kd/+qd6+9vfrjvuuGO//3wAgCJGZwYAytyP/diP6cEHH9Tv/M7v6CMf+YiGh4f19a9/XZ2dndZjzpw5o8985jPa2trST//0T+uv/uqv9Cd/8id63vOed931/vAP/1BdXV364Ac/qLe97W364he/eMvXf8lLXqLR0VE9+OCDevLJJ/XQQw/pwQcf1J/92Z/phS98ob7xjW/kBKtb+exnP6tXvepV+sQnPqFf+IVfkNPp1N/8zd/c9PGf//zn5XK59KEPfUhf/epX9f73v1+f+tSn9vVaAIDiZ5jsbgSAsjQzM6O+vj79xm/8hh566CG7yzlSDz/8sD784Q9rZWVFra2tdpcDADgkdGYAAAAAlCTCDAAAAICSRJgBAAAAUJLYMwMAAACgJNGZAQAAAFCSCDMAAAAAShJhBgAAAEBJIswAAAAAKEmEGQAAAAAliTADAAAAoCQRZgAAAACUJMIMAAAAgJJEmAEAAABQkggzAAAAAEoSYQYAAABASSLMAAAAAChJhBkAAAAAJYkwAwAAAKAkEWYAAAAAlCTCDAAAAICSRJgBAAAAUJIIMwAAAABKEmEGAAAAQEkizAAAAAAoSYQZAAAAACWJMAMAAACgJBFmAAAAAJQkwgwAAACAkkSYAQAAAFCSCDMAAAAAShJhBgAAAEBJIswAAAAAKEmEGQAAAAAliTADAAAAoCQRZgAAAACUJMIMAAAAgJJEmAEAAABQkggzAAAAAEoSYQYAAABASSLMAAAAAChJhBkAAAAAJclhdwEAgP0zTVM7KVO7qYwyplRlSHWOKnmc3JsCAFQewgwAFLnNRFpjGwld2Unq6k5KsbR53WPc1YY66x3qqndquMmlRle1DZUCAHC0DNM0r39XBADYyjRNTUWSemolpuntpAxJ+/llnX1cn9epO9vc6vc5ZRjG4RYLAIBNCDMAUGQie2k9MhfVTB4h5tmyz+v1OnVft0e+Gjo1AIDyQ5gBgCISXovr0fmoUpnCQsyzGZIcVdK9xz0KtNQewBUBACgehBkAKAKmaeqbi7t6YjF2aK/x0g637umoY9kZAKBsMP4GAIrAYQcZSXpiMabHFncP9TUAADhKhBkAsFl4LX7oQSbr8cWYwmvxI3ktAAAOG2EGAGwU2Uvr0fnokb7mo/NRRfbSR/qaAAAcBsIMANjENE09MvfMZv+jlMpIj8xFxZZJAECp49BMALDJVCSpme1k3s+7cv7b+off/w3NfOtflNpLqLmrRy/4wR/VXW/7iX0935Q0s53UVCSpgYaavF8fAIBiQZgBAJs8tRLL+xyZS//0v/WZn3qHjp0K6BX/4WdUU1ev9flpRZau5vXahqSnV2KEGQBASSPMAIANNhNpTefZlYlHt/WF//w+nb77lXr7b/yRqqoKXylsSpraTmozkVajiwM1AQCliT0zAGCDsY2E8j3t5dt/+xeKrq3o3vf9oqqqqrQX21EmU/iGG+M7dQAAUKrozACADa7sJPNaXiZJE//yj3J5vIqsXNWf/MyPaXV2UjXuOn33a+/Xa3/m/5PTVZvX9UxJCzv579kBAKBY0JkBgCNmmqau7qTyft7q3LQyqbQ+88Ef09BLvlc/8hv/Q8//gbfrX774aX3x4f9UUC0LBdQBAECxoDMDAEdsJ2Uqls5/LPJebEfJ+K5e9MPv1Bt+7lclSSPf9zqlk0k9+Rd/rFc+8PNq7R7I65qxtKloMiOPk3tbAIDSw7sXAByx3QIPlskuI7vjVW/K+fp3vfoHJUlzoacKum7sqA+6AQDggBBmAOCIZQo8q9Lb1iFJ8rS053y9vrlNkhSLbBZ03QKaRAAAFAXCDAAcsap8x5h9R9eZoCQpspx7psz2yqIkqb6ptaDrVhdYDwAAdiPMAMARq3MU9qs3+MofkCT936/8Wc7X/++X/1RVDof677yroOu6C6wHAAC7MQAAAI5YvcOQu9rIewjAsdNB3fkDb9dTX/msMqmU+p7/Uk0//bjCX/srvfxdH5DvO8vQ8uGuNtj8DwAoWYZpmqyWBoAj9j8ntzQVyf+Ml3Qyqf/9Rx/T03/159peWVRj53G9+P536+4feW9BdQz4nHrzQENBzwUAwG6EGQCwweOLu3rs6m7eB2ceJEPS3Z11uqujzsYqAAAoHGsLAMAGw00uW4OMJJnfqQMAgFJFmAEAGzS6qtXndcquQWKGpH6vU42uapsqAADg9hFmAMAmd7a5bevOmJKe3+a26dUBADgYhBkAsEm/z6leG7ozhqQ+r1P9PucRvzIAAAeLMAMANjEMQ/d1e3TUx7w4qqTXdHtkGJyWCQAobYQZALCRr6Za9x73HOlr3nvcI18Ne2UAAKWPMAMANgu01OqlHUezf+WuDrcCLbVH8loAABw2wgwAFIF7Oup01yEHmrs63LqbM2UAAGWEQzMBoIiE1+J6dD6qVEYHMunM0DN7ZO497qEjAwAoO4QZACgykb20HpmLamY7KUOFhZrs83q9Tt3XzR4ZAEB5IswAQBEyTVNTkaSeXolpKo9Qk31cv9ep57e51e9zMrUMAFC2CDMAUOQ2E2mNbSS0sJPUwk5KsfT1v7bNREwDbT511Ts13ORSo4tODACg/BFmAKDERJMZxVIZpU2p2pCW5uf0F5/9Ez344INqbm62uzwAAI6Mw+4CAAD58Tir5HH++zBKd2e7JGlpaYkwAwCoKIxmBoASV19fr7q6Oi0tLdldCgAAR4owAwAlzjAM+f1+LS8v210KAABHijADAGXA7/fTmQEAVBzCDACUgfb2dq2vr2tvb8/uUgAAODKEGQAoA36/X5JYagYAqCiEGQAoA21tbTIMgzADAKgohBkAKANOp1MtLS3smwEAVBTCDACUCYYAAAAqDWEGAMpEe3u7lpaWZJqm3aUAAHAkCDMAUCb8fr/i8bi2t7ftLgUAgCNBmAGAMpGdaMZSMwBApSDMAECZaGhoUE1NDWEGAFAxCDMAUCYMw5Df72c8MwCgYhBmAKCMZIcAAABQCQgzAFBG/H6/VldXlU6n7S4FAIBDR5gBgDLi9/uVyWS0urpqdykAABw6wgwAlJH29nZJTDQDAFQGwgwAlJHa2lo1NDQQZgAAFYEwAwBlholmAIBKQZgBgDLj9/vpzAAAKgJhBgDKjN/v1/b2tnZ3d+0uBQCAQ0WYAYAywxAAAEClIMwAQJlpaWlRdXU1+2YAAGWPMAMAZaaqqkrt7e10ZgAAZY8wAwBliCEAAIBKQJgBgDLU3t6u5eVlZTIZu0sBAODQEGYAoAz5/X6lUiltbGzYXQoAAIeGMAMAZcjv90tiohkAoLwRZgCgDNXX16u+vp4wAwAoa4QZAChTfr+f8cwAgLJGmAGAMsV4ZgBAuSPMAECZ8vv92tjY0N7ent2lAABwKAgzAFCmskMAWGoGAChXhBkAKFNtbW0yDIOlZgCAskWYAYAy5XA41NLSQpgBAJQtwgwAlDEmmgEAyhlhBgDKmN/v19LSkkzTtLsUAAAOHGEGAMqY3+9XPB5XJBKxuxQAAA4cYQYAylh7e7sksW8GAFCWCDMAUMYaGhrkcrnYNwMAKEuEGQAoY4ZhWPtmAAAoN4QZAChz7e3thBkAQFkizABAmfP7/VpdXVUqlbK7FAAADhRhBgDKnN/vl2maWl1dtbsUAAAOFGEGAMocE80AAOWKMAMAZc7lcqmxsZEwAwAoO4QZAKgAfr+f8cwAgLJDmAGACsBEMwBAOSLMAEAF8Pv9ikaj2tnZsbsUAAAODGEGACqA3++XJJaaAQDKCmEGACpAc3OzHA4HS80AAGWFMAMAFaCqqkptbW2EGQBAWSHMAECF8Pv9hBkAQFkhzABAhfD7/VpZWVEmk7G7FAAADgRhBgAqhN/vVyqV0vr6ut2lAABwIAgzAFAh2tvbJYmlZgCAskGYAYAKUV9fL4/HQ5gBAJQNwgwAVBC/389ZMwCAskGYAYAK0t7eTmcGAFA2CDMAUEH8fr82NzeVSCTsLgUAgNtGmAGACuL3+yWJpWYAgLJAmAGACtLa2irDMFhqBgAoC4QZAKggDodDra2thBkAQFkgzABAhWGiGQCgXBBmAKDCZCeamaZpdykAANwWwgwAVBi/369EIqGtrS27SwEA4LYQZgCgwjDRDABQLggzAFBhfD6famtrGQIAACh5hBkAqDCGYcjv9xNmAAAljzADABUoOwQAAIBSRpgBgArk9/u1tramVCpldykAABSMMAMAFcjv98s0Ta2srNhdCgAABSPMAEAFam9vlySWmgEAShphBgAqUE1NjZqamggzAICSRpgBgArl9/s5awYAUNIIMwBQoZhoBgAodYQZAKhQfr9fOzs7ikajdpcCAEBBCDMAUKH8fr8ksdQMAFCyCDMAUKGamprkcDhYagYAKFmEGQCoUFVVVWpvb6czAwAoWYQZAKhgfr+fzgwAoGQRZgCggmXHM2cyGbtLAQAgb4QZAKhg7e3tSqfTWltbs7sUAADyRpgBgArGRDMAQCkjzABABaurq5PX62XfDACgJBFmAKDCMQQAAFCqCDMAUOHa29sJMwCAkkSYAYAK5/f7tbW1pXg8bncpAADkhTADABWOIQAAgFJFmAGACtfa2qqqqiqWmgEASo7D7gIAAPaqrq5Wa2urFpeWFE1mtJvKKGNKVYZU56iSx8l9LwBAcTJM0zTtLgIAYI/NRFpjGwk9PXlZsRqPTIfruse4qw111jvUVe/UcJNLja5qGyoFAOB6hBkAqDCmaWoqktRTKzFNbydlfOdrMoxbPs+QZErq8zp1Z5tb/T6njOd4DgAAh4kwAwAVJLKX1iNzUc1kQ0wB18g+r9fr1H3dHvlq6NQAAOxBmAGAChFei+vR+ahSmcJCzLMZkhxV0r3HPQq01B7AFQEAyA9hBgDKnGma+ubirp5YjB3aa7y0w617OupYdgYAOFKMqAGAMnfYQUaSnliM6bHF3UN9DQAAno0wAwBlLLwWP/Qgk/X4YkzhtfiRvBYAABJhBgDKVmQvrUfno0f6mo/ORxXZSx/pawIAKhdhBgDKkGmaemTumc3+RymVkR6Zi4rtmACAo0CYAYAyNBVJamY7eSBTy/JhSprZTmoqkjziVwYAVCKH3QUAAA7eUyuxvM+RSexG9Y0//oQujz6t+bF/UyyyqR9++ON6/hveltdrG5KeXolpoKEmr+cBAJAvOjMAUGY2E2lNF9CV2d1c19f/4De1Mj2uzpPDBb++KWlqO6nNBHtnAACHi84MAJSZsY1E3l0ZSfK2+vWLj47K2+rX/Llv6RPveGXBNRjfqeOujrqCrwEAwHOhMwMAZebKTmF7ZRw1Lnlb/QdSgylpYYd9MwCAw0WYAYAyYpqmru6k7C5DkrRQJHUAAMoXYQYAyshOylQsXRxjkWNpU9HkEc+GBgBUFMIMAJSR3aM+WOY5xIqsHgBAeSHMAEAZyRRHU8ZSJE0iAECZIswAQBmpMuyuIFd1kdUDACgvhBkAKCN1juL6te4usnoAAOWFdxkAKCP1DkPuImmHuKsNeZy8zQAADg+HZgJAGTEMQ531Dk1FCjvj5YnP/aHi0S1FVpYkSee/8XfaWl6QJL30Le9Rrde372sdq+ctBgBwuAzTNNmeCQBl5PHFXT12dbeggzN/7bXP0+bVyzf8u5/7X0+r6Vj3vq5jSLq7s053ddQVUAUAAPtDmAGAMrOZSOuT5zbsLkPvPdukRle13WUAAMoYi5kBoMw0uqrV53XKrp0zhqR+r5MgAwA4dIQZAChDd7a5C1pmdhBMSc9vc9v06gCASkKYAYAy1O9zqteG7owhqc/rVL/PecSvDACoRIQZAChDhmHovm6PjvqYF0eV9JpujwyjOMZDAwDKG2EGAMqUr6Za9x73HOlr3nvcI18Ne2UAAEeDMAMAZSzQUquXdhzN/pW7OtwKtNQeyWsBACARZgCg7N3TUae7DjnQ3NXh1t2cKQMAOGKcMwMAFSK8Ftej81GlMjqQSWeGntkjc+9xDx0ZAIAtCDMAUEEie2k9MhfVzHZShgoLNdnn9Xqduq+bPTIAAPsQZgCgwpimqalIUk+vxDSVR6jJPq7f69Tz29zq9zmZWgYAsBVhBgAq2GYirbGNhBZ2klrYSSmWvv4twV1t6Fi9Q8fqnRpucqnRRScGAFAcCDMAAEs0mVEslVHalL7ypb9Ui8+jH379fXaXBQDADTnsLgAAUDw8zip5nM8MumxySvGtdZsrAgDg5hjNDAC4Ia/Xq+3tbbvLAADgpggzAIAb8nq9ikQidpcBAMBNEWYAADfk9XoVj8eVTCbtLgUAgBsizAAAbsjr9UqSotGozZUAAHBjhBkAwA1lwwz7ZgAAxYowAwC4IcIMAKDYEWYAADfkcrnkdDoJMwCAokWYAQDckGEYTDQDABQ1wgwA4Ka8Xi8DAAAARYswAwC4KQ7OBAAUM8IMAOCmPB4PYQYAULQIMwCAm6IzAwAoZoQZAMBNeb1e7e3tKZFI2F0KAADXIcwAAG7K5/NJ4qwZAEBxIswAAG6KgzMBAMWMMAMAuCmPxyOJMAMAKE6EGQDATdXU1MjlchFmAABFiTADALglJpoBAIoVYQYAcEuEGQBAsSLMAABuyefzEWYAAEWJMAMAuCWPx0OYAQAUJcIMAOCWssvMTNO0uxQAAHIQZgAAt+T1epVOpxWLxewuBQCAHIQZAMAtcXAmAKBYEWYAALdEmAEAFCvCDADglggzAIBiRZgBANxSdXW16urqCDMAgKJDmAEAPCcOzgQAFCPCDADgORFmAADFiDADAHhOhBkAQDEizAAAnhNhBgBQjAgzAIDn5PV6FY1Glclk7C4FAAALYQYA8Jy8Xq9M09Tu7q7dpQAAYCHMAACeU/asmUgkYnMlAAD8O8IMAOA5cXAmAKAYEWYAAM+pvr5ehmEQZgAARYUwAwB4TlVVVfJ4PIQZAEBRIcwAAPaF8cwAgGJDmAEA7Et2PDMAAMWCMAMA2Bc6MwCAYkOYAQDsi9frZTQzAKCoEGYAAPvi9Xq1u7urdDptdykAAEgizAAA9il71gz7ZgAAxYIwAwDYFw7OBAAUG8IMAGBfCDMAgGJDmAEA7Ivb7VZ1dTVhBgBQNAgzAIB9MQyDiWYAgKJCmAEA7BsHZwIAiglhBgCwbxycCQAoJoQZAMC+eTwewgwAoGgQZgAA+0ZnBgBQTAgzAIB983q9isfjSiaTdpcCAABhBgCwfz6fTxJnzQAAigNhBgCwbxycCQAoJoQZAMC+EWYAAMWEMAMA2Leamho5nU7CDACgKBBmAAD7ZhgGE80AAEWDMAMAyAthBgBQLAgzAIC8+Hw+wgwAoCgQZgAAefF4PIQZAEBRIMwAAPKSXWZmmqbdpQAAKhxhBgCQF6/Xq2QyqUQiYXcpAIAKR5gBAOSFs2YAAMWCMAMAyAthBgBQLAgzAIC8EGYAAMWCMAMAyIvT6VRtbS1hBgBgO8IMACBvHJwJACgGhBkAQN4IMwCAYkCYAQDkjTADACgGhBkAQN4IMwCAYkCYAQDkLRtmTNO0uxQAQAUjzAAA8ub1epXJZBSLxewuBQBQwQgzAIC8cdYMAKAYEGYAAHnLhplIJGJzJQCASkaYAQDkzePxSKIzAwCwF2EGAJC36upq1dfXE2YAALYizAAACsJ4ZgCA3QgzAICCeL1eRaNRu8sAAFQwwgwAoCB0ZgAAdiPMAAAK4vV6mWYGALAVYQYAUBCv16udnR1lMhm7SwEAVCjCDACgIF6vV6Zpamdnx+5SAAAVijADAChI9uBM9s0AAOxCmAEAFIQwAwCwG2EGAFCQuro6GYZBmAEA2IYwAwAoSFVVFeOZAQC2IswAAArGeGYAgJ0IMwCAgnm9XkWjUbvLAABUKMIMAKBgHo+HZWYAANsQZgAABWPPDADAToQZAEDBvF6vdnd3lUql7C4FAFCBCDMAgIL5fD5JYt8MAMAWhBkAQME4OBMAYCfCDACgYIQZAICdCDMAgILV1taqurqaMAMAsAVhBgBQMMMwmGgGALANYQYAcFsIMwAAuxBmAAC3hTADALALYQYAcFsIMwAAuxBmAAC3hTADALALYQYAcFu8Xq8SiYT29vbsLgUAUGEIMwCA28JZMwAAuxBmAAC3hTADALALYQYAcFsIMwAAuxBmAAC3xeVyqaamhjADADhyhBkAwG1johkAwA6EGQDAbSPMAADsQJgBANw2wgwAwA6EGQDAbSPMAADsQJgBANy2bJgxTdPuUgAAFYQwAwC4bV6vV6lUSolEwu5SAAAVhDADALhtnDUDALADYQYAcNuyYSYSidhcCQCgkhBmAAC3jc4MAMAOhBkAwG1zOBxyu92EGQDAkSLMAAAOBOOZAQBHjTADADgQXq9X0WjU7jIAABWEMAMAOBB0ZgAAR40wAwA4EB6vV5FESsuxlBZ3n/n/0WTG7rIAAGXMMDmuGQBQoM1EWmMbCV3ZSeryVlxJo/q6x7irDXXWO9RV79Rwk0uNrusfAwBAIQgzAIC8mKapqUhST63ENL2dlCFpP28k2cf1eZ26s82tfp9ThmEcbrEAgLJGmAEA7FtkL61H5qKaySPEPFv2eb1ep+7r9shXQ6cGAFAYwgwAYF/Ca3E9Oh9VKlNYiHk2Q5KjSrr3uEeBltoDuCIAoNIQZgAAt2Sapr65uKsnFmOH9hov7XDrno46lp0BAPLCNDMAwC0ddpCRpCcWY3pscfdQXwMAUH4IMwCAmwqvxQ89yGQ9vhhTeC1+JK8FACgPhBkAwA1F9tJ6dD56pK/56HxUkb30kb4mAKB0EWYAANcxTVOPzD2z2f8opTLSI3NRsZ0TALAfDrsLAAAUn6lIUjPbyX0//vLYv+lf//pzmnrqcW0sXFZdY5O6A8/XK3/yF9XWM7Dv65iSZraTmookNdBQU0DlAIBKwjQzAMB1Pj+xpZnt5L5HMP/Zz75Ls99+UiPf/wZ1Dp3V9tqy/unzn9Le7o4e+OO/VcfgmX2/tqFnDta8f7ChoNoBAJWDMAMAyLGZSOuT5zbyes7st59U19nvksP5792U1blJ/fb9L9PI971eb/nI7+Vdx3vPNqnRxYGaAICbY88MACDH2EZC+Z720nPHC3OCjCS1dg+ovf+Ulqcv5V2D8Z06AAC4FcIMACDHlZ39Ly+7FdM0FV1fUX1jc/7PlbSws/89OwCAykSYAQBYTNPU1Z3UgVzrW498UZHlqwre+8aCnr9wQHUAAMoXYQYAYNlJmYqlb78vszw9rq/82s+rO/gCPe/1by3oGrG0qWjyiGdDAwBKCmEGAGDZPYCDZbZXl/THH3i7aj0+/chv/JGqqgvfxB876oNuAAAlhXNmAACWzG02ZeLbEf2PB9+q2PaW/uOn/lq+to7but4BNIkAAGWMMAMAsFTlO8bsGslEXH/8Uz+i1dkp/fjvfVH+/lO3XU/1bdQDACh/hBkAgKXOUdjq40w6rT//0Hs0F35KP/rRz6jnjhccSD3uAusBAFQGwgwAwFLvMOSuNvIeAvDVj/5nnf/Hv9WZ73mVYlub+revfiHn77/7tW/OuxZ3tSGPkzADALg5wgwAwGKaphqMPcVMh2Tsf43X1UujkqTz3/g7nf/G31339/mHGVOddbxFAQBuzTBNk+2VAFDBTNPU0tKSQqGQRkdHtdt5So5TL5AM+7oiZiajqulvacSdVDAY1PHjx2XkEa4AAJWBMAMAFWpra0vhcFjhcFjLy8uqq6vT8PCw+obv0FfWXTZXZ2pk/ZzGQ/+qSCSixsZGjYyMKBAIqL293ebaAADFgjADABUkHo/r3LlzCoVCmp2dlcPh0OnTpxUIBDQwMKDq75wJ8/mJLc1sJ2XHG4Qhqc/r1P2DDTJNU7OzswqHwzp37pzi8bj8fr8CgYBGRkbU0NBgQ4UAgGJBmAGAMpdKpTQ+Pq5wOKxLly4pk8mor69PwWBQp0+flst1fRdmcmtPX5iK2FDtM97c79NAQ03O11KplCYnJxUOh3Xx4kWlUin19PRoZGREw8PDcrvdNlULALALYQYAypBpmpqbm1MoFLI6Gp2dnVZHw+v1PufzPz8Z0ewRd2cMSb1ep+4f8N1yj0wikdCFCxcUDoc1NTUlwzA0ODioQCCgU6dOyel0Hl3RAADbEGYAoIwsLy9b+2C2trbU0NCgQCCgYDCotra2vK4V2UvrD85vKJk5pGJvwFklvedMk3w11ft+TjQa1djYmMLhsK5cuaKamhpr6Vx/f7+qqhjvDADlijADACVue3vbCjCLi4uqra3V8PCwAoGAuru7b2sKWHgtrq/ORQ+w2lt7bbdHgZbagp+/vr5u/Vusra2pvr7e+rfo6upiIhoAlBnCDACUoEQiofPnz1vLrKqrq3Xy5EkFg0ENDg7K4Ti4M1q+cXVHTyzGDux6N3NXh1v3dNYfyLVM09Ti4qLC4bBGR0e1vb2tpqYmayJavl0qAEBxIswAQIlIp9OanJxUKBSyNsD39vYqEAjo7Nmzqq0tvKNxK6Zp6rHFXT1+iIHmrg637u6oO5TOSSaTyZmIlkgk1NHRYe0f8vl8B/6aAICjQZgBgCJmmqbm5+cVCoU0NjamWCym9vZ2BYPBIx9NHF6L69H5qFIZHchQAEOSo0q69/jtLS3LR3ay2+joqC5evKh0Om0FwjNnzjARDQBKDGEGAIrQ6uqqtfdjY2NDXq/X2sjv9/ttqyuyl9Yjc1HNbCdlqLBQk31er9ep+7o9eW32P0jxeNyaiDY9Pa2qqioNDQ1pZGREJ0+eZCIaAJQAwgwAFInsVK5QKKSFhQW5XC6dOXNGwWBQPT09RTOVyzRNTUWSenolpqk8Qk32cf1ep57f5la/z1k0G/K3t7etiWgLCwuqqanRmTNnFAgE1NfXVzT/9gCAXIQZALDR3t6e1R2YnJyUYRgaGhpSIBAoie7AZiKtsY2EFnaSWthJKZa+/i3FXW3oWL1Dx+qdGm5yqdFlTydmv9bW1qyu2Pr6uurr663BAceOHSuaAAYAIMwAwJHLZDKamppSOBzW+fPnlUwmdeLECQWDQZ09e1Z1dXV2l1iwaDKjWCqjtClVG5LbUSWPszS7GqZp6urVq9Z+pWg0qubmZo2MjCgYDKqlpcXuEgGg4hFmAOAIXPvBeHR0VDs7O2ptbVUgEFAgEFBTU5PdJeIWMpmMZmZmrACaSCTU2dlpTUTzer12lwgAFYkwAwCHaGNjQ6FQKOcQx2yA6ezsZMlSCUomk9ZEtEuXLimdTquvr8+aiHZYI7IBANcjzADAAdvd3bU2k1++fFlOp9PayM9m8vISj8etw0unp6etw0sDgYCGhoYO9PBSAMD1CDMAcACSyaQuXbqkUCikiYkJmaapwcFBBQIBnTp1SjU1NXaXiEO2vb2t0dFRhcNhXb161ZpGFwgE1NvbS4gFgENAmAGAAl27j+LcuXPa29tTV1eXtY+ivr7e7hJhk2efE+TxeKyJaCwvBICDQ5gBgDyYpqmlpSVrI//29raampoUDAYVCASYcIUcpmnqypUrCofDGhsb087OjlpaWqx9U83NzXaXCAAljTADAPuwtbWlcDisUCiklZUV1dXVaXh4WMFgUF1dXdxpx3PKZDKanp62JqJlO3kjIyMaGRmRx+Oxu0QAKDmEGQC4iVgspnPnzikcDmt2dlYOh0OnT59WIBDQwMCAqquL+/BHFK/sHqtwOKzx8XGZppkzEc3lctldIgCUBMIMAFwjlUppfHxc4XBYly5dUiaTUV9fn4LBoE6fPs2HTBy4bGgeHR3VzMyMHA6HNRFtcHCQiWgAcAuEGQAVzzRNzc3NKRQK6dy5c4rH4xyICFtsbW1ZY70XFxdVW1trjfXu6elhOSMAPAthBkDFWl5etjbyb21tqaGhQYFAQMFgUG1tbXaXhwq3srJiTUTb3NyU1+u1JqJ1dHQQbABAhBkAFWZ7e9v6gJi9853dyH/ixAk+IKLomKap+fl5ayLa7u6uWltbrYloTU1NdpcIALYhzAAoe4lEQufPn1coFLJOaT916hR7ElBy0ul0zkS0ZDKp48ePKxAIaHh4mLONAFQcwgyAspROpzUxMaFwOKyLFy8qlUqpt7dXgUBAZ8+eVW1trd0lArclmUzq4sWLCofDmpiYkGma6u/vVyAQYFgFgIpBmAFQNrLLcUKhkMbGxhSLxdTe3q5gMKiRkRE1NDTYXSJwKHZ3d60x4nNzc3I4HDndR8aIAyhXhBkAJW91ddXaB7OxsSGv12tt5Pf7/XaXBxyp7AGvo6OjWlpaktvt1tmzZxUIBNTd3c2+MABlhTADoCRFo1GNjY0pFAppYWFBLpcrZ4RtVVWV3SUCtlteXraC/tbWlnw+n0ZGRhQMBtXe3k6wAVDyCDMASsbe3p4uXLigcDisyclJGYahoaEhBYNBDQ0Nyel02l0iUJRM09Tly5etiWixWExtbW3WRLTGxka7SwSAghBmABS1TCajqakphUIhXbhwQclkUt3d3dZG/rq6OrtLBEpKOp3W5OSkRkdHrZ+pEydOWD9TTEQDUEoIMwCKjmmaWlhYsNb97+zscK4GcAj29vZyJqIZhqGBgQGNjIzo9OnTqqmpsbtEALglwgyAorGxsaFQKKRwOKy1tTXV19dbAaazs5P1/cAh2tnZsSaiXb58WU6n05qINjAwwEQ0AEWJMAPAVru7uxobG8v5AJXdyN/X18dGfsAGm5ub1uCAlZUVud1uDQ8PKxAI6MSJE9xYAFA0CDMAjlwymdSlS5cUCoWsw/4GBwcVCAR06tQplrYARcI0TS0vLysUCml0dFSRSEQNDQ05E9EAwE6EGQBHIpPJaGZmRuFwWOfOndPe3p66uroUDAY1PDzMpmOgyJmmqbm5OetnOHsobXYpKIfSArADYQbAoTFNU0tLS9Zd3e3tbTU3N1sfflpaWuwuEUAB0um0JiYmFA6HdfHiRaVSKaYMArAFYQbAgcueQB4KhbSysqK6ujoNDw8rGAyqq6uL9fZAGUkkErpw4YJGR0et85+uXTbK+U8ADhNhBsCBiMVi1iSk2dlZORwOnT59mklIQAXZ2dmxBnrMz89bAz1GRkY0MDDAQA8AB44wA6BgqVRK4+PjCofDunTpkjKZjPr6+hQMBnX69Gm5XC67SwRgk42NDWsi2urqqtWhDQQCOn78OB1aAAeCMAMgL9lNwKFQSOfOnVM8HldnZ6cCgYBGRkbk9XrtLhFAETFNU4uLi9YhuNvb22psbLT2zrW1tdldIoASRpgBsC/Xjmfd2tpSQ0ODgsEgH0YA7Fsmk7Fuhpw/f17xeFwdHR0aGRlRIBCQz+ezu0QAJYYwA+Cmtre3rWUii4uLqq2ttTbyc3AegNuRSqWsiWiXLl1SKpVST0+PNRHN7XbbXSKAEkCYAZAjkUjo/PnzCoVCmp6eVnV1tU6dOqVAIKDBwUE5HA67SwRQZrK/d0ZHRzU1NSXDMDQ0NKRAIKCTJ08yEQ3ATRFmANzwzIje3l7rDmltba3dJQKoENFo1JqIduXKFdXU1OjMmTMKBALq6+tjIhqAHIQZoEKZpqn5+XmFQiGNjY1Zp3kHg0GNjIxwmjcA262vr1tLXdfW1lRfX29NROPMKgASYQaoOKurq9aHg42NDXm9XgUCAQWDQfn9frvLA4DrmKapq1evWhPRotGompqarIlora2tdpcIwCaEGaACRKNRjY6OKhwOa2FhQS6XS2fPnlUgEFBPTw/LNgCUjEwmo9nZWWsiWiKRsMbDDw8PMxENqDCEGaBM7e3t6cKFCwqHw5qcnLQ21AaDQZ08eZKN/ABK3rMP7k2n0+rr69PIyAj7/YAKQZgBykgmk9HU1JRCoZAuXLigZDKp7u5u644lo04BlKt4PK7z588rHA5bkxivnYjGDRygPBFmgBJnmqYWFhasjfw7OztqbW211pI3NTXZXSIAHKnt7W2Njo5qdHTUWlqbnYjW29vL0lqgjBBmgBK1sbGhUChkTfnxeDwaGRlRMBhUR0cHU34AQM8MPcnuGVxfX5fH47EO/+3s7OR3JVDiCDNACdnd3dXY2JhCoZDm5+fldDqtjfycvwAAN5ftYmcnou3s7KilpUUjIyMKBAJqaWmxu0QABSDMAEUumUzq4sWLCofDmpiYkGmaGhwcVCAQ0KlTp1RTU2N3iQBQUjKZjKanpzU6Oqpz585pb29Px44ds/YXer1eu0sEsE+EGaAIZTIZzczMKBwOW2+0XV1dCgaDGh4eVn19vd0lAkBZSCaT1kS08fFxZTIZayLamTNnmIgGFDnCDFAkTNPU0tKSQqGQRkdHtb29rebmZmsjP0sgAOBwxWIxayLazMyMqqurdfLkSQUCAQ0NDTERDShChBnAZltbWwqHwwqFQlpZWVFdXZ21ObWrq4vNqQBgg0gkYg0OWFxc5LBhoEgRZgAbxGIxnTt3TuFwWLOzs3I4HDp9+rSCwaD6+/tVXV1td4kAgO9YWVmxBgdsbGzI6/VagwOYHgnYizADHJHsSdWhUMhal93f369AIKDTp0/L5XLZXSIA4BZM09SVK1cUDodzzvXKBpvm5ma7SwQqDmEGOESmaWp2dtbayB+Px9XZ2alAIKCRkREm5gBAicpkMpqamlI4HNaFCxesQS3ZiWgej8fuEoGKQJgBDsHy8rJ1oGUkElFDQ4OCwaACgYDa2trsLg8AcICyI/RHR0c1Pj4u0zTpvANHhDADHJBnbxatra21NvKfOHGCNdUAUAF2d3etiWjZPZGnTp3SyMiIhoaG2BMJHDDCDHAbEomEzp8/r1AopOnpaVVXV+vUqVPWGE/etACgcm1tbVk3uZaWllRbW5szEY2bXMDtI8wAeUqn05qYmFA4HNbFixeVSqXU29urYDDIAWsAgBtaXl62JqJtbm7K5/NZgwP8fj/BBigQYQbYB9M0NT8/r1AopLGxMcViMfn9fmsjf0NDg90lAgBKwLXvJ+fOndPu7q7a2tqsYNPU1GR3iUBJIcwAt7C6uqpwOKxwOGydLRAIBBQMBuX3++0uDwBQwtLpdM5EtGQyqePHj1sT0err6+0uESh6hBngWaLRqLXGeWFhIefU597eXpYCAAAO3N7enjURbWJiQqZpamBgwJqIVlNTY3eJQFEizAB65k3kwoULCofDmpyclGEYGhoaUjAY1MmTJ+VwOOwuEQBQIXZ3d3Xu3DmFw2HNzc3J4XDo9OnTCgQCGhgYYLgMcA3CDCpW9sCzUChktfe7u7ut9r7b7ba7RABAhdvc3LRWCywvL8vtdlurBbq7u1ktgIpHmEFFMU1TCwsL1kb+nZ0dtba2WgdaNjY22l0iAAA3tLS0ZE1E29raUkNDQ85ENKASEWZQETY2NhQKhRQOh7W2tiaPx6ORkREFg0F1dHRwZwsAUDJM09Tc3JzC4bDOnTunWCym9vZ2a8ImN+ZQSQgzKFu7u7saGxtTKBTS/Py8ampqdObMGQUCAfX19amqqsruEgEAuC3pdFqTk5PWRLRUKqXu7m6NjIxoeHhYdXV1dpcIHCrCDMpKMpnUxYsXFQ6HrWkwg4ODCgQCOnXqFNNgAABl60bDbLIT0XgPRLkizKDkZTIZzczMWO32vb09dXV1KRgMMqcfAFCRdnZ2NDY2ptHRUV2+fFlOp9OaiNbf389ENJQNwgxKkmmaWlpasvbBRKNRNTc3KxAIKBAIqKWlxe4SAQAoChsbG9ZEtJWVFdXV1ens2bMKBoM6fvw4+0ZR0ggzKCmbm5sKh8M5v5Czk1y6urr4hQwAwE1kbwRmJ6JFIhE1NjZa76Pt7e12lwjkjTCDoheLxazDw2ZnZ63Dw4LBIK1yAAAKYJqmZmdnrSXa8Xhcfr/fmojW0NBgd4nAvhBmUJRSqZTGx8cVCoU0Pj6uTCaj/v5+BQIBnT59Wi6Xy+4SAQAoC6lUypqIdvHiRaVSKfX09CgQCOjs2bMcIo2iRphB0cjeJQqFQjp//rzi8bg6Ozutu0Rer9fuEgEAKGuJRMKaiDY1NSXDMHKmgjqdTrtLBHIQZmC75eVlayN/dv1udiN/W1ub3eUBAFCRotGoxsbGFA6HdeXKFdXU1ORMROO8NhQDwgxsEYlENDo6qlAopKWlJdXW1mp4eFjBYFAnTpxgIz8AAEVkfX3dGsCztram+vp6DQ8PM4AHtiPM4MgkEglrI//09LSqq6t16tQpBQIBDQ0NsZEfAIAiZ5qmFhcXrYlo29vbampq0sjIiILBoFpbW+0uERWGMINDlU6nNTExkbOpsLe3V8FgUGfOnFFtba3dJQIAgAJkMpmciWiJREIdHR3WXlefz2d3iagAhBkcONM0NT8/r1AopLGxMcViMWvcYyAQ4JcbAABlJjuFdHR0VBcvXlQ6nVZvb68CgYDOnDnDRDQcGsIMDszq6qq1nnZjY0M+n89qO/v9frvLAwAARyAej1sT0aanp1VVVaWhoSGNjIzo5MmTTETDgSLM4LZEo1GNjo4qHA5rYWFBLpdLZ8+eVTAYVE9PDxsCAQCoYNvb29ZEtIWFBdXU1OjMmTMKBALq6+tjIhpuG2EGedvb29OFCxcUCoWsGfQnT55UIBDQyZMn5XA47C4RAAAUmbW1NWsFx/r6uurr6zUyMqJAIKBjx45xAxQFIcxgXzKZjHU68IULF5RMJtXd3a1AIKDh4WHWwgIAgH0xTVNXr1619tZGo1E1NzdbS9NbWlrsLhElhDCDmzJNUwsLC9Yvm52dHbW2tioYDCoQCKixsdHuEgEAQAnLZDKamZlROBzW+fPnlUgk1NnZaU1E83q9dpeIIkeYwXWyB2OFQiGtr6/L4/FYd0s6OjpoAwMAgAOXTCY1Pj6ucDis8fFxpdNp9fX1WRPROM4BN0KYgSRpd3dXY2NjCoVCmp+fZ4MeAACwTTwe17lz5zQ6OmodtJ3dnzs0NMT+XFgIMxUsmUzq4sWLCofDmpiYkGmaGhwcVDAY1KlTpxidCAAAbLe9vW1NTr169apcLpd1w7W3t5cbrhWOMJMn0zS1kzK1m8ooY0pVhlTnqJLHWRo/SNm1qaFQSOfPn9fe3p6OHz9ubeSvr6+3u0QAAIAbevaZdtml8IFAQJ2dnSyFr0CEmX3YTKQ1tpHQlZ2kru6kFEtf/0/mrjbUWe9QV71Tw00uNbqqbaj0xkzT1OLiovXDn50aEggEFAwG1dzcbHeJAAAA+2aapq5cuaJwOGwNKWppaVEgEFAgECiZzzalfpO8GBBmbsI0TU1FknpqJabp7aQMSfv5h8o+rs/r1J1tbvX7nLbdJdjc3LQCzMrKiurq6qyN/MxzBwAA5SCTyWh6etqaiLa3t6euri6NjIxoZGREHo/H7hJzlPpN8mJDmLmByF5aj8xFNZNHiHm27PN6vU7d1+2Rr+Zo/iOMxWI6d+6cQqGQ5ubm5HA4dPr0aQWDQfX396u6mh8GAABQnpLJpC5dumRNRDNNM2cimsvlsqWucrhJXqwIM88SXovr0fmoUpnCQsyzGZIcVdK9xz0KtBzOSMFUKqXx8XGFQiGNj48rk8mov79fgUBAp0+ftu0HFwAAwC7ZG7yjo6OamZmRw+GwJqINDg4e2US0Ur5JXgoIM99hmqa+ubirJxZjh/YaL+1w656OugNJ1KZpanZ2VqFQSOfOnbMOmQoGg0XZUgUAALDL1taWxsbGFA6Htbi4qNraWp05c0bBYFA9PT2H1u0oxZvkpYYw8x3fuLpzqEEm664Ot+7pLHxi2PLyskKhkMLhsCKRiBobG63Nbm1tbQdYKQAAQPlZWVmx9hRvbm7K6/VaE9EO6nDwUrtJXsoIM3omNX91Lnpkr/fa7vzSdCQS0ejoqEKhkJaWllRbW6vh4WEFg0GdOHGi4v8jBgAAyJdpmpqfn7cmou3u7qq1tdW6SdzU1FTwtUvlJnk5qPgwE9lL6w/ObyiZObrXdFZJ7znTdMv1jvF4XOfPn1c4HLZOvj116pSCwaAGBwfZyA8AAHBA0ul0zkS0ZDJZ8Dl8xX6TvNxUdJgxTVOfn4xodjt5IOsY98uQ1ON16i0DvpyuSjqd1sTEhMLhsC5evKhUKqXe3l4Fg0GdOXNGtbWV+x8qAADAUUgmk7p48aLC4bAmJiZkmqYGBgY0MjLynIOVivUmeTmr6DAzubWnL0xF9v34qace1x/8xBtv+HcPfPpv1B28M6/Xf3O/T/0+p+bn5xUKhTQ2NqZYLCa/32+1OH0+X17XBAAAwMHY3d3VuXPnFA6HrSMvTp06ZU1Eu3alTLHdJK8URzOTrkg9tRIraETeS9/2Hh0/+905X2s50ZfXNQxJj16Y194//7U2Nzfl8/n0vOc9T4FAQH6/P8+KAAAAcNDq6up055136s4779TW1pbC4bBGR0f1uc99Tm63W2fPnlUgEFB3d7emIknNbCf3fe2lyQv6+9//dV05H1J0bVnOWrfa+07qe37s/Trzslft+zqmpJntpKYiSQ001BTwXZa2ig0zm4m0pvP4D+5avd/9YgW+/w239fqmpC2nV4ODp/UDw6cOdSwgAAAAbk9DQ4Puvvtu3X333VpeXrYmoj399NPy+XxyvfQNMmp8MrW/z3MbVy8rsRPV8173FvnaOpSM72r0H/6XPvPBd+hN/89v6YU/9GP7rs2Q9PRKrCLDTMUuM3t8cVePXd3NqyuTXWb29l//lE6+5BVyuGpVfRsHLhmS7u6s010ddQVfAwAAAPYwTVOXL1/W0+cu6WL7HdJt3pjOpNP6nR/5PqX2Evrpv/ynvJ//3rNNanRV1t6Ziu3MXNkpfD3jFx/+T9rb3VFVdbV6v/vFes1PPazjZ78r7+uYkhZ2CusOAQAAwF6GYai7u1uXa1p1Kc+b5DdSVV2tBn+X5s/9W/61SBrbSFTcTfKKDDOmaerqTirv51U7nRr5vtfp1F3fr7qmFi1PXdQ3/+R39fs//no98D++qmOng3lfc6GAOgAAAFA8bucm+V5sR8l4XPFoROf/8e906Yl/UODeN+Z9nUq9SV6Ry8yiyYx+Z3T9QK61Ojelj7/15er97hfr3Z/4nwVd4/0jzfI4qw6kHgAAABwd0zT18fC6YunCPlJ/6SMP6cm/+GNJklFVpeFXvFY/+P9+VG5fY97Xclcb+kCwpaA6SlVFdmZ2Uwc3/Lu1u19nXvZqjX39q8qk06oq4DDLWCpDmAEAAChBOymz4CAjSXe9/T8q8P2vV2RlUaFHvyIznVEquVfQtWJpU9FkZX2urJzv9BqZA+5FNfq7lE7uaS+2W9Dzb+O/fwAAANjodm+St/cNafBFL9PzXvcWvfPjn1UitqPP/NQ7VOjiqdgB3rQvBRUZZqoOeALy+pUZOVy1qqmrL+j51UxkBgAAKEkHfZM88H2v1/zYv2l1drKg51faTfKKDDN1jsK+7ejG6nVfu3ppVOf/8e809OKXq6qqsOu6C6wHAAAA9jrom+TJREySFI9GCnp+pd0kr8g9M/UOQ+5qI+/1jX/+8++Rs7ZWPcEXqL65TctTF/XkX/6JnLVuvfrBXyqoFne1UVHrGgEAAMpJwTfJ11fkaW7L+Vo6mdS//q//KWetW+39Jwu6bqXdJK/IMGMYhjrrHZqK5De+7uz3vkbf+pu/0Df/7JNK7GyrvrFFw694rb7vJx5Sa3d/3nWYZkbJtSV9/evf1tDQkLq6ugru7gAAAOBoxWIxzUxOqTrdrHS1M6/nfukjDykR3Vbv816ihvYOba8t61uP/IVWZsZ130//slx1nrzrqcSb5BU5mlmSHl/c1WMHcLjR7TBkqnljVhtPfV2xWExut1sDAwMaHBzU4OCg6usL24MDAACAg2eaphYXFzU+Pq6JiQnNz8/LNE3V3fMmpRs7JWP/a7y+/Xdf0lNf/jMtTpzT7taGXHUedZ25Qy9563/Q2Ze9uqD6BnxOvXmgoaDnlqqKDTObibQ+eW7D7jL03rNN8jkNLSwsWD8YCwsLkqSuri4NDg5qaGhIx44dk5HHDwgAAABuXywW0+TkpCYmJjQxMaGdnR3V1NSov7/fugE9GnMWwU1y6e7OOt3VUWdjFUevYsOMJH1+Yksz24Wf2Ho7DEl9XqfuH7w+PUejUesHZnJyUvF4XHV1dVawGRgYkNvtPvqiAQAAypxpmlpYWLA+i125ckWmaaq9vd36LHbixAlVX3O2YDHdJG905X/mYSmr6DAzubWnL0wVNiniILy536eBhppbPiaTyWh+fl7j4+MaHx/X0tKSDMPQ8ePHNTQ0pKGhIfn9fro2AAAABdrd3bVuIk9MTGh3d1culyun++Lz+W55jWK9SV7uKjrMmKapz09GNHvE/+EZknq9Tt0/4Ms7hEQikZyuzd7enjwej3WnoL+/X7W1tYdTOAAAQBnIZDLXdV8kqaOjwwovx48fz+m+PJdSuElejio6zEhSZC+tPzi/oeQRHpbqrJLec6ZJvprbawOm02nNzc1Ze21WVlZUVVWl7u5uK9y0tbXRtQEAABVvZ2cn54ZwLBZTbW1tTvfF6/UWfP1SvEleDio+zEhSeC2ur85Fj+z1XtvtUaDl4Lsnm5ubmpiY0Pj4uKanp5VMJuXz+azlaH19faqpqbzEDgAAKk8mk9GVK1c0Pj6uyclJa8BSZ2dnTvflII/FKOWb5KWKMPMd37i6oycWY4f+Ond1uHVP5+GPXE6lUpqdnbX22qyvr6u6ulo9PT1W16alpaUiEzwAAChPNxqiVFtbq8HBQev4C48n//Nb8lEuN8lLBWHmO0zT1GOLu3r8EAPNXR1u3d1RZ0uAWF9ft5ajTU9PK51Oq6mpyQo2vb29cjrzO+wJAADATtcOSpqYmNDi4qIk6dixY1b3xY5DycvtJnkxI8w8S3gtrkfno0pldCDrHQ1Jjirp3uPFk5qTyaSmp6etJWmbm5tyOBzq7e21lqQ1NTXZXSYAAMB1tre3re7L1NSU4vG43G63FV4GBgZsP3i83G+SFxPCzA1E9tJ6ZC6qme2kDBUWarLP6/U6dV+3p2jXMZqmqbW1NWs52uzsrDKZjFpaWjQ0NKTBwUH19PTI4XDYXSoAAKhA6XRaly9ftgLM0tKSpH8/XHxwcFDHjh078u7LflTCTXK7EWZuwjRNTUWSenolpqk8Qk32cf1ep57f5la/z1lSiTmRSGh6etpq10YiETmdTmvSx9DQkBoaKm+GOQAAODrXHkUxNTWlRCJhHSCe7b7U1ZXGSfeVdJPcDoSZfdhMpDW2kdDCTlILOynF0tf/k7mrDR2rd+hYvVPDTa6yOH3VNE0tLy9bwWZubk6maaqtrc1ajvbsE3ABAADylT1uIhtglpeXZRiG1X0ZGhpSZ2dnSd0gvlal3iQ/CoSZAkSTGcVSGaVNqdqQ3I4qeZzF19o8aPF4XFNTU1a4iUaj1um42SVptzOfHQAAVI6tra2c7sve3p7q6+tzui9ut9vuMg9cpd4kPyyEGRTENE0tLi5awWZ+fl6maVon5w4NDR347HYAAFC6UqlUTvdlZWVFhmHoxIkTGhgY0NDQkDo6Oiqu81CpN8kPCmEGB2J3d1eTk5PWL6jd3V3V1tZav5wGBwdtnywCAACO1ubmZs7REMlkUh6Px+q+9Pf3l2X3BUeHMIMDl8lktLCwYI1+zp64e+zYMWuvzbFjxyruzgsAAOXu2kO7Jycntbq6KsMw1N3dbQUYv9/PZwAcGMIMDl00GtXk5KT1iy0ej5fsRBIAAJBrY2PD6r7MzMwomUzK6/Vay877+vpUW8sYYRwOwgyO1I1O6jUMQ8ePH7d+6VXielkAAEpFMpm0ui8TExNaX19XVVVVTvelvb2d93IcCcIMbHXtHPnJyUnt7e1Za2mHhobU39/P3RwAAGy2trZmvV/PzMwolUrJ5/PldF9cLpfdZaICEWZQNLIn/I6Pj2t8fFwrKyuqqqrSiRMnrF+W3OkBAODwJZNJTU9PWwFmY2NDVVVV6unpsd6TW1tbeU+G7QgzKFqbm5s58+eTyWTOXaD+/n7V1NTYXSYAACXPNM3rui/pdFqNjY3W0rG+vj7ed1F0CDMoCddOR5mYmNDa2pp1hyg7Ia2lpYU7RAAA7NPe3l5O92Vzc1PV1dU53RfeW1HsCDMoSevr69bo5+za3cbGRivY9Pb2yul02l0mAABFwzRNra6uWtNFZ2dnlU6n1dTUZHVfent76b6gpBBmUPKSyaRmZmasvTabm5tyOBzq7e217iw1NzfbXSYAAEcukUjkdF+2trZy3iMHBwfV3NxM9wUlizCDspJd83vtvPtMJqOWlhYr2PT09MjhcNhdKgAAB840Ta2srFjvg3Nzc8pkMmpubs7pvrB6AeWCMIOytre3p6mpKeuXeiQSkdPpVF9fn4aGhjQ4OKjGxka7ywQAoGCJRMJ6r5ucnFQkEpHD4VBfX19O9wUoR4QZVIxr71aNj49rbm5Opmmqra3N6tp0d3erurra7lIBALgp0zS1tLRkLR27fPkyqxBQsQgzqFjxeDynaxONRlVTU6OBgQHrTpbP57O7TAAAct6zJicntb29ba00yL5nNTU12V0mcOQIM4Ceucu1uLhoBZv5+XmZpim/329NSDt+/LiqqqrsLhUAUAGy70vXdl9M01Rra2vOagK6L6h0hBngBmKxmCYnJ61ws7u7q9ra2pyujcfjsbtMAEAZyb73TE5O5qwYuLb7wj5PIBdhBngOpmlqYWHBCjZXrlyRJB07dsy6O3bs2DG6NgCAvJimqatXr1rdl+yqgPb2diu8sJcTuDXCDJCnnZ0d641nYmJC8XhcbrfbCjYDAwOqq6uzu0wAQBHa3d21Oi+Tk5Pa2dlRTU2N+vv7rQDT0NBgd5lAySDMALchk8lofn7e6tosLi7KMAx1dXVZe206Ojo4jAwAKtS13f3JyUlduXLF2pOZDS8nTpyg+wIUiDADHKDt7W1NTExYb1p7e3uqr6+3zrQZGBhQbW2t3WUCAA7Rzs5OTvdld3dXLpfL2nc5MDDAtEzggBBmgEOSTqd1+fJlq2uzvLwswzDU3d1tLUlrb2+nawMAJS6TyeTsrVxYWJAkdXR0WN2X48eP030BDgFhBjgiW1tb1hvd1NSUksmkvF6vtRytr69PLpfL7jIBAPsQjUZzui+xWCxn6uXAwIC8Xq/dZQJljzAD2CCVSmlubk7j4+MaHx/X2tqaqqqq1NPTY3VtWltb6doAQJHI7pHMDn+5evWqJKmzs9P6vd3V1cVkS+CIEWaAIrCxsWF1baanp5VKpdTY2Gi9Qfb29qqmpsbuMgGgokSjUSu8TE5OWtMrr+2+cOYYYC/CDFBkksmkZmZmrHCzsbGh6upq9fb2WkvSmpub7S4TAMpOJpPR5cuXrQCzuLgoiXPFgGJGmAGKmGmaWltbsyakzc7OKp1Oq7m52ZqQ1tvbK4fDYXepAFCSIpFIzt6XRCKhurq6nO5LfX293WUCuAnCDFBC9vb2ND09be21iUQicjqd6uvrs+4aNjY22l0mABSt7KTJbPdlaWlJknT8+HFr8lhnZyfdF6BEEGaAEmWaplZWVqzlaHNzc8pkMmptbbWWo3V3dzMKFEDFi0QiOdMks2eAZTsvAwMDqqurs7tMAAUgzABlIh6Pa2pqynrDjkajqqmpUX9/v7UkjUPaAFSCdDptTYycnJy0zvl6dveFiZFA6SPMAGXINE0tLS1Zy9Hm5+dlmqb8fr+1HO3EiRMsowBQNq49y2t6elp7e3vyeDxWeOnv75fb7ba7TAAHjDADVIBYLGZtcB0fH9fu7q5cLpcGBgasrg3jRQGUkmvP65qYmNDq6qoMw9CJEyesANPR0UH3BShzhBmgwpimqYWFBesDwJUrVyQ9c/Bbdq8No0cBFKONjQ1r4/709LSSyaS8Xq91Y6a/v1+1tbV2lwngCBFmgAq3s7OjyclJK9xkD4XL3tkcHBxkYywAW6RSKc3MzFgBZm1tTVVVVVb3ZWhoSO3t7XRfgApGmAFgyWQyunLlihVsrl69KunfR5YODQ2xaRbAoVpfX8/pvqRSKfl8vpy9Ly6Xy+4yARQJwgyAm9re3rY+VGQPk8uOM80u6WBDLYDbkUwmc7ov6+vrqqqqUnd3t/W7pq2tjZsoAG6IMANgX7IHzWW7NtlRp9cu9/D7/XzgAHBLpmlqfX3d+l0yOzurVCqlhoYGq/vS19dH9wXAvhBmABRka2vLmo42NTVlbcS9tmvDhxEAkrS3t5fTfdnY2FB1dbV6enqsANPa2srNEAB5I8wAuG03GpGaXSaSnZDGBxWgcpimqbW1tZzuSzqdVmNjY073paamxu5SAZQ4wgyAA7exsZFzeF12CUk22PT29vIhBigze3t7mp6e1vj4uCYnJ7W5uanq6mr19vZaAaalpYWbGgAOFGEGwKFKJpOanZ3V+Pi4xsfHreUl2Q84Q0NDamlpsbtMAHkyTVMrKyvW0rG5uTml02k1NTVZP9u9vb1yOp12lwqgjBFmAByZZ2/8nZmZUTqdVnNzs/Xhp6enhw8/QJFKJBI53ZetrS05HI7rui8AcFQIMwBsc+2ylImJCeuDUV9fn4aGhjQ4OKimpia7ywQqlmmaWl5ezum+ZDIZbkAAKBqEGQBF4dolK+Pj49aHptbW1pwPTdXV1XaXCpS1eDyuqakp63ypSCRi3WTIdl+am5vtLhMAJBFmABSpRCKhqakpa69NNBpVTU2N+vv7rXDj8/nsLhMoeaZpamlpyeq+XL58OedGwuDgoHp6euRwOOwuFQCuQ5gBUPSyH7ayy9EuX74s0zTV3t5uTUg7fvw4XRtgn+LxuCYnJ60AE41G5XQ61d/fr4GBAQ0NDamxsdHuMgHgORFmAJScWCyW80FsZ2dHLpdLAwMD1p1kr9drd5lA0TBNU4uLi9bG/ewNgba2Nutnpru7m+4LgJJDmAFQ0kzT1NWrV63laFeuXJEkdXZ2WsvRurq6VFVVZXOlwNG6Uei/dqnm4OCgGhoa7C4TAG4LYQZAWdnZ2cn5ABeLxeR2u62lMwMDA6qvr7e7TODAXRvsJyYmdOXKFWs55rXdF5ZjAignhBkAZSuTyejKlSvWh7urV69Kkrq6uqzRz8eOHeNEcpSs3d3dnPC+u7srl8uV031hUAaAckaYAVAxotGoNfp5cnJSiURC9fX11oe+gYEBud1uu8sEbiqTyWhhYcEKL9lllX6/31pWyTAMAJWEMAOgIqXTac3Pz1tdm6WlJRmGoRMnTlgfCv1+P10b2O5GSycZeAEAzyDMAICkSCRiBZupqSnt7e3J6/Vawaa/v18ul8vuMlEBsssjs+FlYWFBktTR0ZHTfWGoBQAQZgDgOqlUSnNzc9aStNXVVVVVVam7u9v6MNnW1kbXBgcmuwRycnJSk5OTisViqq2tzem+eDweu8sEgKJDmAGA57CxsWEFm+npaaVSKTU0NFjBpq+vTzU1NXaXiRKSyWQ0Pz9vdV+ywymOHTtmhRdGigPAcyPMAEAeksmkZmdnrXNtNjY2VF1drZ6eHg0NDWloaEjNzc10bXCd7e1tK7xMTU0pHo/L7XZbwycGBwcZGw4AeSLMAMBtWFtbs/bazMzMKJ1Oq6mpyRr93NvbK6fTaXeZsMG1QyYmJye1uLgo6ZnR4Nnuy7Fjx+i+AMBtIMwAwAHZ29vTzMyM1bXZ2tqSw+FQX1+ftSStqanJ7jJxiCKRSE73JZFIqK6uLmf8d11dnd1lAkDZIMwAwCEwTVOrq6tW12Z2dlaZTEYtLS3WcrTu7m45HA67Sz1wpmlqJ2VqN5VRxpSqDKnOUSWPs/w6EOl0WpcvX7b+d15eXpZhGNd1X1h2CACHgzADAEcgkUhoamrK+tC7vb0tp9Op/v5+a0laQ0OD3WUWbDOR1thGQld2krq6k1Isff1bi7vaUGe9Q131Tg03udToKs2DHbe2tnK6L3t7ezmHr/b399N9AYAjQpgBgCNmmqaWlpasCWmXL1+WaZpqb2+3lqOdOHGi6E9xN01TU5GknlqJaXo7KUPSft5Qso/r8zp1Z5tb/T5nUXcurh3VPTExoZWVFRmGoePHj1v/e3V0dBT19wAA5YowAwA2i8ViOV2bnZ0duVyunK5NsZ3wHtlL65G5qGbyCDHPln1er9ep+7o98tUUT3jb3NzM6b4kk0l5PJ6c7ovb7ba7TACoeIQZACgipmnq6tWrVrCZn5+X9Mzp79m9NnafPxJei+vR+ahSmcJCzLMZkhxV0r3HPQq01B7AFfOXSqU0OztrBZjV1VUZhqHu7m4NDAxoaGhIfr+f7gsAFBnCDAAUsd3dXesD9sTEhGKxmNxud87J8Ed1Nolpmvrm4q6eWIwd2mu8tMOtezrqjiQ0bGxs5IzVTiaT8nq9Od2X2lp7whUAYH8IMwBQIjKZjBYWFqzRz9lT47OTs4aGhg51ctY3ru4capDJuqvDrXs6Dz6gZQ88zQbDtbU1VVVVqbu72wow7e3tdF8AoIQQZgCgREWj0ZyuzbVnmgwNDWlgYODA9nWE1+L66lz0QK61H6/tPpglZ+vr6zndl1QqJZ/Pl9N9cblcB1AxAMAOhBkAKAOZTCbnvJOlpaUDm7gV2UvrD85vKJk5hMJvwlklvedMU95DAZLJpHVw6eTkpNbX11VVVaWenh4rwLS1tdF9AYAyQZgBgDKUPYl+fHzcOgslO41raGho3/tBTNPU5ycjmt1OHshm//0yJPV4nXrLgO+WwcM0Ta2trVndqZmZGaXTaTU0NFjfa19fn2pqao6ueADAkSHMAECZS6fTmpubs/barK6uqqqqSidOnLAmpN2sWzG5tacvTEUKfu3//Ycf1aO/+6vyD5zWT33hm3k//839Pg005AaRvb09q/syMTGhzc1NVVdX53RfWltb6b4AQAUgzABAhdnc3LSCwNTUlLWPJBtsru1kfH5iSzMFdmW2lhb0W296iQxDajrWnXeYMfTMwZpvHvBpdXXV6r7Mzs4qnU6rqanJCi+9vb10XwCgAhFmAKCCpVIpzczMWEvS1tfXrS5H19BpPenqK/jaf/6h92hnY02ZTFq7m+sFdWZkmqp58svaXlpQdXW1ent7reVjzc3NdF8AoMIRZgAAluz+k/Hxcc06mlU1dKeMAg7onH76Cf3he39QD3726/qrX/+F2wgzGXVEF3RXZ716e3vldDrzvwYAoGw57C4AAFA8Wlpa1NLSohe96EX63PiGZqKpvK+RSaf1V7/+i7rzje9Qx9DZ2yvIqFJ9V5+GBhpu7zoAgLJEmAEAXMc0TS3FMnpm50p+/uWLn9bm1cv68U9+8UBqWdjJP1ABACpD/msHAABlbydlKpbOfxXyzua6vvbJX9Mr3vMz8jS1HkgtsbSp6FEecgMAKBmEGQDAdXZThYWHr/3ur6rO16iXvPU/HGg9sQLrAQCUN5aZAQCukylgNMzq3KSe/MvP6HUP/Yq2Vxatr6cSCaVTSW0szMlV71VdQ1Pe1y6gSQQAqABMMwMAXGc5ltIfXdjM6zlTTz2uP/iJN97yMS9920/o9T/7kbzr+fHTjWpzc/8NAJCLdwYAwHXqHPmvQvYPnNY7fuuPr/v61373V5XYiep1P/sRtRzvLagedwH1AADKH2EGAHCdeochd7WR1xCA+qYWDX/vfdd9/fHP/r4k3fDv9sNdbcjjJMwAAK7HuwMA4DqGYaizvjjudx0rkjoAAMWHPTMAgBt6fHFXj13dlZ1vEoakuzvrdFdHnY1VAACKFZ0ZAMANDTe5bA0ykmR+pw4AAG6EMAMAuKFGV7X6vE4ZNr2+Ianf61Sjq9qmCgAAxY4wAwC4qTvb3LZ1Z0xJz29z2/TqAIBSQJgBANxUv8+pXhu6M4akPq9T/T7nEb8yAKCUEGYAADdlGIbu6/boqI95cVRJr+n2yDDsWuQGACgFhBkAwC35aqp173HPkb7mvcc98tWwVwYAcGuEGQDAcwq01OqlHUezf+WuDrcCLbVH8loAgNJGmAEA7Ms9HXW665ADzV0dbt3NmTIAgH3i0EwAQF7Ca3E9Oh9VKqMDmXRm6Jk9Mvce99CRAQDkhTADAMhbZC+tR+aimtlOylBhoSb7vF6vU/d1s0cGAJA/wgwAoCCmaWoqktTTKzFN5RFqso/r9zr1/Da3+n1OppYBAApCmAEA3LbNRFpjGwkt7CS1sJNSLH39W4u72tCxeoeO1Ts13ORSo4tODADg9hBmAAAHLprMKJbKKG1K1YbkdlTJ42TmDADgYBFmAAAAAJQkbpMBAAAAKEmEGQAAAAAliTADAAAAoCQRZgAAAACUJMIMAAAAgJJEmAEAAABQkggzAAAAAEoSYQYAAABASSLMAAAAAChJhBkAAAAAJYkwAwAAAKAkEWYAAAAAlCTCDAAAAICSRJgBAAAAUJIIMwAAAABKEmEGAAAAQEkizAAAAAAoSYQZAAAAACWJMAMAAACgJBFmAAAAAJQkwgwAAACAkkSYAQAAAFCSCDMAAAAAShJhBgAAAEBJIswAAAAAKEmEGQAAAAAliTADAAAAoCQRZgAAAACUJMIMAAAAgJJEmAEAAABQkggzAAAAAEoSYQYAAABASSLMAAAAAChJhBkAAAAAJYkwAwAAAKAkEWYAAAAAlCTCDAAAAICSRJgBAAAAUJIIMwAAAABKEmEGAAAAQEkizAAAAAAoSYQZAAAAACXp/wePJy5reXaI1wAAAABJRU5ErkJggg==\n"},"metadata":{}}]},{"cell_type":"markdown","source":["## IP-ADMG-Prune"],"metadata":{"id":"jvL1vztarQjx"}},{"cell_type":"code","source":["!pip install cplex gurobipy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T3MZArg2s-3M","executionInfo":{"status":"ok","timestamp":1748516478544,"user_tz":-60,"elapsed":9810,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"}},"outputId":"a431e9f5-f7f9-461b-bac5-1c52e138f764"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting cplex\n","  Downloading cplex-22.1.2.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (56 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/57.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cplex-22.1.2.0-cp311-cp311-manylinux2014_x86_64.whl (44.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: cplex\n","Successfully installed cplex-22.1.2.0\n"]}]},{"cell_type":"code","source":["import cplex\n","\n","def Prune_scores(instance, originalScores,filename, prune_more=False):\n","\t\tt0P = time.time()\n","\t\tsum1 = 0\n","\t\tsum2 = 0\n","\t\tDpars = {}\n","\t\tfor D in originalScores.keys():\n","\t\t\tif len(D[0]) == 1:\n","\t\t\t\tDpars[D] = list(originalScores[D].keys())\n","\t\t\t\tDparscopy = Dpars[D].copy()\n","\t\t\t\tfor ind in range(len(Dpars[D])):\n","\t\t\t\t\tfor i in range(ind+1,len(originalScores[D])):\n","\t\t\t\t\t\tif set(Dpars[D][ind][0]).difference(set(Dpars[D][i][0])) == set() and originalScores[D][Dpars[D][ind]] >= originalScores[D][Dpars[D][i]]:\n","\t\t\t\t\t\t\tif Dpars[D][i] in Dparscopy:\n","\t\t\t\t\t\t\t\tDparscopy.remove(Dpars[D][i])\n","\t\t\t\tsum1 = sum1+len(Dpars[D])\n","\t\t\t\tDpars[D] = Dparscopy.copy()\n","\t\t\t\tsum2 = sum2+len(Dpars[D])\n","\n","\t\t\t# size 2 c-component\n","\t\t\telif len(D[0]) == 2:\n","\t\t\t\tDpars[D] = list(originalScores[D].keys())\n","\t\t\t\tDparscopy = Dpars[D].copy()\n","\t\t\t\tfor ind in range(len(Dpars[D])):\n","\t\t\t\t\t# a = D[0][0], b = D[0][1]\n","\t\t\t\t\t# a<->b vs a<->b\n","\t\t\t\t\tdelInd = False\n","\t\t\t\t\tfor i in range(ind):\n","\t\t\t\t\t\tif set(Dpars[D][i][0]).difference(set(Dpars[D][ind][0])) == set() and set(Dpars[D][i][1]).difference(set(Dpars[D][ind][1])) == set() and originalScores[D][Dpars[D][ind]] <= originalScores[D][Dpars[D][i]]:\n","\t\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\t\tdelInd = True\n","\t\t\t\t\t\t\tbreak\n","\t\t\t\t\tif delInd == True:\n","\t\t\t\t\t\tcontinue\n","\t\t\t\t\t# a<->b vs a,b\n","\t\t\t\t\tDa = ((D[0][0],),())\n","\t\t\t\t\tDb = ((D[0][1],),())\n","\t\t\t\t\tDaPars = list(originalScores[Da].keys())\n","\t\t\t\t\tDbPars = list(originalScores[Db].keys())\n","\t\t\t\t\tmaxa = -float('inf')\n","\t\t\t\t\tmaxb = -float('inf')\n","\t\t\t\t\tfor ind1 in range(len(DaPars)):\n","\t\t\t\t\t\tif set(DaPars[ind1][0]).difference(set(Dpars[D][ind][0])) == set() and originalScores[Da][DaPars[ind1]] > maxa:\n","\t\t\t\t\t\t\tmaxa = originalScores[Da][DaPars[ind1]]\n","\t\t\t\t\tfor ind2 in range(len(DbPars)):\n","\t\t\t\t\t\tif set(DbPars[ind2][0]).difference(set(Dpars[D][ind][1])) == set() and originalScores[Db][DbPars[ind2]] > maxb:\n","\t\t\t\t\t\t\tmaxb = originalScores[Db][DbPars[ind2]]\n","\t\t\t\t\tif originalScores[D][Dpars[D][ind]] <= maxa+maxb:\n","\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\tcontinue\n","\t\t\t\t\ttol = 1e-10\n","\t\t\t\t\t# a<->b vs a->b\n","\t\t\t\t\tDa = ((D[0][0],),())\n","\t\t\t\t\tDb = ((D[0][1],),())\n","\t\t\t\t\tDbPars = list(originalScores[Db].keys())\n","\t\t\t\t\tmaxa = originalScores[Da][((),)]\n","\t\t\t\t\tmaxb = -float('inf')\n","\t\t\t\t\tfor ind2 in range(len(DbPars)):\n","\t\t\t\t\t\tif set(DbPars[ind2][0]).difference(set(Dpars[D][ind][1])) == {D[0][0]} and originalScores[Db][DbPars[ind2]] > maxb:\n","\t\t\t\t\t\t\tmaxb = originalScores[Db][DbPars[ind2]]\n","\t\t\t\t\tif originalScores[D][Dpars[D][ind]] <= maxa+maxb+tol:\n","\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\tcontinue\n","\t\t\t\t\t# a<->b vs a<-b\n","\t\t\t\t\tDa = ((D[0][0],),())\n","\t\t\t\t\tDb = ((D[0][1],),())\n","\t\t\t\t\tDaPars = list(originalScores[Da].keys())\n","\t\t\t\t\tmaxa = -float('inf')\n","\t\t\t\t\tmaxb = originalScores[Db][((),)]\n","\t\t\t\t\tfor ind1 in range(len(DaPars)):\n","\t\t\t\t\t\tif set(DaPars[ind1][0]).difference(set(Dpars[D][ind][0])) == {D[0][1]} and originalScores[Da][DaPars[ind1]] > maxa:\n","\t\t\t\t\t\t\tmaxa = originalScores[Da][DaPars[ind1]]\n","\t\t\t\t\tif originalScores[D][Dpars[D][ind]] <= maxa+maxb+tol:\n","\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\tcontinue\n","\t\t\t\tsum1 = sum1+len(Dpars[D])\n","\t\t\t\tDpars[D] = Dparscopy.copy()\n","\t\t\t\tsum2 = sum2+len(Dpars[D])\n","\t\t\telif len(D[0]) == 3:\n","\t\t\t\tDpars[D] = list(originalScores[D].keys())\n","\t\t\t\tDparscopy = Dpars[D].copy()\n","\t\t\t\tfor ind in range(len(Dpars[D])):\n","\t\t\t\t\t# a<->b<->c\n","\t\t\t\t\tif len(D[1]) == 2:\n","\t\t\t\t\t\tNodeb = 0\n","\t\t\t\t\t\tfor i in D[0]:\n","\t\t\t\t\t\t\tif i in D[1][0] and i in D[1][1]:\n","\t\t\t\t\t\t\t\tNodeb = i\n","\t\t\t\t\t\t\t\tbreak\n","\t\t\t\t\t\tNodea = 0\n","\t\t\t\t\t\tfor i in D[0]:\n","\t\t\t\t\t\t\tif i != Nodeb and i in D[1][0]:\n","\t\t\t\t\t\t\t\tNodea = i\n","\t\t\t\t\t\t\t\tbreak\n","\t\t\t\t\t\tNodec = 0\n","\t\t\t\t\t\tfor i in D[0]:\n","\t\t\t\t\t\t\tif i != Nodeb and i in D[1][1]:\n","\t\t\t\t\t\t\t\tNodec = i\n","\t\t\t\t\t\t\t\tbreak\n","\t\t\t\t\t\tif prune_more == True and (Nodea in Dpars[D][ind][D[0].index(Nodec)] or Nodec in Dpars[D][ind][D[0].index(Nodea)]):\n","\t\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\t\tcontinue\n","\t\t\t\t\t\tDa = ((Nodea,),())\n","\t\t\t\t\t\tDb = ((Nodeb,),())\n","\t\t\t\t\t\tDc = ((Nodec,),())\n","\t\t\t\t\t\tDab = (tuple(sorted((Nodea,Nodeb))),(tuple(sorted((Nodea,Nodeb))),))\n","\t\t\t\t\t\tDbc = (tuple(sorted((Nodeb,Nodec))),(tuple(sorted((Nodeb,Nodec))),))\n","\t\t\t\t\t\t# a<->b<->c vs a,b,c\n","\t\t\t\t\t\tDaPars = list(originalScores[Da].keys())\n","\t\t\t\t\t\tDbPars = list(originalScores[Db].keys())\n","\t\t\t\t\t\tDcPars = list(originalScores[Dc].keys())\n","\t\t\t\t\t\tmaxa = -float('inf')\n","\t\t\t\t\t\tmaxb = -float('inf')\n","\t\t\t\t\t\tmaxc = -float('inf')\n","\t\t\t\t\t\tfor ind1 in range(len(DaPars)):\n","\t\t\t\t\t\t\tif set(DaPars[ind1][0]).difference(set(Dpars[D][ind][D[0].index(Nodea)])) == set() and originalScores[Da][DaPars[ind1]] > maxa:\n","\t\t\t\t\t\t\t\tmaxa = originalScores[Da][DaPars[ind1]]\n","\t\t\t\t\t\tfor ind2 in range(len(DbPars)):\n","\t\t\t\t\t\t\tif set(DbPars[ind2][0]).difference(set(Dpars[D][ind][D[0].index(Nodeb)])) == set() and originalScores[Db][DbPars[ind2]] > maxb:\n","\t\t\t\t\t\t\t\tmaxb = originalScores[Db][DbPars[ind2]]\n","\t\t\t\t\t\tfor ind3 in range(len(DcPars)):\n","\t\t\t\t\t\t\tif set(DcPars[ind3][0]).difference(set(Dpars[D][ind][D[0].index(Nodec)])) == set() and originalScores[Dc][DcPars[ind3]] > maxc:\n","\t\t\t\t\t\t\t\tmaxc = originalScores[Dc][DcPars[ind3]]\n","\t\t\t\t\t\tif originalScores[D][Dpars[D][ind]] <= maxa+maxb+maxc:\n","\t\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\t\tcontinue\n","\t\t\t\t\t\t# a<->b<->c vs a<->b,c\n","\t\t\t\t\t\tDabPars = list(originalScores[Dab].keys())\n","\t\t\t\t\t\tDbcPars = list(originalScores[Dbc].keys())\n","\t\t\t\t\t\tmaxab = -float('inf')\n","\t\t\t\t\t\tmaxbc = -float('inf')\n","\t\t\t\t\t\tabInda = 0\n","\t\t\t\t\t\tabIndb = 1\n","\t\t\t\t\t\tif Nodea > Nodeb:\n","\t\t\t\t\t\t\tabInda = 1\n","\t\t\t\t\t\t\tabIndb = 0\n","\t\t\t\t\t\tfor ind1 in range(len(DabPars)):\n","\t\t\t\t\t\t\tif set(DabPars[ind1][abInda]).difference(set(Dpars[D][ind][D[0].index(Nodea)])) == set() and set(DabPars[ind1][abIndb]).difference(set(Dpars[D][ind][D[0].index(Nodeb)])) == set() and originalScores[Dab][DabPars[ind1]] > maxab:\n","\t\t\t\t\t\t\t\tmaxab = originalScores[Dab][DabPars[ind1]]\n","\t\t\t\t\t\tif originalScores[D][Dpars[D][ind]] <= maxab+maxc:\n","\t\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\t\tcontinue\n","\t\t\t\t\t\t# a<->b<->c vs a,b<->c\n","\t\t\t\t\t\tbcIndb = 0\n","\t\t\t\t\t\tbcIndc = 1\n","\t\t\t\t\t\tif Nodeb > Nodec:\n","\t\t\t\t\t\t\tbcIndb = 1\n","\t\t\t\t\t\t\tbcIndc = 0\n","\t\t\t\t\t\tfor ind1 in range(len(DbcPars)):\n","\t\t\t\t\t\t\tif set(DbcPars[ind1][bcIndb]).difference(set(Dpars[D][ind][D[0].index(Nodeb)])) == set() and set(DbcPars[ind1][bcIndc]).difference(set(Dpars[D][ind][D[0].index(Nodec)])) == set() and originalScores[Dbc][DbcPars[ind1]] > maxbc:\n","\t\t\t\t\t\t\t\tmaxbc = originalScores[Dbc][DbcPars[ind1]]\n","\t\t\t\t\t\tif originalScores[D][Dpars[D][ind]] <= maxa+maxbc:\n","\t\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\t\tcontinue\n","\t\t\t\t\t\t# a<->b<->c vs a<->b<->c\n","\t\t\t\t\t\tdelInd = False\n","\t\t\t\t\t\tfor i in range(ind):\n","\t\t\t\t\t\t\tif set(Dpars[D][i][0]).difference(set(Dpars[D][ind][0])) == set() and set(Dpars[D][i][1]).difference(set(Dpars[D][ind][1])) == set() and set(Dpars[D][i][2]).difference(set(Dpars[D][ind][2])) == set() and originalScores[D][Dpars[D][ind]] <= originalScores[D][Dpars[D][i]]:\n","\t\t\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\t\t\tdelInd = True\n","\t\t\t\t\t\t\t\tbreak\n","\t\t\t\t\t\tif delInd == True:\n","\t\t\t\t\t\t\tcontinue\n","\t\t\t\t\t# a<->b<->c<->a\n","\t\t\t\t\tif len(D[1]) == 3:\n","\t\t\t\t\t\tNodea = D[0][0]\n","\t\t\t\t\t\tNodeb = D[0][1]\n","\t\t\t\t\t\tNodec = D[0][2]\n","\t\t\t\t\t\tDab = ((Nodea,Nodeb),((Nodea,Nodeb),))\n","\t\t\t\t\t\tDbc = ((Nodeb,Nodec),((Nodeb,Nodec),))\n","\t\t\t\t\t\tDac = ((Nodea,Nodec),((Nodea,Nodec),))\n","\t\t\t\t\t\tDabc = ((Nodea,Nodeb,Nodec),((Nodea,Nodeb),(Nodeb,Nodec)))\n","\t\t\t\t\t\tif Dabc not in originalScores.keys():\n","\t\t\t\t\t\t\tDabc = ((Nodea,Nodeb,Nodec),((Nodeb,Nodec),(Nodea,Nodeb)))\n","\t\t\t\t\t\tDbca = ((Nodea,Nodeb,Nodec),((Nodeb,Nodec),(Nodea,Nodec)))\n","\t\t\t\t\t\tif Dbca not in originalScores.keys():\n","\t\t\t\t\t\t\tDbca = ((Nodea,Nodeb,Nodec),((Nodea,Nodec),(Nodeb,Nodec)))\n","\t\t\t\t\t\tDcab = ((Nodea,Nodeb,Nodec),((Nodea,Nodec),(Nodeb,Nodec)))\n","\t\t\t\t\t\tif Dcab not in originalScores.keys():\n","\t\t\t\t\t\t\tDcab = ((Nodea,Nodeb,Nodec),((Nodeb,Nodec),(Nodea,Nodec)))\n","\t\t\t\t\t\tDaPars = list(originalScores[Da].keys())\n","\t\t\t\t\t\tDbPars = list(originalScores[Db].keys())\n","\t\t\t\t\t\tDcPars = list(originalScores[Dc].keys())\n","\t\t\t\t\t\tmaxa = -float('inf')\n","\t\t\t\t\t\tmaxb = -float('inf')\n","\t\t\t\t\t\tmaxc = -float('inf')\n","\t\t\t\t\t\tfor ind1 in range(len(DaPars)):\n","\t\t\t\t\t\t\tif set(DaPars[ind1][0]).difference(set(Dpars[D][ind][D[0].index(Nodea)])) == set() and originalScores[Da][DaPars[ind1]] > maxa:\n","\t\t\t\t\t\t\t\tmaxa = originalScores[Da][DaPars[ind1]]\n","\t\t\t\t\t\tfor ind2 in range(len(DbPars)):\n","\t\t\t\t\t\t\tif set(DbPars[ind2][0]).difference(set(Dpars[D][ind][D[0].index(Nodeb)])) == set() and originalScores[Db][DbPars[ind2]] > maxb:\n","\t\t\t\t\t\t\t\tmaxb = originalScores[Db][DbPars[ind2]]\n","\t\t\t\t\t\tfor ind3 in range(len(DcPars)):\n","\t\t\t\t\t\t\tif set(DcPars[ind3][0]).difference(set(Dpars[D][ind][D[0].index(Nodec)])) == set() and originalScores[Dc][DcPars[ind3]] > maxc:\n","\t\t\t\t\t\t\t\tmaxc = originalScores[Dc][DcPars[ind3]]\n","\t\t\t\t\t\tDabPars = list(originalScores[Dab].keys())\n","\t\t\t\t\t\tDbcPars = list(originalScores[Dbc].keys())\n","\t\t\t\t\t\tDacPars = list(originalScores[Dac].keys())\n","\t\t\t\t\t\tmaxab = -float('inf')\n","\t\t\t\t\t\tmaxbc = -float('inf')\n","\t\t\t\t\t\tmaxac = -float('inf')\n","\t\t\t\t\t\tfor ind1 in range(len(DabPars)):\n","\t\t\t\t\t\t\tif set(DabPars[ind1][0]).difference(set(Dpars[D][ind][D[0].index(Nodea)])) == set() and set(DabPars[ind1][1]).difference(set(Dpars[D][ind][D[0].index(Nodeb)])) == set() and originalScores[Dab][DabPars[ind1]] > maxab:\n","\t\t\t\t\t\t\t\tmaxab = originalScores[Dab][DabPars[ind1]]\n","\t\t\t\t\t\tfor ind1 in range(len(DbcPars)):\n","\t\t\t\t\t\t\tif set(DbcPars[ind1][0]).difference(set(Dpars[D][ind][D[0].index(Nodeb)])) == set() and set(DbcPars[ind1][1]).difference(set(Dpars[D][ind][D[0].index(Nodec)])) == set() and originalScores[Dbc][DbcPars[ind1]] > maxbc:\n","\t\t\t\t\t\t\t\tmaxbc = originalScores[Dbc][DbcPars[ind1]]\n","\t\t\t\t\t\tfor ind1 in range(len(DacPars)):\n","\t\t\t\t\t\t\tif set(DacPars[ind1][0]).difference(set(Dpars[D][ind][D[0].index(Nodea)])) == set() and set(DacPars[ind1][1]).difference(set(Dpars[D][ind][D[0].index(Nodec)])) == set() and originalScores[Dac][DacPars[ind1]] > maxac:\n","\t\t\t\t\t\t\t\tmaxac = originalScores[Dac][DacPars[ind1]]\n","\t\t\t\t\t\tDabcPars = list(originalScores[Dabc].keys())\n","\t\t\t\t\t\tDbcaPars = list(originalScores[Dbca].keys())\n","\t\t\t\t\t\tDcabPars = list(originalScores[Dcab].keys())\n","\t\t\t\t\t\tmaxabc = -float('inf')\n","\t\t\t\t\t\tmaxbca = -float('inf')\n","\t\t\t\t\t\tmaxcab = -float('inf')\n","\t\t\t\t\t\tfor ind1 in range(len(DabcPars)):\n","\t\t\t\t\t\t\tif set(DabcPars[ind1][0]).difference(set(Dpars[D][ind][D[0].index(Nodea)])) == set() and set(DabcPars[ind1][1]).difference(set(Dpars[D][ind][D[0].index(Nodeb)])) == set() and set(DabcPars[ind1][2]).difference(set(Dpars[D][ind][D[0].index(Nodec)])) == set() and originalScores[Dabc][DabcPars[ind1]] > maxabc:\n","\t\t\t\t\t\t\t\tmaxabc = originalScores[Dabc][DabcPars[ind1]]\n","\t\t\t\t\t\tfor ind1 in range(len(DbcaPars)):\n","\t\t\t\t\t\t\tif set(DbcaPars[ind1][0]).difference(set(Dpars[D][ind][D[0].index(Nodea)])) == set() and set(DbcaPars[ind1][1]).difference(set(Dpars[D][ind][D[0].index(Nodeb)])) == set() and set(DbcaPars[ind1][2]).difference(set(Dpars[D][ind][D[0].index(Nodec)])) == set() and originalScores[Dbca][DbcaPars[ind1]] > maxbca:\n","\t\t\t\t\t\t\t\tmaxbca = originalScores[Dbca][DbcaPars[ind1]]\n","\t\t\t\t\t\tfor ind1 in range(len(DcabPars)):\n","\t\t\t\t\t\t\tif set(DcabPars[ind1][0]).difference(set(Dpars[D][ind][D[0].index(Nodea)])) == set() and set(DcabPars[ind1][1]).difference(set(Dpars[D][ind][D[0].index(Nodeb)])) == set() and set(DcabPars[ind1][2]).difference(set(Dpars[D][ind][D[0].index(Nodec)])) == set() and originalScores[Dcab][DcabPars[ind1]] > maxcab:\n","\t\t\t\t\t\t\t\tmaxcab = originalScores[Dcab][DcabPars[ind1]]\n","\t\t\t\t\t\t# vs a,b,c\n","\t\t\t\t\t\tif originalScores[D][Dpars[D][ind]] <= maxa+maxb+maxc:\n","\t\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\t\tcontinue\n","\t\t\t\t\t\t# vs a<->b,c\n","\t\t\t\t\t\tif originalScores[D][Dpars[D][ind]] <= maxab+maxc:\n","\t\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\t\tcontinue\n","\t\t\t\t\t\t# vs a, b<->c\n","\t\t\t\t\t\tif originalScores[D][Dpars[D][ind]] <= maxa+maxbc:\n","\t\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\t\tcontinue\n","\t\t\t\t\t\t# vs b, c<->a\n","\t\t\t\t\t\tif originalScores[D][Dpars[D][ind]] <= maxac+maxb:\n","\t\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\t\tcontinue\n","\t\t\t\t\t\t# vs a<->b<->c\n","\t\t\t\t\t\tif originalScores[D][Dpars[D][ind]] <= maxabc:\n","\t\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\t\tcontinue\n","\t\t\t\t\t\t# vs b<->c<->a\n","\t\t\t\t\t\tif originalScores[D][Dpars[D][ind]] <= maxbca:\n","\t\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\t\tcontinue\n","\t\t\t\t\t\t# vs c<->a<->b\n","\t\t\t\t\t\tif originalScores[D][Dpars[D][ind]] <= maxcab:\n","\t\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\t\tcontinue\n","\t\t\t\t\t\t# vs a<->b<->c<->a\n","\t\t\t\t\t\tdelInd = False\n","\t\t\t\t\t\tfor i in range(ind):\n","\t\t\t\t\t\t\tif set(Dpars[D][i][0]).difference(set(Dpars[D][ind][0])) == set() and set(Dpars[D][i][1]).difference(set(Dpars[D][ind][1])) == set() and set(Dpars[D][i][2]).difference(set(Dpars[D][ind][2])) == set() and originalScores[D][Dpars[D][ind]] <= originalScores[D][Dpars[D][i]]:\n","\t\t\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\t\t\tdelInd = True\n","\t\t\t\t\t\t\t\tbreak\n","\t\t\t\t\t\tif delInd == True:\n","\t\t\t\t\t\t\tcontinue\n","\t\t\t\tsum1 = sum1+len(Dpars[D])\n","\t\t\t\tDpars[D] = Dparscopy.copy()\n","\t\t\t\tsum2 = sum2+len(Dpars[D])\n","\t\t\telse:\n","\t\t\t\tDpars[D] = list(originalScores[D].keys())\n","\t\t\t\tsum1 = sum1+len(Dpars[D])\n","\t\t\t\tsum2 = sum2+len(Dpars[D])\n","\t\tprint(str(sum1)+\" vs \"+str(sum2)+\", pruning time: \"+str(time.time()-t0P))\n","\t\tfileName = f'{filename} + _cplex.log'\n","\t\t# if not os.path.exists('../content/Results/'):\n","\t\t#   \tos.makedirs('../content/Results/')\n","\t\tf = open(fileName,\"a\")\n","\t\tf.write(str(sum1)+\" vs \"+str(sum2)+\", pruning time: \"+str(time.time()-t0P))\n","\t\tf.close()\n","\n","\t\tscores = {}\n","\t\tfor D in originalScores.keys():\n","\t\t\tfor Dpar in Dpars[D]:\n","\t\t\t\tif D not in scores.keys():\n","\t\t\t\t\tscores[D] = {}\n","\t\t\t\tscores[D][Dpar] = originalScores[D][Dpar]\n","\n","\n","def Initialize(instance, originalScores, filename, prune=True,dag=False,printsc=False,prune_parentInDistrict=False):\n","\t\tif prune == True:\n","\t\t\tscores = Prune_scores(instance,originalScores,filename, prune_more=prune_parentInDistrict)\n","\t\telse:\n","\t\t\tscores = originalScores\n","\t\tprint(scores)\n","\t\tV = set()\n","\t\tcComps = []\n","\t\tfor D in scores.keys():\n","\t\t\tcComps.append(D)\n","\t\t\tV = V.union(set(D[0]))\n","\t\tiComps = {}\n","\t\tfor i in V:\n","\t\t\tiComps[i] = []\n","\t\t\tfor D in cComps:\n","\t\t\t\tif i in D[0]:\n","\t\t\t\t\tiComps[i].append(cComps.index(D))\n","\t\tdPars = {}\n","\t\tfor d in range(len(cComps)):\n","\t\t\tdPars[d] = []\n","\t\t\tfor par in scores[cComps[d]].keys():\n","\t\t\t\tdPars[d].append(par)\n","\t\tiPars = {}\n","\t\tfor i in V:\n","\t\t\tiPars[i] = []\n","\t\t\tfor d in iComps[i]:\n","\t\t\t\tfor W in dPars[d]:\n","\t\t\t\t\tif W[cComps[d][0].index(i)] not in iPars[i]:\n","\t\t\t\t\t\tiPars[i].append(W[cComps[d][0].index(i)])\n","\t\tif printsc == True:\n","\t\t\tfor d in range(len(cComps)):\n","\t\t\t\tprint(str(cComps[d])+':')\n","\t\t\t\tprint(scores[cComps[d]])\n","\t\t\t\tprint('\\n')\n","\n","\n","\t\tbiPars = {}\n","\t\tfor D in cComps:\n","\t\t\tfor bi in D[1]:\n","\t\t\t\tif bi not in biPars.keys():\n","\t\t\t\t\tbiPars[bi] = []\n","\t\t\t\tfor W in dPars[cComps.index(D)]:\n","\t\t\t\t\tbiPar = (W[D[0].index(bi[0])],W[D[0].index(bi[1])])\n","\t\t\t\t\tif biPar not in biPars[bi]:\n","\t\t\t\t\t\tbiPars[bi].append(biPar)\n","\t\tm = cplex.Cplex()\n","\t\tz = {}\n","\t\tfor d in range(len(cComps)):\n","\t\t\tfor dp in range(len(dPars[d])):\n","\t\t\t\tif dag == False or len(cComps[d][0]) <= 1:\n","\t\t\t\t\tz[d,dp] = m.variables.add(obj=[scores[cComps[d]][dPars[d][dp]]],lb=[0],ub=[1],types=['B'],names=['z'+str(d)+','+str(dp)])\n","\t\t\t\telse:\n","\t\t\t\t\tz[d,dp] = m.variables.add(obj=[scores[cComps[d]][dPars[d][dp]]],lb=[0],ub=[0],types=['B'],names=['z'+str(d)+','+str(dp)])\n","\n","\t\tm.objective.set_sense(m.objective.sense.maximize)\n","\n","\n","\t\tfor i in V:\n","\t\t\tm.linear_constraints.add(lin_expr=[cplex.SparsePair(ind = ['z'+str(d)+','+str(dp) for d in iComps[i] for dp in range(len(dPars[d]))], val = [1]*sum(len(dPars[d]) for d in iComps[i]))], senses=[\"E\"], rhs=[1])\n","\n","\t\tindInv = []\n","\t\tfor i in V:\n","\t\t\tfor j in range(i+1,len(V)):\n","\t\t\t\tindInv.append((i,j))\n","\n","\t\tudE = range(len(indInv))\n","\n","\t\tbi = {}\n","\t\tfor e in udE:\n","\t\t\tbi[e] = m.variables.add(obj=[0],types=['C'],names=['bi'+str(e)])\n","\t\t\tzindex_set = ['z'+str(d)+','+str(dp) for d in range(len(cComps)) for dp in range(len(dPars[d])) if indInv[e] in cComps[d][1]]\n","\t\t\tm.linear_constraints.add(lin_expr=[cplex.SparsePair(ind = zindex_set+['bi'+str(e)], val = [1]*len(zindex_set)+[-1])], senses=[\"E\"], rhs=[0])\n","\n","\t\tx = {}\n","\t\tfor i in V:\n","\t\t\tfor ip in range(len(iPars[i])):\n","\t\t\t\tx[i,ip] = m.variables.add(obj=[0],types=['C'],names=['x'+str(i)+','+str(ip)])\n","\t\t\t\tzindex_set = ['z'+str(d)+','+str(dp) for d in iComps[i] for dp in range(len(dPars[d])) if dPars[d][dp][cComps[d][0].index(i)] == iPars[i][ip]]\n","\t\t\t\tm.linear_constraints.add(lin_expr=[cplex.SparsePair(ind = zindex_set+['x'+str(i)+','+str(ip)], val = [1]*len(zindex_set)+[-1])], senses=[\"E\"], rhs=[0])\n"],"metadata":{"id":"omdkH6hbQFZo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cCg4VrPYXTAb"},"source":["## Treewidth and Cliquewidth"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j35yqc8yUZjA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747054630588,"user_tz":-120,"elapsed":24,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"}},"outputId":"0a86975d-e61e-4487-a548-daf482c51bee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Optimized Causal Inference Parameters:\n","Treewidth: 9\n","Clique-width: 2\n","Branchwidth: 15.0\n"]},{"output_type":"execute_result","data":{"text/plain":["(9, 2, 15.0)"]},"metadata":{},"execution_count":30}],"source":["import networkx as nx\n","from itertools import combinations\n","\n","def compute_treewidth(G):\n","    \"\"\"\n","    Computes the treewidth of a graph G using a dynamic programming approach.\n","    This is an approximation algorithm since exact computation of treewidth is NP-hard.\n","    \"\"\"\n","    n = len(G.nodes)\n","    best_treewidth = float('inf')\n","\n","    # Try all possible orderings of the vertices (brute force approach for simplicity)\n","    for order in combinations(G.nodes, n):\n","        max_bag_size = 0\n","        for i in range(n):\n","            bag = set(order[:i+1])\n","            max_bag_size = max(max_bag_size, len(bag))\n","\n","        best_treewidth = min(best_treewidth, max_bag_size - 1)\n","\n","    return best_treewidth\n","\n","\n","def compute_clique_width(G):\n","    \"\"\"\n","    Computes the clique-width of a graph G using an approximation.\n","    Clique-width is NP-hard to compute, so we are using an approximation method.\n","    This implementation uses graph labeling strategies.\n","    \"\"\"\n","    n = len(G.nodes)\n","    clique_width = n  # A trivial upper bound is the number of nodes\n","\n","    # Greedily attempt to find cliques in the graph, adjusting the labeling\n","    labels = {node: i for i, node in enumerate(G.nodes)}\n","    for u, v in G.edges():\n","        if labels[u] != labels[v]:\n","            clique_width = min(clique_width, max(labels[u], labels[v]) + 1)\n","\n","    return clique_width\n","\n","\n","def apply_constraints(treewidth, clique_width):\n","    \"\"\"\n","    Apply the constraints mentioned in the document to optimize the causal inference model.\n","    \"\"\"\n","    # The constraint between treewidth and branchwidth\n","    branchwidth = 3/2 * (treewidth + 1)\n","\n","    # The constraint on clique-width based on treewidth\n","    clique_width_bound = 3 * 2**treewidth - 1\n","\n","    # Ensure the clique-width respects the upper bound\n","    clique_width = min(clique_width, clique_width_bound)\n","\n","    return branchwidth, clique_width\n","\n","\n","def optimize_causal_inference(G):\n","    \"\"\"\n","    Optimizes the causal inference model based on graph width parameters (treewidth and clique-width).\n","    \"\"\"\n","    # Calculate treewidth and clique-width\n","    treewidth = compute_treewidth(G)\n","    clique_width = compute_clique_width(G)\n","\n","    # Apply constraints\n","    branchwidth, clique_width = apply_constraints(treewidth, clique_width)\n","\n","    # Use these parameters to adjust the optimization process\n","    # For example, use treewidth and clique-width for dynamic programming or other causal inference algorithms\n","    print(f\"Optimized Causal Inference Parameters:\")\n","    print(f\"Treewidth: {treewidth}\")\n","    print(f\"Clique-width: {clique_width}\")\n","    print(f\"Branchwidth: {branchwidth}\")\n","\n","    # Further causal optimization code would go here (e.g., variable elimination, do-calculus, etc.)\n","    # This would leverage the computed parameters to improve the efficiency of inference and causal structure learning\n","\n","    return treewidth, clique_width, branchwidth\n","\n","\n","# Example of using the functions with a graph (NetworkX)\n","G = nx.erdos_renyi_graph(10, 0.5)  # Create a random graph as an example\n","optimize_causal_inference(G)\n"]},{"cell_type":"markdown","metadata":{"id":"TLSdqlegKacq"},"source":["# Dynotear\n","\n","*  结构模型类: StructureModel"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PmPTJHHKZcGy"},"outputs":[],"source":["\n","# - varsortability\n","# - make_plots\n","# - calculate_metrics"]},{"cell_type":"markdown","metadata":{"id":"G4O3xDXs0AW_"},"source":["## StructureModel"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hOBmGY880Ah7"},"outputs":[],"source":["# Copyright 2019-2020 QuantumBlack Visual Analytics Limited\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n","# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\n","# OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, AND\n","# NONINFRINGEMENT. IN NO EVENT WILL THE LICENSOR OR OTHER CONTRIBUTORS\n","# BE LIABLE FOR ANY CLAIM, DAMAGES, OR OTHER LIABILITY, WHETHER IN AN\n","# ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF, OR IN\n","# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n","#\n","# The QuantumBlack Visual Analytics Limited (\"QuantumBlack\") name and logo\n","# (either separately or in combination, \"QuantumBlack Trademarks\") are\n","# trademarks of QuantumBlack. The License does not grant you any right or\n","# license to the QuantumBlack Trademarks. You may not use the QuantumBlack\n","# Trademarks or any confusingly similar mark as a trademark for your product,\n","#     or use the QuantumBlack Trademarks in any other manner that might cause\n","# confusion in the marketplace, including but not limited to in advertising,\n","# on websites, or on software.\n","#\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","\"\"\"\n","This module contains the implementation of ``StructureModel``.\n","\n","``StructureModel`` is a class that describes relationships between variables as a graph.\n","\"\"\"\n","\n","from typing import Any, Hashable, List, Set, Tuple, Union\n","\n","import networkx as nx\n","import numpy as np\n","from networkx.exception import NodeNotFound\n","\n","\n","def _validate_origin(origin: str) -> None:\n","    \"\"\"\n","    Checks that origin has a valid value. One of:\n","        - unknown: edge exists for an unknown reason;\n","        - learned: edge was created as the output of a machine-learning process;\n","        - expert: edge was created by a domain expert.\n","\n","    Args:\n","        origin: the value to validate.\n","\n","    Raises:\n","        ValueError: if origin is not valid.\n","    \"\"\"\n","    allowed = {\"unknown\", \"learned\", \"expert\"}\n","\n","    if origin not in allowed:\n","        raise ValueError(f\"Unknown origin: must be one of {allowed} - got `{origin}`.\")\n","\n","\n","class StructureModel(nx.DiGraph):\n","    \"\"\"\n","    Base class for structure models, which are an extension of ``networkx.DiGraph``.\n","\n","    A ``StructureModel`` stores nodes and edges with optional data, or attributes.\n","\n","    Edges have one required attribute, \"origin\", which describes how the edge was created.\n","    Origin can be one of either unknown, learned, or expert.\n","\n","    StructureModel hold directed edges, describing a cause -> effect relationship.\n","    Cycles are permitted within a ``StructureModel``.\n","\n","    Nodes can be arbitrary (hashable) Python objects with optional key/value attributes.\n","    By convention None is not used as a node.\n","\n","    Edges are represented as links between nodes with optional key/value attributes.\n","    \"\"\"\n","\n","    def __init__(self, incoming_graph_data=None, origin=\"unknown\", **attr):\n","        \"\"\"\n","        Create a ``StructureModel`` with incoming_graph_data, which has come from some origin.\n","\n","        Args:\n","            incoming_graph_data (Optional): input graph (optional, default: None)\n","                                 Data to initialize graph. If None (default) an empty graph is created.\n","                                 The data can be any format that is supported by the to_networkx_graph()\n","                                 function, currently including edge list, dict of dicts, dict of lists,\n","                                 NetworkX graph, NumPy matrix or 2d ndarray, SciPy sparse matrix, or PyGraphviz graph.\n","\n","            origin (str): label for how the edges were created. Can be one of:\n","                        - unknown: edges exist for an unknown reason;\n","                        - learned: edges were created as the output of a machine-learning process;\n","                        - expert: edges were created by a domain expert.\n","\n","            attr : Attributes to add to graph as key/value pairs (no attributes by default).\n","        \"\"\"\n","        _validate_origin(origin)\n","        super().__init__(incoming_graph_data, **attr)\n","\n","        for u_of_edge, v_of_edge in self.edges:\n","            self[u_of_edge][v_of_edge][\"origin\"] = origin\n","\n","    def to_directed_class(self):\n","        \"\"\"\n","        Returns the class to use for directed copies.\n","        See :func:`networkx.DiGraph.to_directed()`.\n","        \"\"\"\n","        return StructureModel\n","\n","    def to_undirected_class(self):\n","        \"\"\"\n","        Returns the class to use for undirected copies.\n","        See :func:`networkx.DiGraph.to_undirected()`.\n","        \"\"\"\n","        return nx.Graph\n","\n","    # disabled: W0221: Parameters differ from overridden 'add_edge' method (arguments-differ)\n","    # this has been disabled because origin tracking is required for CausalGraphs\n","    # implementing it in this way allows all 3rd party libraries and applications to\n","    # integrate seamlessly, where edges will be given origin=\"unknown\" where not provided\n","    def add_edge(self, u_of_edge: str, v_of_edge: str, origin: str = \"unknown\", **attr):\n","        \"\"\"\n","        Adds a causal relationship from u to v.\n","\n","        If u or v do not currently exists in the ``StructureModel`` then they will be created.\n","\n","        By default a relationship will be given origin=\"unknown\", but\n","        may also be given \"learned\" or \"expert\" origin.\n","\n","        Adding an edge that already exists will replace the existing edge.\n","        See :func:`networkx.DiGraph.add_edge`.\n","\n","        Args:\n","            u_of_edge: causal node.\n","            v_of_edge: effect node.\n","            origin: label for how the edge was created. Can be one of:\n","                        - unknown: edge exists for an unknown reason;\n","                        - learned: edge was created as the output of a machine-learning process;\n","                        - expert: edge was created by a domain expert.\n","            **attr:  Attributes to add to edge as key/value pairs (no attributes by default).\n","        \"\"\"\n","        _validate_origin(origin)\n","\n","        attr.update({\"origin\": origin})\n","        super().add_edge(u_of_edge, v_of_edge, **attr)\n","\n","    # disabled: W0221: Parameters differ from overridden 'add_edge' method (arguments-differ)\n","    # this has been disabled because origin tracking is required for CausalGraphs\n","    # implementing it in this way allows all 3rd party libraries and applications to\n","    # integrate seamlessly, where edges will be given origin=\"unknown\" where not provided\n","    def add_edges_from(\n","        self,\n","        ebunch_to_add: Union[Set[Tuple], List[Tuple]],\n","        origin: str = \"unknown\",\n","        **attr,\n","    ):\n","        \"\"\"\n","        Adds a bunch of causal relationships, u -> v.\n","\n","        If u or v do not currently exists in the ``StructureModel`` then they will be created.\n","\n","        By default relationships will be given origin=\"unknown\",\n","        but may also be given \"learned\" or \"expert\" origin.\n","\n","        Notes:\n","            Adding an edge that already exists will replace the existing edge.\n","            See :func:`networkx.DiGraph.add_edges_from`.\n","\n","        Args:\n","            ebunch_to_add: container of edges.\n","                           Each edge given in the container will be added to the graph.\n","                           The edges must be given as 2-tuples (u, v) or\n","                           3-tuples (u, v, d) where d is a dictionary containing edge data.\n","            origin: label for how the edges were created. One of:\n","                        - unknown: edges exist for an unknown reason.\n","                        - learned: edges were created as the output of a machine-learning process.\n","                        - expert: edges were created by a domain expert.\n","            **attr:  Attributes to add to edge as key/value pairs (no attributes by default).\n","        \"\"\"\n","        _validate_origin(origin)\n","\n","        attr.update({\"origin\": origin})\n","        super().add_edges_from(ebunch_to_add, **attr)\n","\n","    # disabled: W0221: Parameters differ from overridden 'add_edge' method (arguments-differ)\n","    # this has been disabled because origin tracking is required for CausalGraphs\n","    # implementing it in this way allows all 3rd party libraries and applications to\n","    # integrate seamlessly, where edges will be given origin=\"unknown\" where not provided\n","    def add_weighted_edges_from(\n","        self,\n","        ebunch_to_add: Union[Set[Tuple], List[Tuple]],\n","        weight: str = \"weight\",\n","        origin: str = \"unknown\",\n","        **attr,\n","    ):\n","        \"\"\"\n","        Adds a bunch of weighted causal relationships, u -> v.\n","\n","        If u or v do not currently exists in the ``StructureModel`` then they will be created.\n","\n","        By default relationships will be given origin=\"unknown\",\n","        but may also be given \"learned\" or \"expert\" origin.\n","\n","        Notes:\n","            Adding an edge that already exists will replace the existing edge.\n","            See :func:`networkx.DiGraph.add_edges_from`.\n","\n","        Args:\n","            ebunch_to_add: container of edges.\n","                           Each edge given in the container will be added to the graph.\n","                           The edges must be given as 2-tuples (u, v) or\n","                           3-tuples (u, v, d) where d is a dictionary containing edge data.\n","            weight : string, optional (default='weight').\n","                     The attribute name for the edge weights to be added.\n","            origin: label for how the edges were created. One of:\n","                - unknown: edges exist for an unknown reason;\n","                - learned: edges were created as the output of a machine-learning process;\n","                - expert: edges were created by a domain expert.\n","            **attr: Attributes to add to edge as key/value pairs (no attributes by default).\n","        \"\"\"\n","        _validate_origin(origin)\n","\n","        attr.update({\"origin\": origin})\n","        super().add_weighted_edges_from(ebunch_to_add, weight=weight, **attr)\n","\n","    def edges_with_origin(self, origin: List[Any]) -> List[Tuple[Any, Any]]:\n","        \"\"\"\n","        List of edges created with given origin attribute.\n","\n","        Returns:\n","            A list of edges with the given origin.\n","        \"\"\"\n","        return [(u, v) for u, v in self.edges if self[u][v][\"origin\"] == origin]\n","\n","    def remove_edges_below_threshold(self, threshold: float):\n","        \"\"\"\n","        Remove edges whose absolute weights are less than a defined threshold.\n","\n","        Args:\n","            threshold: edges whose absolute weight is less than this value are removed.\n","        \"\"\"\n","        self.remove_edges_from(\n","            [(u, v) for u, v, w in self.edges(data=\"weight\") if np.abs(w) < threshold]\n","        )\n","\n","    def get_largest_subgraph(self) -> \"StructureModel\":\n","        \"\"\"\n","        Get the largest subgraph of the Structure Model.\n","\n","        Returns:\n","            The largest subgraph of the Structure Model. If no subgraph exists, None is returned.\n","        \"\"\"\n","        largest_n_edges = 0\n","        largest_subgraph = None\n","\n","        for component in nx.weakly_connected_components(self):\n","            subgraph = self.subgraph(component).copy()\n","\n","            if len(subgraph.edges) > largest_n_edges:\n","                largest_n_edges = len(subgraph.edges)\n","                largest_subgraph = subgraph\n","\n","        return largest_subgraph\n","\n","    def get_target_subgraph(self, node: Hashable) -> \"StructureModel\":\n","        \"\"\"\n","        Get the subgraph with the specified node.\n","\n","        Args:\n","            node: the name of the node.\n","\n","        Returns:\n","            The subgraph with the target node.\n","\n","        Raises:\n","            NodeNotFound: if the node is not found in the graph.\n","        \"\"\"\n","        if node in self.nodes:\n","            for component in nx.weakly_connected_components(self):\n","                subgraph = self.subgraph(component).copy()\n","\n","                if node in set(subgraph.nodes):\n","                    return subgraph\n","\n","        raise NodeNotFound(f\"Node {node} not found in the graph.\")\n","\n","    def threshold_till_dag(self):\n","        \"\"\"\n","        Remove edges with smallest weight until the graph is a DAG.\n","        Not recommended if the weights have different units.\n","        \"\"\"\n","        while not nx.algorithms.is_directed_acyclic_graph(self):\n","            i, j, _ = min(self.edges(data=\"weight\"), key=lambda x: abs(x[2]))\n","            self.remove_edge(i, j)\n","\n","    def get_markov_blanket(\n","        self, nodes: Union[Any, List[Any], Set[Any]]\n","    ) -> \"StructureModel\":\n","        \"\"\"\n","        Get Markov blanket of specified target nodes\n","\n","        Args:\n","            nodes: Target node name or list/set of target nodes\n","\n","        Returns:\n","            Markov blanket of the target node(s)\n","\n","        Raises:\n","            NodeNotFound: if one of the target nodes is not found in the graph.\n","        \"\"\"\n","        if not isinstance(nodes, (list, set)):\n","            nodes = [nodes]\n","\n","        blanket_nodes = set()\n","\n","        for node in set(nodes):  # Ensure target nodes are unique\n","            if node not in set(self.nodes):\n","                raise NodeNotFound(f\"Node {node} not found in the graph.\")\n","\n","            blanket_nodes.add(node)\n","            blanket_nodes.update(self.predecessors(node))\n","\n","            for child in self.successors(node):\n","                blanket_nodes.add(child)\n","                blanket_nodes.update(self.predecessors(child))\n","\n","        blanket = StructureModel()\n","        blanket.add_nodes_from(blanket_nodes)\n","        blanket.add_weighted_edges_from(\n","            [\n","                (u, v, w)\n","                for u, v, w in self.edges(data=\"weight\")\n","                if u in blanket_nodes and v in blanket_nodes\n","            ]\n","        )\n","        return blanket"]},{"cell_type":"markdown","metadata":{"id":"Vh2iIZtqxa5W"},"source":["## Transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-LRXM1ARxbD9"},"outputs":[],"source":["# Copyright 2019-2020 QuantumBlack Visual Analytics Limited\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n","# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\n","# OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, AND\n","# NONINFRINGEMENT. IN NO EVENT WILL THE LICENSOR OR OTHER CONTRIBUTORS\n","# BE LIABLE FOR ANY CLAIM, DAMAGES, OR OTHER LIABILITY, WHETHER IN AN\n","# ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF, OR IN\n","# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n","#\n","# The QuantumBlack Visual Analytics Limited (\"QuantumBlack\") name and logo\n","# (either separately or in combination, \"QuantumBlack Trademarks\") are\n","# trademarks of QuantumBlack. The License does not grant you any right or\n","# license to the QuantumBlack Trademarks. You may not use the QuantumBlack\n","# Trademarks or any confusingly similar mark as a trademark for your product,\n","#     or use the QuantumBlack Trademarks in any other manner that might cause\n","# confusion in the marketplace, including but not limited to in advertising,\n","# on websites, or on software.\n","#\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","\"\"\"\n","Collection of sklearn style transformers designed to assist with causal structure learning.\n","\"\"\"\n","\n","from copy import deepcopy\n","from typing import List, Tuple, Union\n","\n","import numpy as np\n","import pandas as pd\n","from pandas.api.types import is_integer_dtype\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn.exceptions import NotFittedError\n","\n","\n","class DynamicDataTransformer(BaseEstimator, TransformerMixin):\n","    \"\"\"\n","    Format a time series dataframe or list of dataframes into the a format that matches the structure learned by\n","        `from_pandas_dynamic`. This is done to allow for bayesian network probability fitting.\n","\n","        Example of utilisation:\n","        >>> ddt = DynamicDataTransformer(p=p).fit(time_series, return_df=False)\n","        >>> X, Xlags = ddt.transform(time_series)\n","\n","        >>> ddt = DynamicDataTransformer(p=p).fit(time_series, return_df=True)\n","        >>> df = ddt.transform(time_series)\n","    \"\"\"\n","\n","    def __init__(self, p: int):\n","        \"\"\"\n","        Initialise Transformer\n","        Args:\n","            p: Number of past interactions we allow the model to create. The state of a variable at time `t` is\n","                affected by the variables at the time stamp + the variables at `t-1`, `t-2`,... `t-p`.\n","        \"\"\"\n","        self.p = p\n","        self.columns = None\n","        self.return_df = None\n","\n","    def fit(\n","        self,\n","        time_series: Union[pd.DataFrame, List[pd.DataFrame]],\n","        return_df: bool = True,\n","    ) -> \"DynamicDataTransformer\":\n","        \"\"\"\n","        Fits the time series. This consists memorizing:\n","            - Column names and column positions\n","            - whether a dataframe or a tuple of arrays should be returned by `transform` (details below)\n","        Args:\n","            time_series: pd.DataFrame or List of pd.DataFrame instances.\n","                If a list is provided each element of the list being an realisation of a time series\n","                (i.e. time series governed by the same processes)\n","                The columns of the data frame represent the variables in the model, and the *index represents\n","                the time index*.\n","                Successive events, therefore, must be indexed with one integer of difference between them too.\n","\n","            return_df: Whether the `transform` method should return a pandas.DataFrame or a tuple with (X,Xlags)\n","                (Details on the documentation of the `transform` method)\n","\n","        Returns:\n","            self\n","\n","        \"\"\"\n","        time_series = time_series if isinstance(time_series, list) else [time_series]\n","        self._check_input_from_pandas(time_series)\n","        self.columns = list(time_series[0].columns)\n","        self.return_df = return_df\n","        return self\n","\n","    def transform(\n","        self, time_series: Union[pd.DataFrame, List[pd.DataFrame]]\n","    ) -> Union[pd.DataFrame, Tuple[np.ndarray, np.ndarray]]:\n","        \"\"\"\n","        Applies transformation to format the dataframe properly\n","        Args:\n","            time_series: time_series: pd.DataFrame or List of pd.DataFrame instances. Details on `fit` documentation\n","\n","        Returns:\n","            - If `self.return_df=True`, returns a pandas.DataFrame on the following format:\n","\n","                A_lag0 B_lag0 C_lag0 ... A_lag1 B_lag1 C_lag1 ... A_lag`p` B_lag`p` C_lag`p`\n","                    X     X      X          X     X      X          X        X        X\n","                    X     X      X          X     X      X          X        X        X\n","                    X     X      X          X     X      X          X        X        X\n","            `lag0` denotes the current variable state and lag`k` denotes the states `k` time stamps in the past.\n","\n","            - If `self.return_df=False`, returns a tuple of two numpy.ndarrayy: X and Xlags\n","                    X (np.ndarray): 2d input data, axis=1 is data columns, axis=0 is data rows.\n","                        Each column represents one variable,\n","                        and each row represents x(m,t) i.e. the mth time series at time t.\n","                    Xlags (np.ndarray):\n","                        Shifted data of X with lag orders stacking horizontally. Xlags=[shift(X,1)|...|shift(X,p)]\n","        Raises:\n","            NotFittedError: if `transform` called before `fit`\n","        \"\"\"\n","        if self.columns is None:\n","            raise NotFittedError(\n","                \"This DynamicDataTransformer is not fitted yet. \"\n","                \"Call `fit` before using this method\"\n","            )\n","\n","        time_series = time_series if isinstance(time_series, list) else [time_series]\n","\n","        self._check_input_from_pandas(time_series)\n","\n","        time_series = [t[self.columns] for t in time_series]\n","        ts_realisations = self._cut_dataframes_on_discontinuity_points(time_series)\n","        X, Xlags = self._convert_realisations_into_dynotears_format(\n","            ts_realisations, self.p\n","        )\n","\n","        if self.return_df:\n","            res = self._concat_lags(X, Xlags)\n","            return res\n","        return X, Xlags\n","\n","    def _concat_lags(self, X: np.ndarray, Xlags: np.ndarray) -> pd.DataFrame:\n","        df_x = pd.DataFrame(X, columns=[f\"{col}_lag0\" for col in self.columns])\n","        df_xlags = pd.DataFrame(\n","            Xlags,\n","            columns=[\n","                f\"{col}_lag{l_}\" for l_ in range(1, self.p + 1) for col in self.columns\n","            ],\n","        )\n","        return pd.concat([df_x, df_xlags], axis=1)\n","\n","    def _check_input_from_pandas(self, time_series: List[pd.DataFrame]):\n","        \"\"\"\n","        Check if the input of function `from_pandas_dynamic` is valid\n","        Args:\n","            time_series: List of pd.DataFrame instances.\n","                each element of the list being an realisation of a same time series\n","\n","        Raises:\n","            ValueError: if empty list of time_series is provided\n","            ValueError: if dataframes contain non numeric data\n","            TypeError: if elements provided are not pandas dataframes\n","            ValueError: if dataframes contain different columns\n","            ValueError: if dataframes index is not in increasing order\n","            TypeError: if dataframes index are not index\n","        \"\"\"\n","        if not time_series:\n","            raise ValueError(\n","                \"Provided empty list of time_series. At least one DataFrame must be provided\"\n","            )\n","\n","        df = deepcopy(time_series[0])\n","\n","        for t in time_series:\n","            if not isinstance(t, pd.DataFrame):\n","                raise TypeError(\n","                    \"Time series entries must be instances of `pd.DataFrame`\"\n","                )\n","\n","            non_numeric_cols = t.select_dtypes(exclude=\"number\").columns\n","\n","            if not non_numeric_cols.empty:\n","                raise ValueError(\n","                    \"All columns must have numeric data. Consider mapping the \"\n","                    f\"following columns to int: {list(non_numeric_cols)}\"\n","                )\n","\n","            if (not np.all(df.columns == t.columns)) or (\n","                not np.all(df.dtypes == t.dtypes)\n","            ):\n","                raise ValueError(\"All inputs must have the same columns and same types\")\n","\n","            if not np.all(t.index == t.index.sort_values()):\n","                raise ValueError(\n","                    \"Index for dataframe must be provided in increasing order\"\n","                )\n","\n","            if not is_integer_dtype(t.index):\n","             # RangeIndex.is_integer is deprecated. Use pandas.api.types.is_integer_dtype instead. if not t.index.is_integer():\n","                raise TypeError(\"Index must be integers\")\n","\n","            if self.columns is not None:\n","                missing_cols = [c for c in self.columns if c not in t.columns]\n","                if missing_cols:\n","                    raise ValueError(\n","                        \"We should provide all necessary columns in the time series. \"\n","                        f\"Columns not provided: {missing_cols}\"\n","                    )\n","\n","    @staticmethod\n","    def _cut_dataframes_on_discontinuity_points(\n","        time_series: List[pd.DataFrame],\n","    ) -> List[np.ndarray]:\n","        \"\"\"\n","        Helper function for `from_pandas_dynamic`\n","        Receive a list of dataframes. For each dataframe, cut the points of discontinuity as two different dataframes.\n","        Discontinuities are determined by the indexes.\n","\n","        For Example:\n","        If the following is a dataframe:\n","            index   variable_1  variable_2\n","            1       X           X\n","            2       X           X\n","            3       X           X\n","            4       X           X\n","            8       X           X               <- discontinuity point\n","            9       X           X\n","            10      X           X\n","\n","        We cut this dataset in two:\n","\n","            index   variable_1  variable_2\n","            1       X           X\n","            2       X           X\n","            3       X           X\n","            4       X           X\n","\n","            and:\n","            index   variable_1  variable_2\n","            8       X           X\n","            9       X           X\n","            10      X           X\n","\n","\n","        Args:\n","            time_series: list of dataframes representing various realisations of a same time series\n","\n","        Returns:\n","            List of np.ndarrays representing the pieces of the input datasets with no discontinuity\n","\n","        \"\"\"\n","        time_series_realisations = []\n","        for t in time_series:\n","            cutting_points = np.where(np.diff(t.index) > 1)[0]\n","            cutting_points = [0] + list(cutting_points + 1) + [len(t)]\n","            for start, end in zip(cutting_points[:-1], cutting_points[1:]):\n","                time_series_realisations.append(t.iloc[start:end, :].values)\n","        return time_series_realisations\n","\n","    @staticmethod\n","    def _convert_realisations_into_dynotears_format(\n","        realisations: List[np.ndarray], p: int\n","    ) -> Tuple[np.ndarray, np.ndarray]:\n","        \"\"\"\n","        Given a list of realisations of a time series, convert it to the format received by the dynotears algorithm.\n","        Each realisation on `realisations` is a realisation of the time series,\n","        where the time dimension is represented by the rows.\n","            - The higher the row, the higher the time index\n","            - The data is complete, meaning that the difference between two time stamps is equal one\n","        Args:\n","            realisations: a list of realisations of a time series\n","            p: the number of lagged columns to create\n","\n","        Returns:\n","            X and Y as in the SVAR model and DYNOTEARS paper. I.e. X being representing X(m,t) and Y the concatenated\n","            differences [X(m,t-1) | X(m,t-2) | ... | X(m,t-p)]\n","        \"\"\"\n","        X = np.concatenate([realisation[p:] for realisation in realisations], axis=0)\n","        y_lag_list = [\n","            np.concatenate([realisation[p - i - 1 : -i - 1] for i in range(p)], axis=1)\n","            for realisation in realisations\n","        ]\n","        y_lag = np.concatenate(y_lag_list, axis=0)\n","\n","        return X, y_lag"]},{"cell_type":"markdown","metadata":{"id":"1fXXkSjlzKh4"},"source":["## Dynotear"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2hNjHayxzKtf"},"outputs":[],"source":["# Copyright 2019-2020 QuantumBlack Visual Analytics Limited\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n","# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\n","# OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, AND\n","# NONINFRINGEMENT. IN NO EVENT WILL THE LICENSOR OR OTHER CONTRIBUTORS\n","# BE LIABLE FOR ANY CLAIM, DAMAGES, OR OTHER LIABILITY, WHETHER IN AN\n","# ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF, OR IN\n","# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n","#\n","# The QuantumBlack Visual Analytics Limited (\"QuantumBlack\") name and logo\n","# (either separately or in combination, \"QuantumBlack Trademarks\") are\n","# trademarks of QuantumBlack. The License does not grant you any right or\n","# license to the QuantumBlack Trademarks. You may not use the QuantumBlack\n","# Trademarks or any confusingly similar mark as a trademark for your product,\n","#     or use the QuantumBlack Trademarks in any other manner that might cause\n","# confusion in the marketplace, including but not limited to in advertising,\n","# on websites, or on software.\n","#\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","\"\"\"\n","Tools to learn a Dynamic Bayesian Network which describe the conditional dependencies between variables in a time-series\n","dataset.\n","\"\"\"\n","\n","import warnings\n","from typing import Dict, List, Tuple, Union\n","\n","import numpy as np\n","import pandas as pd\n","import scipy.linalg as slin\n","import scipy.optimize as sopt\n","\n","#from structure import StructureModel\n","#from structure.transformers import DynamicDataTransformer\n","\n","\n","def from_pandas_dynamic(  # pylint: disable=too-many-arguments\n","    time_series: Union[pd.DataFrame, List[pd.DataFrame]],\n","    p: int,\n","    lambda_w: float = 0.1,\n","    lambda_a: float = 0.1,\n","    max_iter: int = 100,\n","    h_tol: float = 1e-8,\n","    w_threshold: float = 0.0,\n","    tabu_edges: List[Tuple[int, int, int]] = None,\n","    tabu_parent_nodes: List[int] = None,\n","    tabu_child_nodes: List[int] = None,\n",") -> StructureModel:\n","    \"\"\"\n","    Learn the graph structure of a Dynamic Bayesian Network describing conditional dependencies between variables in\n","    data. The input data is a time series or a list of realisations of a same time series.\n","    The optimisation is to minimise a score function F(W, A) over the graph's contemporaneous (intra-slice) weighted\n","    adjacency matrix, W, and lagged (inter-slice) weighted adjacency matrix, A, subject to the a constraint function\n","    h(W), where h_value(W) == 0 characterises an acyclic graph. h(W) > 0 is a continuous, differentiable function that\n","    encapsulated how acyclic the graph is (less = more acyclic).\n","\n","    Based on \"DYNOTEARS: Structure Learning from Time-Series Data\".\n","    https://arxiv.org/abs/2002.00498\n","    @inproceedings{pamfil2020dynotears,\n","        title={DYNOTEARS: Structure Learning from Time-Series Data},\n","        author={Pamfil, Roxana and Sriwattanaworachai, Nisara and Desai, Shaan and Pilgerstorfer,\n","        Philip and Georgatzis, Konstantinos and Beaumont, Paul and Aragam, Bryon},\n","        booktitle={International Conference on Artificial Intelligence and Statistics},\n","        pages={1595--1605},\n","        year={2020}year={2020},\n","    }\n","    Args:\n","        time_series: pd.DataFrame or List of pd.DataFrame instances.\n","        If a list is provided each element of the list being an realisation of a time series (i.e. time series governed\n","        by the same processes)\n","        The columns of the data frame represent the variables in the model, and the *index represents the time index*.\n","        Successive events, therefore, must be indexed with one integer of difference between them too.\n","        p: Number of past interactions we allow the model to create. The state of a variable at time `t` is affected by\n","        past variables up to a `t-p`, as well as by other variables at `t`.\n","        lambda_w: parameter for l1 regularisation of intra-slice edges\n","        lambda_a: parameter for l1 regularisation of inter-slice edges\n","        max_iter: max number of dual ascent steps during optimisation.\n","        h_tol: exit if h(W) < h_tol (as opposed to strict definition of 0).\n","        w_threshold: fixed threshold for absolute edge weights.\n","        tabu_edges: list of edges(lag, from, to) not to be included in the graph. `lag == 0` implies that the edge is\n","        forbidden in the INTRA graph (W), while lag > 0 implies an INTER-slice weight equal zero.\n","        tabu_parent_nodes: list of nodes banned from being a parent of any other nodes.\n","        tabu_child_nodes: list of nodes banned from being a child of any other nodes.\n","\n","    Returns:\n","        StructureModel representing the model learnt. The node names are noted as `{var}_lag{l}`, where `var` is the\n","        original variable name as in the give in the input data frames and `l`, in 0,1,2..p is the correspondent\n","        time lag.\n","    \"\"\"\n","    time_series = [time_series] if not isinstance(time_series, list) else time_series\n","\n","    X, Xlags = DynamicDataTransformer(p=p).fit_transform(time_series, return_df=False)\n","\n","    col_idx = {c: i for i, c in enumerate(time_series[0].columns)}\n","    idx_col = {i: c for c, i in col_idx.items()}\n","\n","    if tabu_edges:\n","        tabu_edges = [(lag, col_idx[u], col_idx[v]) for lag, u, v in tabu_edges]\n","    if tabu_parent_nodes:\n","        tabu_parent_nodes = [col_idx[n] for n in tabu_parent_nodes]\n","    if tabu_child_nodes:\n","        tabu_child_nodes = [col_idx[n] for n in tabu_child_nodes]\n","\n","    g, w_est, a_est = from_numpy_dynamic(\n","        X,\n","        Xlags,\n","        lambda_w,\n","        lambda_a,\n","        max_iter,\n","        h_tol,\n","        w_threshold,\n","        tabu_edges,\n","        tabu_parent_nodes,\n","        tabu_child_nodes,\n","    )\n","\n","    sm = StructureModel()\n","    sm.add_nodes_from(\n","        [f\"{var}_lag{l_val}\" for var in col_idx.keys() for l_val in range(p + 1)]\n","    )\n","    sm.add_weighted_edges_from(\n","        [\n","            (\n","                _format_name_from_pandas(idx_col, u),\n","                _format_name_from_pandas(idx_col, v),\n","                w,\n","            )\n","            for u, v, w in g.edges.data(\"weight\")\n","        ],\n","        origin=\"learned\",\n","    )\n","\n","    return sm, w_est, a_est\n","\n","\n","def _format_name_from_pandas(idx_col: Dict[int, str], from_numpy_node: str) -> str:\n","    \"\"\"\n","    Helper function for `from_pandas_dynamic`. converts a node from the `from_numpy_dynamic` format to the `from_pandas`\n","    format\n","    Args:\n","        idx_col: map from variable to intdex\n","        from_numpy_node: nodes in the structure model output by `from_numpy_dynamic`.\n","    Returns:\n","        nodes in from_pandas_dynamic format\n","    \"\"\"\n","    idx, lag_val = from_numpy_node.split(\"_lag\")\n","    return f\"{idx_col[int(idx)]}_lag{lag_val}\"\n","\n","\n","def from_numpy_dynamic(  # pylint: disable=too-many-arguments\n","    X: np.ndarray,\n","    Xlags: np.ndarray,\n","    lambda_w: float = 0.1,\n","    lambda_a: float = 0.1,\n","    max_iter: int = 100,\n","    h_tol: float = 1e-8,\n","    w_threshold: float = 0.0,\n","    tabu_edges: List[Tuple[int, int, int]] = None,\n","    tabu_parent_nodes: List[int] = None,\n","    tabu_child_nodes: List[int] = None,\n",") -> StructureModel:\n","    \"\"\"\n","    Learn the graph structure of a Dynamic Bayesian Network describing conditional dependencies between variables in\n","    data. The input data is time series data present in numpy arrays X and Xlags.\n","\n","    The optimisation is to minimise a score function F(W, A) over the graph's contemporaneous (intra-slice) weighted\n","    adjacency matrix, W, and lagged (inter-slice) weighted adjacency matrix, A, subject to the a constraint function\n","    h(W), where h_value(W) == 0 characterises an acyclic graph. h(W) > 0 is a continuous, differentiable function that\n","    encapsulated how acyclic the graph is (less = more acyclic).\n","\n","    Based on \"DYNOTEARS: Structure Learning from Time-Series Data\".\n","    https://arxiv.org/abs/2002.00498\n","    @inproceedings{pamfil2020dynotears,\n","        title={DYNOTEARS: Structure Learning from Time-Series Data},\n","        author={Pamfil, Roxana and Sriwattanaworachai, Nisara and Desai, Shaan and Pilgerstorfer,\n","        Philip and Georgatzis, Konstantinos and Beaumont, Paul and Aragam, Bryon},\n","        booktitle={International Conference on Artificial Intelligence and Statistics},\n","        pages={1595--1605},\n","        year={2020}year={2020},\n","    }\n","\n","    Args:\n","        X (np.ndarray): 2d input data, axis=1 is data columns, axis=0 is data rows. Each column represents one variable,\n","        and each row represents x(m,t) i.e. the mth time series at time t.\n","        Xlags (np.ndarray): shifted data of X with lag orders stacking horizontally. Xlags=[shift(X,1)|...|shift(X,p)]\n","        lambda_w (float): l1 regularization parameter of intra-weights W\n","        lambda_a (float): l1 regularization parameter of inter-weights A\n","        max_iter: max number of dual ascent steps during optimisation\n","        h_tol (float): exit if h(W) < h_tol (as opposed to strict definition of 0)\n","        w_threshold: fixed threshold for absolute edge weights.\n","        tabu_edges: list of edges(lag, from, to) not to be included in the graph. `lag == 0` implies that the edge is\n","        forbidden in the INTRA graph (W), while lag > 0 implies an INTER weight equal zero.\n","        tabu_parent_nodes: list of nodes banned from being a parent of any other nodes.\n","        tabu_child_nodes: list of nodes banned from being a child of any other nodes.\n","    Returns:\n","        W (np.ndarray): d x d estimated weighted adjacency matrix of intra slices\n","        A (np.ndarray): d x pd estimated weighted adjacency matrix of inter slices\n","\n","    Raises:\n","        ValueError: If X or Xlags does not contain data, or dimensions of X and Xlags do not conform\n","    \"\"\"\n","    _, d_vars = X.shape\n","    p_orders = Xlags.shape[1] // d_vars\n","\n","    bnds_w = 2 * [\n","        (0, 0)\n","        if i == j\n","        else (0, 0)\n","        if tabu_edges is not None and (0, i, j) in tabu_edges\n","        else (0, 0)\n","        if tabu_parent_nodes is not None and i in tabu_parent_nodes\n","        else (0, 0)\n","        if tabu_child_nodes is not None and j in tabu_child_nodes\n","        else (0, None)\n","        for i in range(d_vars)\n","        for j in range(d_vars)\n","    ]\n","\n","    bnds_a = []\n","    for k in range(1, p_orders + 1):\n","        bnds_a.extend(\n","            2\n","            * [\n","                (0, 0)\n","                if tabu_edges is not None and (k, i, j) in tabu_edges\n","                else (0, 0)\n","                if tabu_parent_nodes is not None and i in tabu_parent_nodes\n","                else (0, 0)\n","                if tabu_child_nodes is not None and j in tabu_child_nodes\n","                else (0, None)\n","                for i in range(d_vars)\n","                for j in range(d_vars)\n","            ]\n","        )\n","\n","    bnds = bnds_w + bnds_a\n","    w_est, a_est = _learn_dynamic_structure(\n","        X, Xlags, bnds, lambda_w, lambda_a, max_iter, h_tol\n","    )\n","\n","    w_est[np.abs(w_est) < w_threshold] = 0\n","    a_est[np.abs(a_est) < w_threshold] = 0\n","    sm = _matrices_to_structure_model(w_est, a_est)\n","    return sm, w_est, a_est\n","\n","\n","def _matrices_to_structure_model(\n","    w_est: np.ndarray, a_est: np.ndarray\n",") -> StructureModel:\n","    \"\"\"\n","    Converts the matrices output by dynotears (W and A) into a StructureModel\n","    We use the following convention:\n","    - {var}_lag{l} where l is the lag value (i.e. from how many previous timestamps the edge is coming\n","    - if we deal with a intra_slice_node, `l == 0`\n","    Args:\n","        w_est: Intra-slice weight matrix\n","        a_est: Inter-slice matrix\n","\n","    Returns:\n","        StructureModel representing the structure learnt\n","\n","    \"\"\"\n","    sm = StructureModel()\n","    lag_cols = [\n","        f\"{var}_lag{l_val}\"\n","        for l_val in range(1 + (a_est.shape[0] // a_est.shape[1]))\n","        for var in range(a_est.shape[1])\n","    ]\n","    sm.add_nodes_from(lag_cols)\n","    sm.add_edges_from(\n","        [\n","            (lag_cols[i], lag_cols[j], {\"weight\": w_est[i, j]})\n","            for i in range(w_est.shape[0])\n","            for j in range(w_est.shape[1])\n","            if w_est[i, j] != 0\n","        ]\n","    )\n","    sm.add_edges_from(\n","        [\n","            (lag_cols[i + w_est.shape[0]], lag_cols[j], {\"weight\": a_est[i, j]})\n","            for i in range(a_est.shape[0])\n","            for j in range(a_est.shape[1])\n","            if a_est[i, j] != 0\n","        ]\n","    )\n","    return sm\n","\n","\n","def _reshape_wa(\n","    wa_vec: np.ndarray, d_vars: int, p_orders: int\n",") -> Tuple[np.ndarray, np.ndarray]:\n","    \"\"\"\n","    Helper function for `_learn_dynamic_structure`. Transform adjacency vector to matrix form\n","\n","    Args:\n","        wa_vec (np.ndarray): current adjacency vector with intra- and inter-slice weights\n","        d_vars (int): number of variables in the model\n","        p_orders (int): number of past indexes we to use\n","    Returns:\n","        intra- and inter-slice adjacency matrices\n","    \"\"\"\n","\n","    w_tilde = wa_vec.reshape([2 * (p_orders + 1) * d_vars, d_vars])\n","    w_plus = w_tilde[:d_vars, :]\n","    w_minus = w_tilde[d_vars : 2 * d_vars, :]\n","    w_mat = w_plus - w_minus\n","    a_plus = (\n","        w_tilde[2 * d_vars :]\n","        .reshape(2 * p_orders, d_vars**2)[::2]\n","        .reshape(d_vars * p_orders, d_vars)\n","    )\n","    a_minus = (\n","        w_tilde[2 * d_vars :]\n","        .reshape(2 * p_orders, d_vars**2)[1::2]\n","        .reshape(d_vars * p_orders, d_vars)\n","    )\n","    a_mat = a_plus - a_minus\n","    return w_mat, a_mat\n","\n","\n","def _learn_dynamic_structure(\n","    X: np.ndarray,\n","    Xlags: np.ndarray,\n","    bnds: List[Tuple[float, float]],\n","    lambda_w: float = 0.1,\n","    lambda_a: float = 0.1,\n","    max_iter: int = 100,\n","    h_tol: float = 1e-8,\n",") -> Tuple[np.ndarray, np.ndarray]:\n","    \"\"\"\n","    Learn the graph structure of a Dynamic Bayesian Network describing conditional dependencies between data variables.\n","\n","    The optimisation is to minimise a score function F(W, A) over the graph's contemporaneous (intra-slice) weighted\n","    adjacency matrix, W, and lagged (inter-slice) weighted adjacency matrix, A, subject to the a constraint function\n","    h(W), where h_value(W) == 0 characterises an acyclic graph. h(W) > 0 is a continuous, differentiable function that\n","    encapsulated how acyclic the graph is (less = more acyclic).\n","\n","    Based on \"DYNOTEARS: Structure Learning from Time-Series Data\".\n","    https://arxiv.org/abs/2002.00498\n","    @inproceedings{pamfil2020dynotears,\n","        title={DYNOTEARS: Structure Learning from Time-Series Data},\n","        author={Pamfil, Roxana and Sriwattanaworachai, Nisara and Desai, Shaan and Pilgerstorfer,\n","        Philip and Georgatzis, Konstantinos and Beaumont, Paul and Aragam, Bryon},\n","        booktitle={International Conference on Artificial Intelligence and Statistics},\n","        pages={1595--1605},\n","        year={2020}year={2020},\n","    }\n","\n","    Args:\n","        X (np.ndarray): 2d input data, axis=1 is data columns, axis=0 is data rows. Each column represents one variable,\n","        and each row represents x(m,t) i.e. the mth time series at time t.\n","        Xlags (np.ndarray): shifted data of X with lag orders stacking horizontally. Xlags=[shift(X,1)|...|shift(X,p)]\n","        bnds: Box constraints of L-BFGS-B to ban self-loops in W, enforce non-negativity of w_plus, w_minus, a_plus,\n","        a_minus, and help with stationarity in A\n","        lambda_w (float): l1 regularization parameter of intra-weights W\n","        lambda_a (float): l1 regularization parameter of inter-weights A\n","        max_iter (int): max number of dual ascent steps during optimisation\n","        h_tol (float): exit if h(W) < h_tol (as opposed to strict definition of 0)\n","\n","    Returns:\n","        W (np.ndarray): d x d estimated weighted adjacency matrix of intra slices\n","        A (np.ndarray): d x pd estimated weighted adjacency matrix of inter slices\n","\n","    Raises:\n","        ValueError: If X or Xlags does not contain data, or dimensions of X and Xlags do not conform\n","    \"\"\"\n","    if X.size == 0:\n","        raise ValueError(\"Input data X is empty, cannot learn any structure\")\n","    if Xlags.size == 0:\n","        raise ValueError(\"Input data Xlags is empty, cannot learn any structure\")\n","    if X.shape[0] != Xlags.shape[0]:\n","        raise ValueError(\"Input data X and Xlags must have the same number of rows\")\n","    if Xlags.shape[1] % X.shape[1] != 0:\n","        raise ValueError(\n","            \"Number of columns of Xlags must be a multiple of number of columns of X\"\n","        )\n","\n","    n, d_vars = X.shape\n","    p_orders = Xlags.shape[1] // d_vars\n","\n","    def _h(wa_vec: np.ndarray) -> float:\n","        \"\"\"\n","        Constraint function of the dynotears\n","\n","        Args:\n","            wa_vec (np.ndarray): current adjacency vector with intra- and inter-slice weights\n","\n","        Returns:\n","            float: DAGness of the intra-slice adjacency matrix W (0 == DAG, >0 == cyclic)\n","        \"\"\"\n","\n","        _w_mat, _ = _reshape_wa(wa_vec, d_vars, p_orders)\n","        return np.trace(slin.expm(_w_mat * _w_mat)) - d_vars\n","\n","    def _func(wa_vec: np.ndarray) -> float:\n","        \"\"\"\n","        Objective function that the dynotears tries to minimise\n","\n","        Args:\n","            wa_vec (np.ndarray): current adjacency vector with intra- and inter-slice weights\n","\n","        Returns:\n","            float: objective\n","        \"\"\"\n","\n","        _w_mat, _a_mat = _reshape_wa(wa_vec, d_vars, p_orders)\n","        loss = (\n","            0.5\n","            / n\n","            * np.square(\n","                np.linalg.norm(\n","                    X.dot(np.eye(d_vars, d_vars) - _w_mat) - Xlags.dot(_a_mat), \"fro\"\n","                )\n","            )\n","        )\n","        _h_value = _h(wa_vec)\n","        l1_penalty = lambda_w * (wa_vec[: 2 * d_vars**2].sum()) + lambda_a * (\n","            wa_vec[2 * d_vars**2 :].sum()\n","        )\n","        return loss + 0.5 * rho * _h_value * _h_value + alpha * _h_value + l1_penalty\n","\n","    def _grad(wa_vec: np.ndarray) -> np.ndarray:\n","        \"\"\"\n","        Gradient function used to compute next step in dynotears\n","\n","        Args:\n","            wa_vec (np.ndarray): current adjacency vector with intra- and inter-slice weights\n","\n","        Returns:\n","            gradient vector\n","        \"\"\"\n","\n","        _w_mat, _a_mat = _reshape_wa(wa_vec, d_vars, p_orders)\n","        e_mat = slin.expm(_w_mat * _w_mat)\n","        loss_grad_w = (\n","            -1.0\n","            / n\n","            * (X.T.dot(X.dot(np.eye(d_vars, d_vars) - _w_mat) - Xlags.dot(_a_mat)))\n","        )\n","        obj_grad_w = (\n","            loss_grad_w\n","            + (rho * (np.trace(e_mat) - d_vars) + alpha) * e_mat.T * _w_mat * 2\n","        )\n","        obj_grad_a = (\n","            -1.0\n","            / n\n","            * (Xlags.T.dot(X.dot(np.eye(d_vars, d_vars) - _w_mat) - Xlags.dot(_a_mat)))\n","        )\n","\n","        grad_vec_w = np.append(\n","            obj_grad_w, -obj_grad_w, axis=0\n","        ).flatten() + lambda_w * np.ones(2 * d_vars**2)\n","        grad_vec_a = obj_grad_a.reshape(p_orders, d_vars**2)\n","        grad_vec_a = np.hstack(\n","            (grad_vec_a, -grad_vec_a)\n","        ).flatten() + lambda_a * np.ones(2 * p_orders * d_vars**2)\n","        return np.append(grad_vec_w, grad_vec_a, axis=0)\n","\n","    # initialise matrix, weights and constraints\n","    wa_est = np.zeros(2 * (p_orders + 1) * d_vars**2)\n","    wa_new = np.zeros(2 * (p_orders + 1) * d_vars**2)\n","    rho, alpha, h_value, h_new = 1.0, 0.0, np.inf, np.inf\n","\n","    for n_iter in range(max_iter):\n","        while (rho < 1e20) and (h_new > 0.25 * h_value or h_new == np.inf):\n","            wa_new = sopt.minimize(\n","                _func, wa_est, method=\"L-BFGS-B\", jac=_grad, bounds=bnds\n","            ).x\n","            h_new = _h(wa_new)\n","            if h_new > 0.25 * h_value:\n","                rho *= 10\n","\n","        wa_est = wa_new\n","        h_value = h_new\n","        alpha += rho * h_value\n","        if h_value <= h_tol:\n","            break\n","        if h_value > h_tol and n_iter == max_iter - 1:\n","            warnings.warn(\"Failed to converge. Consider increasing max_iter.\")\n","    return _reshape_wa(wa_est, d_vars, p_orders)"]},{"cell_type":"markdown","metadata":{"id":"eLDFzWZzrxb6"},"source":["## Milp\n","\n","* Mixed-Integer Linear Programming Learning DAG"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L_lIHaChrxoJ"},"outputs":[],"source":["from typing import Tuple, Dict\n","\n","import gurobipy as gp\n","import numpy as np\n","from gurobipy import GRB\n","from gurobipy import Model\n","from omegaconf import DictConfig, OmegaConf\n","\n","import notears.utils as notears_utils\n","\n","\n","import igraph as ig\n","\n","from dagsolvers.dagsolver_utils import apply_threshold, find_optimal_threshold_for_shd, find_minimal_dag_threshold\n","\n","\n","def find_cycles(edges, mode):\n","    vertices = set(e[0] for e in edges)\n","    vertices.update(e[1] for e in edges)\n","\n","    visited = set()\n","    on_stack = set()\n","    parent = {}\n","    stack = []\n","    shortest_cycle = None\n","    found_cycles = []\n","    number_of_cycles = 0\n","\n","    for root in vertices:\n","        if root in visited:\n","            continue\n","        stack.append(root)\n","        while stack:\n","            v = stack[-1]\n","            if v not in visited:\n","                visited.add(v)\n","                on_stack.add(v)\n","            else:\n","                if v in on_stack:\n","                    on_stack.remove(v)\n","                # else:\n","                #     print('DEBUG')\n","                stack.pop()\n","\n","            neighbors = [e[1] for e in edges if e[0] == v]\n","            for neighbor in neighbors:\n","                if neighbor not in visited:\n","                    stack.append(neighbor)\n","                    parent[neighbor] = v\n","                elif neighbor in on_stack:\n","                    number_of_cycles += 1\n","                    # Found a cycle\n","                    cycle = [neighbor, v] # Back edge\n","                    p = parent[v]\n","                    while p != neighbor:\n","                        cycle.append(p)\n","                        p=parent[p]\n","                    #print(cycle)\n","                    if mode == 'first_cycle':\n","                        return [cycle] # return the first found cycle\n","                    found_cycles.append(cycle)\n","                    if shortest_cycle is None or len(shortest_cycle) > len(cycle):\n","                        shortest_cycle = cycle\n","\n","    #print(f'number of cycles: {number_of_cycles}')\n","    if mode == 'shortest_cycle':\n","        if shortest_cycle is not None:\n","            return [shortest_cycle]\n","        else:\n","            return []\n","    elif mode == 'all_cycles':\n","        return found_cycles\n","    elif mode == 'first_cycle':\n","        return []\n","    else:\n","        assert False, f'Invalid mode{mode}'\n","\n","\n","def extract_adj_matrix(edges_vals, weights_vals, d):\n","    W = np.zeros((d,d))\n","    for v1 in range(d):\n","        for v2 in range(d):\n","            if v1 != v2:\n","                if edges_vals[v1, v2] > 0.5:\n","                    W[v1, v2] = weights_vals[(v1, v2)]\n","    return W\n","\n","def extract_adj_matrix_no_vars(weights_vals, d):\n","    A = np.zeros((d,d))\n","    for v1 in range(d):\n","        for v2 in range(d):\n","            A[v1, v2] = weights_vals[(v1, v2)]\n","    return A\n","\n","def check_for_cycles(model, where):\n","    if where == GRB.Callback.MESSAGE:\n","        pass\n","        # edges_vals = model.cbGetSolution(model._edges_vars)\n","        # weights_vals = model.cbGetSolution(model._edges_weights)\n","        # W = extract_adj_matrix(edges_vals, weights_vals)\n","        # print(W)\n","\n","    if where == GRB.Callback.MIPSOL:\n","        #print('CALLBACK')\n","        # make a list of edges selected in the solution\n","        constr_added = False\n","        vals = model.cbGetSolution(model._edges_vars)\n","        weights_vals = model.cbGetSolution(model._edges_weights)\n","        selected_edges = gp.tuplelist((i, j) for i, j in model._edges_vars.keys()\n","                                      if vals[i, j] > 0.5)\n","        # find the shortest cycle in the selected edge list\n","        cycles = find_cycles(selected_edges, model._callback_mode)\n","        for cycle in cycles:\n","            edges_of_cycle = []\n","            for i in range(len(cycle)-1):\n","                edges_of_cycle.append((cycle[i+1], cycle[i]))\n","            edges_of_cycle.append((cycle[0], cycle[-1]))\n","            #callback_constraints[1] = callback_constraints[1] + 1\n","            #print('NEW CONSTRAINT')\n","            model._lazy_count += 1\n","            model.cbLazy(gp.quicksum(model._edges_vars[i, j] for i, j in edges_of_cycle)\n","                         <= len(edges_of_cycle)-1)\n","            constr_added = True\n","\n","        # Compute solving statistics\n","        rt = model.cbGet(GRB.Callback.RUNTIME)\n","        if not constr_added and model._B_ref is not None and (rt - model._last_time_stats > 60): # Compute statistics every 60 seconds\n","            B_true = model._B_ref\n","            model._last_time_stats = rt\n","            W_sol = extract_adj_matrix(vals, weights_vals, model._d)\n","            dag_t, W_sol = find_minimal_dag_threshold(W_sol)\n","            #W_sol = apply_threshold(W_sol, 0.3)\n","            default_threshold = 0.3\n","            W_t = apply_threshold(W_sol, default_threshold)\n","            shd = utils.count_accuracy(B_true, W_t != 0)['shd']\n","            objval = model.cbGet(GRB.Callback.MIPSOL_OBJ)\n","\n","            best_t, best_shd = find_optimal_threshold_for_shd(B_true, W_sol, [], [], np.zeros_like(B_true), np.zeros_like(B_true))\n","\n","            print(f't{default_threshold}_SHD: {shd} BEST_SHD: {best_shd} BEST_t: {best_t} OBJ: {objval} DAG_t: {dag_t}')\n","            model._stats.append((round(rt), shd, best_shd, best_t, objval, dag_t))\n","\n","\n","\n","\n","\n","\n","def construct_matrix_vars(m: Model, d: int, matrix_name: str, constraints_mode, weights_bound, tabu_edges, diagonal=False) -> Tuple[Dict, Dict]:\n","    edges_vars = {}\n","    edges_weights = {}\n","    for v1 in range(d):\n","        for v2 in range(d):\n","            if diagonal or v1 != v2:\n","                if constraints_mode != 'no-vars':\n","                    edges_vars[v1,v2] = m.addVar(vtype=GRB.BINARY, name=f'{matrix_name}_{v1}->{v2}')\n","                edges_weights[v1,v2] = m.addVar(lb = float('-inf'),vtype=GRB.CONTINUOUS, name=f'{matrix_name}_weight{v1}->{v2}')\n","\n","                if constraints_mode == 'no-weights':\n","                    m.addConstr(edges_weights[v1,v2] == edges_vars[v1,v2])\n","                elif constraints_mode == 'no-vars':\n","                    m.addConstr(edges_weights[v1,v2] <= weights_bound)\n","                    m.addConstr(-edges_weights[v1,v2] <= weights_bound)\n","                else:\n","                    m.addConstr(edges_weights[v1,v2] <= weights_bound * edges_vars[v1,v2])\n","                    m.addConstr(-edges_weights[v1,v2] <= weights_bound * edges_vars[v1,v2])\n","    if tabu_edges is not None:\n","        for (v1,v2) in tabu_edges:\n","            m.addConstr(edges_vars[v1,v2] == 0)\n","            m.addConstr(edges_weights[v1,v2] == 0)\n","    return edges_vars, edges_weights\n","\n","\n","def solve(X, cfg: DictConfig, w_threshold, Y=None, B_ref=None, tabu_edges=None):\n","\n","    time_limit = cfg.time_limit\n","    lambda1 = cfg.lambda1\n","    lambda2 = cfg.lambda2\n","    loss_type = cfg.loss_type\n","    constraints_mode = cfg.constraints_mode\n","    mode = cfg.callback_mode\n","    robust = cfg.robust\n","    weights_bound = cfg.weights_bound\n","    reg_type = cfg.reg_type\n","    a_reg_type = cfg.a_reg_type\n","    target_mip_gap = cfg.target_mip_gap\n","\n","    n, d = X.shape\n","    if Y is None:\n","        Y = []\n","    p = len(Y) # The number of historical data slices\n","     # 'no-weights'\n","    # if loss_type == 'l2':\n","    #     X = X - np.mean(X, axis=0, keepdims=True)\n","\n","\n","    m = gp.Model()\n","    W_edges_vars, W_edges_weights = construct_matrix_vars(m, d, 'W', constraints_mode, weights_bound, tabu_edges)\n","    for v1 in range(d):\n","        for v2 in range(v1):\n","            m.addConstr(W_edges_vars[v2,v1] + W_edges_vars[v1,v2] <= 1)\n","\n","    A_edges_vars = []\n","    A_edges_weights = []\n","\n","    a_constraints_mode = '' if a_reg_type == 'l1' else 'no-vars'\n","\n","    for t in range(p):\n","        A_t_edges_vars, A_t_edges_weights = construct_matrix_vars(m, d, f'A_{t}', a_constraints_mode, weights_bound, diagonal=True, tabu_edges=None)\n","        A_edges_vars.append(A_t_edges_vars)\n","        A_edges_weights.append(A_t_edges_weights)\n","\n","    robust_vars = {}\n","    quad_diff = {}\n","    if robust:\n","        for i in range(n):\n","            robust_vars[i] = m.addVar(vtype=GRB.BINARY, name=f's{i}')\n","            for j in range(d):\n","                quad_diff[i, j] = m.addVar(lb = float('-inf'),vtype=GRB.CONTINUOUS, name=f'q{i}-{j}')\n","        r = round(0.9 * n)\n","        m.addConstr(gp.quicksum(robust_vars[i] for i in range(n)) >= r)\n","        for i in range(n):\n","            for j in range(d):\n","                m.addConstr((X[i,j] - gp.quicksum(X[i, k] * W_edges_weights[k, j] for k in range(d) if k != j) - gp.quicksum(Y[t][i, k] * A_edges_weights[t][k, j] for k in range(d) for t in range(p)))**2 == quad_diff[i,j])\n","        robust_objective = gp.quicksum(quad_diff[i,j] * robust_vars[i] for i in range(n) for j in range(d))\n","    #callback_constraints = {}\n","    #callback_constraints[1] = 0\n","\n","\n","    # regulazition\n","    if reg_type == 'l2':\n","        reg = gp.quicksum(w**2 for w in W_edges_weights.values())\n","        # reg2 = 0\n","        # for A_t_edges_weights in A_edges_weights:\n","        #     reg2 = reg2 + gp.quicksum(a**2 for a in A_t_edges_weights.values())\n","    elif reg_type == 'l1':\n","        reg = gp.quicksum(w for w in W_edges_vars.values())\n","        # reg2 = 0\n","        # l2 reg for As becouse we dont have decision variables for them.\n","        # for A_t_edges_weights in A_edges_weights:\n","        #     reg2 = reg2 + gp.quicksum(a**2 for a in A_t_edges_weights.values())\n","        # for A_t_edges_vars in A_edges_vars:\n","        #     reg = reg + gp.quicksum(a for a in A_t_edges_vars.values())\n","    else:\n","        assert False\n","\n","    if a_reg_type == 'l2':\n","        reg2 = 0\n","        for A_t_edges_weights in A_edges_weights:\n","            reg2 = reg2 + gp.quicksum(a**2 for a in A_t_edges_weights.values())\n","    elif a_reg_type == 'l1':\n","        reg2 = 0\n","        for A_t_edges_vars in A_edges_vars:\n","            reg = reg + gp.quicksum(a for a in A_t_edges_vars.values())\n","    else:\n","        assert False\n","\n","\n","    # Cost function\n","    if loss_type == 'l2':\n","        if robust:\n","            m.setObjective(robust_objective + lambda1 * reg / d + lambda2 * reg2 / d, GRB.MINIMIZE)\n","        else:\n","            m.setObjective(gp.quicksum((X[i,j] - gp.quicksum(X[i, k] * W_edges_weights[k, j] for k in range(d) if k != j)\n","                                        - gp.quicksum(Y[t][i, k] * A_edges_weights[t][k, j] for k in range(d) for t in range(p))\n","                                        )**2 for i in range(n) for j in range(d))/n + lambda1 * reg / d + lambda2 * reg2 / d, GRB.MINIMIZE)\n","            print(m.getObjective().getValue())\n","    elif loss_type == 'l1':\n","\n","        abs_vars = {}\n","        for i in range(n):\n","            for j in range(d):\n","                abs_vars[i,j] = m.addVar(vtype=GRB.CONTINUOUS, name=f'abs{i}-{j})')\n","                m.addConstr((X[i,j] - gp.quicksum(X[i, k] * W_edges_weights[k, j] for k in range(d) if k != j) - gp.quicksum(Y[t][i, k] * A_edges_weights[t][k, j] for k in range(d) for t in range(p))) <= abs_vars[i,j])\n","                m.addConstr(-(X[i,j] - gp.quicksum(X[i, k] * W_edges_weights[k, j] for k in range(d) if k != j) - gp.quicksum(Y[t][i, k] * A_edges_weights[t][k, j] for k in range(d) for t in range(p))) <= abs_vars[i,j])\n","\n","        # abs_edges_weights={}\n","        # for v1 in range(d):\n","        #     for v2 in range(d):\n","        #         if v1 != v2:\n","        #             abs_edges_weights[v1,v2] = m.addVar(vtype=GRB.CONTINUOUS, name=f'abs_weight{v1}->{v2}')\n","        #             m.addConstr(W_edges_weights[v1,v2] <= abs_edges_weights[v1,v2])\n","        #             m.addConstr(-W_edges_weights[v1,v2] <= abs_edges_weights[v1,v2])\n","\n","\n","        m.setObjective(gp.quicksum(abs_vars[i,j] for i in range(n) for j in range(d))/n + lambda1 * reg / d + lambda2 * reg2 / d, GRB.MINIMIZE)\n","\n","    m.Params.lazyConstraints = 1\n","    m.Params.MIPGap = target_mip_gap\n","    m.params.TimeLimit = time_limit\n","    m._edges_vars = W_edges_vars\n","    m._edges_weights = W_edges_weights\n","    m._lazy_count = 0\n","    m._last_time_stats = 0\n","    m._B_ref = B_ref\n","    m._stats = []\n","    m._d = d\n","    m._callback_mode = mode\n","    m.optimize(check_for_cycles)\n","\n","    sol_count = m.getAttr(GRB.attr.SolCount)\n","    if sol_count == 0:\n","        return None, None, None, None, None\n","    gap = m.MIPGap\n","    lazy_count = m._lazy_count\n","    stats = m._stats\n","\n","    #print(f'add constraints: {callback_constraints[1]}')\n","\n","    W_edges_vals = m.getAttr('x', W_edges_vars)\n","    W_weights_vals = m.getAttr('x', W_edges_weights)\n","\n","    W = extract_adj_matrix(W_edges_vals, W_weights_vals, d)\n","\n","    A = []\n","    for t in range(p):\n","        #A_t_edges_vals = m.getAttr('x', A_edges_vars[t])\n","        A_t_weights_vals = m.getAttr('x', A_edges_weights[t])\n","        A_t = extract_adj_matrix_no_vars(A_t_weights_vals, d)\n","        A.append(A_t)\n","\n","    assert utils.is_dag(W)\n","    m.dispose()\n","    gp.disposeDefaultEnv()\n","\n","    # threshold_func = np.vectorize(lambda x: (x if abs(x) > threshold else 0.0))\n","    # W_t = threshold_func(W)\n","\n","    W[np.abs(W) < w_threshold] = 0\n","\n","    return W, A, gap, lazy_count, stats\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"jVKrwMb1kLsE"},"source":["## ExMAG\n","\n","* Learning MAG"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G9MTQnUDkL1r"},"outputs":[],"source":["import gurobipy as gp\n","import numpy as np\n","from gurobipy import GRB\n","# import notears.utils as notears_utils\n","\n","\n","import igraph as ig\n","\n","# from dagsolvers.dagsolver_utils import apply_threshold, find_optimal_threshold, find_minimal_dag_threshold\n","\n","\n","def find_cycles(edges, mode):\n","    vertices = set(e[0] for e in edges)\n","    vertices.update(e[1] for e in edges)\n","\n","    visited = set()\n","    on_stack = set()\n","    parent = {}\n","    stack = []\n","    shortest_cycle = None\n","    found_cycles = []\n","    number_of_cycles = 0\n","\n","    for root in vertices:\n","        if root in visited:\n","            continue\n","        stack.append(root)\n","        while stack:\n","            v = stack[-1]\n","            if v not in visited:\n","                visited.add(v)\n","                on_stack.add(v)\n","            else:\n","                if v in on_stack:\n","                    on_stack.remove(v)\n","                # else:\n","                #     print('DEBUG')\n","                stack.pop()\n","\n","            neighbors = [e[1] for e in edges if e[0] == v]\n","            for neighbor in neighbors:\n","                if neighbor not in visited:\n","                    stack.append(neighbor)\n","                    parent[neighbor] = v\n","                elif neighbor in on_stack:\n","                    number_of_cycles += 1\n","                    # Found a cycle\n","                    cycle = [neighbor, v] # Back edge\n","                    p = parent[v]\n","                    while p != neighbor:\n","                        cycle.append(p)\n","                        p=parent[p]\n","                    #print(cycle)\n","                    #return cycle # return the first found cycle\n","                    found_cycles.append(cycle)\n","                    if shortest_cycle is None or len(shortest_cycle) > len(cycle):\n","                        shortest_cycle = cycle\n","\n","    #print(f'number of cycles: {number_of_cycles}')\n","    if mode == 'shortest_cycle':\n","        if shortest_cycle is not None:\n","            return [shortest_cycle]\n","        else:\n","            return []\n","    elif mode == 'all_cycles':\n","        return found_cycles\n","    else:\n","        assert False, f'Invalid mode{mode}'\n","\n","\n","def extract_adj_matrix(edges_vals, weights_vals, d):\n","    W = np.zeros((d,d))\n","    for v1 in range(d):\n","        for v2 in range(d):\n","            if v1 != v2:\n","                if edges_vals[v1, v2] > 0.5:\n","                    W[v1, v2] = weights_vals[(v1, v2)]\n","    return W\n","\n","## 3.无环约束：通过检测环来防止模型中出现环形结构。检测到环后，通过以下约束去除环，并确保新加的边不会引入环。\n","def check_for_cycles(model, where):\n","    if where == GRB.Callback.MESSAGE:\n","        pass\n","        # edges_vals = model.cbGetSolution(model._edges_vars)\n","        # weights_vals = model.cbGetSolution(model._edges_weights)\n","        # W = extract_adj_matrix(edges_vals, weights_vals)\n","        # print(W)\n","\n","    if where == GRB.Callback.MIPSOL:\n","        #print('CALLBACK')\n","        # make a list of edges selected in the solution\n","        constr_added = False\n","        vals = model.cbGetSolution(model._edges_vars)\n","        weights_vals = model.cbGetSolution(model._edges_weights)\n","        selected_edges = gp.tuplelist((i, j) for i, j in model._edges_vars.keys()\n","                                      if vals[i, j] > 0.5)\n","        # find the shortest cycle in the selected edge list\n","        cycles = find_cycles(selected_edges, model._callback_mode)\n","        for cycle in cycles:\n","            edges_of_cycle = []\n","            for i in range(len(cycle)-1):\n","                edges_of_cycle.append((cycle[i+1], cycle[i]))\n","            edges_of_cycle.append((cycle[0], cycle[-1]))\n","            #callback_constraints[1] = callback_constraints[1] + 1\n","            #print('NEW CONSTRAINT')\n","            model._lazy_count += 1\n","            model.cbLazy(gp.quicksum(model._edges_vars[i, j] for i, j in edges_of_cycle)\n","                         <= len(edges_of_cycle)-1)\n","            constr_added = True\n","\n","        # Compute solving statistics\n","        rt = model.cbGet(GRB.Callback.RUNTIME)\n","        if not constr_added and model._B_ref is not None and (rt - model._last_time_stats > 60): # Compute statistics every 60 seconds\n","            B_true = model._B_ref\n","            model._last_time_stats = rt\n","            W_sol = extract_adj_matrix(vals, weights_vals, model._d)\n","            dag_t, W_sol = find_minimal_dag_threshold(W_sol)\n","            #W_sol = apply_threshold(W_sol, 0.3)\n","            default_threshold = 0.3\n","            W_t = apply_threshold(W_sol, default_threshold)\n","            shd = notears_utils.count_accuracy(B_true, W_t != 0)['shd']\n","            objval = model.cbGet(GRB.Callback.MIPSOL_OBJ)\n","\n","            best_t, best_shd, _, _ = find_optimal_threshold(B_true, W_sol)\n","\n","            print(f't{default_threshold}_SHD: {shd} BEST_SHD: {best_shd} BEST_t: {best_t} OBJ: {objval} DAG_t: {dag_t}')\n","            model._stats.append((round(rt), shd, best_shd, best_t, objval, dag_t))\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","def solve(X, lambda1, loss_type, reg_type, w_threshold, B_ref=None, mode='shortest_cycle', time_limit=300, robust=False, weights_bound=100.0, constraints_mode='weights'):\n","        n, d = X.shape\n","\n","         # 'no-weights'\n","        # if loss_type == 'l2':\n","        #     X = X - np.mean(X, axis=0, keepdims=True)\n","\n","\n","        m = gp.Model()\n","        edges_vars = {}\n","        edges_weights = {}\n","\n","        for v1 in range(d):\n","            for v2 in range(d):\n","                if v1 != v2:\n","                    ## 1. 二值约束：对于每个可能的边，变量 edges_vars 表示该边是否存在，为二值变量（0或1）。\n","                    edges_vars[v1,v2] = m.addVar(vtype=GRB.BINARY, name=f'{v1}->{v2}')\n","                    edges_weights[v1,v2] = m.addVar(lb = float('-inf'),vtype=GRB.CONTINUOUS, name=f'weight{v1}->{v2}')\n","\n","                    ## 2. 权重约束：权重w_{v_1, v_2} 与边变量 edges_vars_{v_1, v_2}相关联。如果不存在从v1到v2的边，则权重为零。\n","                    if constraints_mode == 'no-weights':\n","                        m.addConstr(edges_weights[v1,v2] == edges_vars[v1,v2])\n","                    else:\n","                        m.addConstr(edges_weights[v1,v2] <= weights_bound * edges_vars[v1,v2])\n","                        m.addConstr(-edges_weights[v1,v2] <= weights_bound * edges_vars[v1,v2])\n","\n","        ## 4. 双向约束：在每对变量之间最多允许一条有向边，即 v1-v2和v2-v1不能同时存在。\n","        for v1 in range(d):\n","            for v2 in range(v1):\n","                m.addConstr(edges_vars[v2,v1] + edges_vars[v1,v2] <= 1)\n","\n","        robust_vars = {}\n","        quad_diff = {}\n","        if robust:\n","            for i in range(n):\n","                robust_vars[i] = m.addVar(vtype=GRB.BINARY, name=f's{i}')\n","                for j in range(d):\n","                    quad_diff[i, j] = m.addVar(lb = float('-inf'),vtype=GRB.CONTINUOUS, name=f'q{i}-{j}')\n","            r = round(0.9 * n)\n","            m.addConstr(gp.quicksum(robust_vars[i] for i in range(n)) >= r)\n","            for i in range(n):\n","                for j in range(d):\n","                    m.addConstr((X[i,j] - gp.quicksum(X[i, k] * edges_weights[k, j] for k in range(d) if k != j))**2 == quad_diff[i,j])\n","            robust_objective = gp.quicksum(quad_diff[i,j] * robust_vars[i] for i in range(n) for j in range(d))\n","        #callback_constraints = {}\n","        #callback_constraints[1] = 0\n","\n","\n","        # regulazition\n","        if reg_type == 'l2':\n","            reg = gp.quicksum(w**2 for w in edges_weights.values())\n","        elif reg_type == 'l1':\n","            reg = gp.quicksum(w for w in edges_vars.values())\n","        else:\n","            assert False\n","\n","\n","\n","        # Cost function\n","        if loss_type == 'l2':\n","            if robust:\n","                m.setObjective(robust_objective + lambda1 * reg / d, GRB.MINIMIZE)\n","            else:\n","                m.setObjective(gp.quicksum((X[i,j] - gp.quicksum(X[i, k] * edges_weights[k, j] for k in range(d) if k != j))**2 for i in range(n) for j in range(d))/n + lambda1 * reg / d, GRB.MINIMIZE)\n","                print(m.getObjective().getValue())\n","        elif loss_type == 'l1':\n","\n","            abs_vars = {}\n","            for i in range(n):\n","                for j in range(d):\n","                    abs_vars[i,j] = m.addVar(vtype=GRB.CONTINUOUS, name=f'abs{i}-{j})')\n","                    m.addConstr((X[i,j] - gp.quicksum(X[i, k] * edges_weights[k, j] for k in range(d) if k != j)) <= abs_vars[i,j])\n","                    m.addConstr(-(X[i,j] - gp.quicksum(X[i, k] * edges_weights[k, j] for k in range(d) if k != j)) <= abs_vars[i,j])\n","\n","            abs_edges_weights={}\n","            for v1 in range(d):\n","                for v2 in range(d):\n","                    if v1 != v2:\n","                        abs_edges_weights[v1,v2] = m.addVar(vtype=GRB.CONTINUOUS, name=f'abs_weight{v1}->{v2}')\n","                        m.addConstr(edges_weights[v1,v2] <= abs_edges_weights[v1,v2])\n","                        m.addConstr(-edges_weights[v1,v2] <= abs_edges_weights[v1,v2])\n","\n","\n","            m.setObjective(gp.quicksum(abs_vars[i,j] for i in range(n) for j in range(d)) + lambda1 * reg, GRB.MINIMIZE)\n","\n","\n","\n","\n","\n","        m.Params.lazyConstraints = 1\n","        m.Params.MIPGap = 0.1\n","        m.params.TimeLimit = time_limit\n","        m._edges_vars = edges_vars\n","        m._edges_weights = edges_weights\n","        m._lazy_count = 0\n","        m._last_time_stats = 0\n","        m._B_ref = B_ref\n","        m._stats = []\n","        m._d = d\n","        m._callback_mode = mode\n","        m.optimize(check_for_cycles)\n","\n","        gap = m.MIPGap\n","        lazy_count = m._lazy_count\n","        stats = m._stats\n","\n","        #print(f'add constraints: {callback_constraints[1]}')\n","\n","        edges_vals = m.getAttr('x', edges_vars)\n","        weights_vals = m.getAttr('x', edges_weights)\n","\n","        W = extract_adj_matrix(edges_vals, weights_vals, d)\n","\n","        assert notears_utils.is_dag(W)\n","        m.dispose()\n","        gp.disposeDefaultEnv()\n","\n","        # threshold_func = np.vectorize(lambda x: (x if abs(x) > threshold else 0.0))\n","        # W_t = threshold_func(W)\n","\n","        W[np.abs(W) < w_threshold] = 0\n","\n","        return W, gap, lazy_count, stats\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"1yTUOjUulbYp"},"source":["## sortnregress"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2PSieVsQlbiJ"},"outputs":[],"source":["import numpy as np\n","from sklearn.linear_model import LinearRegression, LassoLarsIC\n","\n","\n","def sortnregress(X):\n","    \"\"\" Take n x d data, order nodes by marginal variance and\n","    regresses each node onto those with lower variance, using\n","    edge coefficients as structure estimates. \"\"\"\n","    LR = LinearRegression()\n","    LL = LassoLarsIC(criterion='bic')\n","\n","    d = X.shape[1]\n","    W = np.zeros((d, d))\n","    increasing = np.argsort(np.var(X, axis=0))\n","\n","    for k in range(1, d):\n","        covariates = increasing[:k]\n","        target = increasing[k]\n","\n","        LR.fit(X[:, covariates], X[:, target].ravel())\n","        weight = np.abs(LR.coef_)\n","        LL.fit(X[:, covariates] * weight, X[:, target].ravel())\n","        W[covariates, target] = LL.coef_ * weight\n","\n","    return W\n"]},{"cell_type":"markdown","source":["# IP-ADMG"],"metadata":{"id":"f5mgzJpztul7"}},{"cell_type":"markdown","source":["## BNSLlvInst"],"metadata":{"id":"af1fzJPNWytn"}},{"cell_type":"code","source":["import pickle\n","import math\n","import copy\n","import time\n","#from dircycle2 import dircyc,almostdircyc\n","#from heuristic2 import contract_heur,contract_heur_bdir\n","from gurobipy import *\n","\n","class BNSLlvInst:\n","\tdef __init__(self,instance):\n","\t\tself.instance = instance\n","\t\tself.originalScores = None\n","\t\tself.scores = None\n","\t\tself.data = None\n","\t\tself.V = None\n","\t\tself.cComps = None\n","\t\tself.iComps = None\n","\t\tself.dPars = None\n","\t\tself.iPars = None\n","\t\tself.biPars = None\n","\t\tself.m = None\n","\t\tself.z = None\n","\t\tself.ind = None\n","\t\tself.indInv = None\n","\t\tself.udE = None\n","\t\tself.bi = None\n","\t\tself.x = None\n","\t\tself.clusterIP = None\n","\t\tself.ConflictNodes = None\n","\t\tself.ConflictEdges = None\n","\n","\tdef readFromPkl(self):\n","\t\tfilename = self.instance\n","\t\tfile = open(filename, 'rb')\n","\t\t[self.data,self.originalScores] = pickle.load(file)\n","\t\tprint(self.data,self.originalScores)\n","\t\tfile.close()\n","\n","  # Prune redundant c-components\n","\tdef Prune_scores(self):\n","\t\tt0P = time.time()\n","\t\tsum1 = 0\n","\t\tsum2 = 0\n","\t\tDpars = {}\n","\t\tfor D in self.originalScores.keys():\n","\t\t\tif len(D[0]) == 1:\n","\t\t\t\tDpars[D] = list(self.originalScores[D].keys())\n","\t\t\t\tDparscopy = Dpars[D].copy()\n","\t\t\t\tfor ind in range(len(Dpars[D])):\n","\t\t\t\t\tfor i in range(ind+1,len(self.originalScores[D])):\n","\t\t\t\t\t\tif set(Dpars[D][ind][0]).difference(set(Dpars[D][i][0])) == set() and self.originalScores[D][Dpars[D][ind]] >= self.originalScores[D][Dpars[D][i]]:\n","\t\t\t\t\t\t\tif Dpars[D][i] in Dparscopy:\n","\t\t\t\t\t\t\t\tDparscopy.remove(Dpars[D][i])\n","\t\t\t\tsum1 = sum1+len(Dpars[D])\n","\t\t\t\tDpars[D] = Dparscopy.copy()\n","\t\t\t\tsum2 = sum2+len(Dpars[D])\n","\n","\t\t\t# size 2 c-component\n","\t\t\telif len(D[0]) == 2:\n","\t\t\t\tDpars[D] = list(self.originalScores[D].keys())\n","\t\t\t\tDparscopy = Dpars[D].copy()\n","\t\t\t\tfor ind in range(len(Dpars[D])):\n","\t\t\t\t\t# a = D[0][0], b = D[0][1]\n","\t\t\t\t\t# a<->b vs a<->b\n","\t\t\t\t\tdelInd = False\n","\t\t\t\t\tfor i in range(ind):\n","\t\t\t\t\t\tif set(Dpars[D][i][0]).difference(set(Dpars[D][ind][0])) == set() and set(Dpars[D][i][1]).difference(set(Dpars[D][ind][1])) == set() and self.originalScores[D][Dpars[D][ind]] <= self.originalScores[D][Dpars[D][i]]:\n","\t\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\t\tdelInd = True\n","\t\t\t\t\t\t\tbreak\n","\t\t\t\t\tif delInd == True:\n","\t\t\t\t\t\tcontinue\n","\t\t\t\t\t# a<->b vs a,b\n","\t\t\t\t\tDa = ((D[0][0],),())\n","\t\t\t\t\tDb = ((D[0][1],),())\n","\t\t\t\t\tDaPars = list(self.originalScores[Da].keys())\n","\t\t\t\t\tDbPars = list(self.originalScores[Db].keys())\n","\t\t\t\t\tmaxa = -float('inf')\n","\t\t\t\t\tmaxb = -float('inf')\n","\t\t\t\t\tfor ind1 in range(len(DaPars)):\n","\t\t\t\t\t\tif set(DaPars[ind1][0]).difference(set(Dpars[D][ind][0])) == set() and self.originalScores[Da][DaPars[ind1]] > maxa:\n","\t\t\t\t\t\t\tmaxa = self.originalScores[Da][DaPars[ind1]]\n","\t\t\t\t\tfor ind2 in range(len(DbPars)):\n","\t\t\t\t\t\tif set(DbPars[ind2][0]).difference(set(Dpars[D][ind][1])) == set() and self.originalScores[Db][DbPars[ind2]] > maxb:\n","\t\t\t\t\t\t\tmaxb = self.originalScores[Db][DbPars[ind2]]\n","\t\t\t\t\tif self.originalScores[D][Dpars[D][ind]] <= maxa+maxb:\n","\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\tcontinue\n","\t\t\t\t\ttol = 1e-10\n","\t\t\t\t\t# a<->b vs a->b\n","\t\t\t\t\tDa = ((D[0][0],),())\n","\t\t\t\t\tDb = ((D[0][1],),())\n","\t\t\t\t\tDbPars = list(self.originalScores[Db].keys())\n","\t\t\t\t\tmaxa = self.originalScores[Da][((),)]\n","\t\t\t\t\tmaxb = -float('inf')\n","\t\t\t\t\tfor ind2 in range(len(DbPars)):\n","\t\t\t\t\t\tif set(DbPars[ind2][0]).difference(set(Dpars[D][ind][1])) == {D[0][0]} and self.originalScores[Db][DbPars[ind2]] > maxb:\n","\t\t\t\t\t\t\tmaxb = self.originalScores[Db][DbPars[ind2]]\n","\t\t\t\t\tif self.originalScores[D][Dpars[D][ind]] <= maxa+maxb+tol:\n","\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\tcontinue\n","\t\t\t\t\t# a<->b vs a<-b\n","\t\t\t\t\tDa = ((D[0][0],),())\n","\t\t\t\t\tDb = ((D[0][1],),())\n","\t\t\t\t\tDaPars = list(self.originalScores[Da].keys())\n","\t\t\t\t\tmaxa = -float('inf')\n","\t\t\t\t\tmaxb = self.originalScores[Db][((),)]\n","\t\t\t\t\tfor ind1 in range(len(DaPars)):\n","\t\t\t\t\t\tif set(DaPars[ind1][0]).difference(set(Dpars[D][ind][0])) == {D[0][1]} and self.originalScores[Da][DaPars[ind1]] > maxa:\n","\t\t\t\t\t\t\tmaxa = self.originalScores[Da][DaPars[ind1]]\n","\t\t\t\t\tif self.originalScores[D][Dpars[D][ind]] <= maxa+maxb+tol:\n","\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\tcontinue\n","\t\t\t\tsum1 = sum1+len(Dpars[D])\n","\t\t\t\tDpars[D] = Dparscopy.copy()\n","\t\t\t\tsum2 = sum2+len(Dpars[D])\n","\t\t\telif len(D[0]) == 3:\n","\t\t\t\tDpars[D] = list(self.originalScores[D].keys())\n","\t\t\t\tDparscopy = Dpars[D].copy()\n","\t\t\t\tfor ind in range(len(Dpars[D])):\n","\t\t\t\t\t# a<->b<->c\n","\t\t\t\t\tif len(D[1]) == 2:\n","\t\t\t\t\t\tNodeb = 0\n","\t\t\t\t\t\tfor i in D[0]:\n","\t\t\t\t\t\t\tif i in D[1][0] and i in D[1][1]:\n","\t\t\t\t\t\t\t\tNodeb = i\n","\t\t\t\t\t\t\t\tbreak\n","\t\t\t\t\t\tNodea = 0\n","\t\t\t\t\t\tfor i in D[0]:\n","\t\t\t\t\t\t\tif i != Nodeb and i in D[1][0]:\n","\t\t\t\t\t\t\t\tNodea = i\n","\t\t\t\t\t\t\t\tbreak\n","\t\t\t\t\t\tNodec = 0\n","\t\t\t\t\t\tfor i in D[0]:\n","\t\t\t\t\t\t\tif i != Nodeb and i in D[1][1]:\n","\t\t\t\t\t\t\t\tNodec = i\n","\t\t\t\t\t\t\t\tbreak\n","\t\t\t\t\t\tDa = ((Nodea,),())\n","\t\t\t\t\t\tDb = ((Nodeb,),())\n","\t\t\t\t\t\tDc = ((Nodec,),())\n","\t\t\t\t\t\tDab = (tuple(sorted((Nodea,Nodeb))),(tuple(sorted((Nodea,Nodeb))),))\n","\t\t\t\t\t\tDbc = (tuple(sorted((Nodeb,Nodec))),(tuple(sorted((Nodeb,Nodec))),))\n","\t\t\t\t\t\t# a<->b<->c vs a,b,c\n","\t\t\t\t\t\tDaPars = list(self.originalScores[Da].keys())\n","\t\t\t\t\t\tDbPars = list(self.originalScores[Db].keys())\n","\t\t\t\t\t\tDcPars = list(self.originalScores[Dc].keys())\n","\t\t\t\t\t\tmaxa = -float('inf')\n","\t\t\t\t\t\tmaxb = -float('inf')\n","\t\t\t\t\t\tmaxc = -float('inf')\n","\t\t\t\t\t\tfor ind1 in range(len(DaPars)):\n","\t\t\t\t\t\t\tif set(DaPars[ind1][0]).difference(set(Dpars[D][ind][D[0].index(Nodea)])) == set() and self.originalScores[Da][DaPars[ind1]] > maxa:\n","\t\t\t\t\t\t\t\tmaxa = self.originalScores[Da][DaPars[ind1]]\n","\t\t\t\t\t\tfor ind2 in range(len(DbPars)):\n","\t\t\t\t\t\t\tif set(DbPars[ind2][0]).difference(set(Dpars[D][ind][D[0].index(Nodeb)])) == set() and self.originalScores[Db][DbPars[ind2]] > maxb:\n","\t\t\t\t\t\t\t\tmaxb = self.originalScores[Db][DbPars[ind2]]\n","\t\t\t\t\t\tfor ind3 in range(len(DcPars)):\n","\t\t\t\t\t\t\tif set(DcPars[ind3][0]).difference(set(Dpars[D][ind][D[0].index(Nodec)])) == set() and self.originalScores[Dc][DcPars[ind3]] > maxc:\n","\t\t\t\t\t\t\t\tmaxc = self.originalScores[Dc][DcPars[ind3]]\n","\t\t\t\t\t\tif self.originalScores[D][Dpars[D][ind]] <= maxa+maxb+maxc:\n","\t\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\t\tcontinue\n","\t\t\t\t\t\t# a<->b<->c vs a<->b,c\n","\t\t\t\t\t\tDabPars = list(self.originalScores[Dab].keys())\n","\t\t\t\t\t\tDbcPars = list(self.originalScores[Dbc].keys())\n","\t\t\t\t\t\tmaxab = -float('inf')\n","\t\t\t\t\t\tmaxbc = -float('inf')\n","\t\t\t\t\t\tabInda = 0\n","\t\t\t\t\t\tabIndb = 1\n","\t\t\t\t\t\tif Nodea > Nodeb:\n","\t\t\t\t\t\t\tabInda = 1\n","\t\t\t\t\t\t\tabIndb = 0\n","\t\t\t\t\t\tfor ind1 in range(len(DabPars)):\n","\t\t\t\t\t\t\tif set(DabPars[ind1][abInda]).difference(set(Dpars[D][ind][D[0].index(Nodea)])) == set() and set(DabPars[ind1][abIndb]).difference(set(Dpars[D][ind][D[0].index(Nodeb)])) == set() and self.originalScores[Dab][DabPars[ind1]] > maxab:\n","\t\t\t\t\t\t\t\tmaxab = self.originalScores[Dab][DabPars[ind1]]\n","\t\t\t\t\t\tif self.originalScores[D][Dpars[D][ind]] <= maxab+maxc:\n","\t\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\t\tcontinue\n","\t\t\t\t\t\t# a<->b<->c vs a,b<->c\n","\t\t\t\t\t\tbcIndb = 0\n","\t\t\t\t\t\tbcIndc = 1\n","\t\t\t\t\t\tif Nodeb > Nodec:\n","\t\t\t\t\t\t\tbcIndb = 1\n","\t\t\t\t\t\t\tbcIndc = 0\n","\t\t\t\t\t\tfor ind1 in range(len(DbcPars)):\n","\t\t\t\t\t\t\tif set(DbcPars[ind1][bcIndb]).difference(set(Dpars[D][ind][D[0].index(Nodeb)])) == set() and set(DbcPars[ind1][bcIndc]).difference(set(Dpars[D][ind][D[0].index(Nodec)])) == set() and self.originalScores[Dbc][DbcPars[ind1]] > maxbc:\n","\t\t\t\t\t\t\t\tmaxbc = self.originalScores[Dbc][DbcPars[ind1]]\n","\t\t\t\t\t\tif self.originalScores[D][Dpars[D][ind]] <= maxa+maxbc:\n","\t\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\t\tcontinue\n","\t\t\t\t\t\t# a<->b<->c vs a<->b<->c\n","\t\t\t\t\t\tdelInd = False\n","\t\t\t\t\t\tfor i in range(ind):\n","\t\t\t\t\t\t\tif set(Dpars[D][i][0]).difference(set(Dpars[D][ind][0])) == set() and set(Dpars[D][i][1]).difference(set(Dpars[D][ind][1])) == set() and set(Dpars[D][i][2]).difference(set(Dpars[D][ind][2])) == set() and self.originalScores[D][Dpars[D][ind]] <= self.originalScores[D][Dpars[D][i]]:\n","\t\t\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\t\t\tdelInd = True\n","\t\t\t\t\t\t\t\tbreak\n","\t\t\t\t\t\tif delInd == True:\n","\t\t\t\t\t\t\tcontinue\n","\t\t\t\t\t# a<->b<->c<->a\n","\t\t\t\t\tif len(D[1]) == 3:\n","\t\t\t\t\t\tNodea = D[0][0]\n","\t\t\t\t\t\tNodeb = D[0][1]\n","\t\t\t\t\t\tNodec = D[0][2]\n","\t\t\t\t\t\tDab = ((Nodea,Nodeb),((Nodea,Nodeb),))\n","\t\t\t\t\t\tDbc = ((Nodeb,Nodec),((Nodeb,Nodec),))\n","\t\t\t\t\t\tDac = ((Nodea,Nodec),((Nodea,Nodec),))\n","\t\t\t\t\t\tDabc = ((Nodea,Nodeb,Nodec),((Nodea,Nodeb),(Nodeb,Nodec)))\n","\t\t\t\t\t\tif Dabc not in self.originalScores.keys():\n","\t\t\t\t\t\t\tDabc = ((Nodea,Nodeb,Nodec),((Nodeb,Nodec),(Nodea,Nodeb)))\n","\t\t\t\t\t\tDbca = ((Nodea,Nodeb,Nodec),((Nodeb,Nodec),(Nodea,Nodec)))\n","\t\t\t\t\t\tif Dbca not in self.originalScores.keys():\n","\t\t\t\t\t\t\tDbca = ((Nodea,Nodeb,Nodec),((Nodea,Nodec),(Nodeb,Nodec)))\n","\t\t\t\t\t\tDcab = ((Nodea,Nodeb,Nodec),((Nodea,Nodec),(Nodeb,Nodec)))\n","\t\t\t\t\t\tif Dcab not in self.originalScores.keys():\n","\t\t\t\t\t\t\tDcab = ((Nodea,Nodeb,Nodec),((Nodeb,Nodec),(Nodea,Nodec)))\n","\t\t\t\t\t\tDaPars = list(self.originalScores[Da].keys())\n","\t\t\t\t\t\tDbPars = list(self.originalScores[Db].keys())\n","\t\t\t\t\t\tDcPars = list(self.originalScores[Dc].keys())\n","\t\t\t\t\t\tmaxa = -float('inf')\n","\t\t\t\t\t\tmaxb = -float('inf')\n","\t\t\t\t\t\tmaxc = -float('inf')\n","\t\t\t\t\t\tfor ind1 in range(len(DaPars)):\n","\t\t\t\t\t\t\tif set(DaPars[ind1][0]).difference(set(Dpars[D][ind][D[0].index(Nodea)])) == set() and self.originalScores[Da][DaPars[ind1]] > maxa:\n","\t\t\t\t\t\t\t\tmaxa = self.originalScores[Da][DaPars[ind1]]\n","\t\t\t\t\t\tfor ind2 in range(len(DbPars)):\n","\t\t\t\t\t\t\tif set(DbPars[ind2][0]).difference(set(Dpars[D][ind][D[0].index(Nodeb)])) == set() and self.originalScores[Db][DbPars[ind2]] > maxb:\n","\t\t\t\t\t\t\t\tmaxb = self.originalScores[Db][DbPars[ind2]]\n","\t\t\t\t\t\tfor ind3 in range(len(DcPars)):\n","\t\t\t\t\t\t\tif set(DcPars[ind3][0]).difference(set(Dpars[D][ind][D[0].index(Nodec)])) == set() and self.originalScores[Dc][DcPars[ind3]] > maxc:\n","\t\t\t\t\t\t\t\tmaxc = self.originalScores[Dc][DcPars[ind3]]\n","\t\t\t\t\t\tDabPars = list(self.originalScores[Dab].keys())\n","\t\t\t\t\t\tDbcPars = list(self.originalScores[Dbc].keys())\n","\t\t\t\t\t\tDacPars = list(self.originalScores[Dac].keys())\n","\t\t\t\t\t\tmaxab = -float('inf')\n","\t\t\t\t\t\tmaxbc = -float('inf')\n","\t\t\t\t\t\tmaxac = -float('inf')\n","\t\t\t\t\t\tfor ind1 in range(len(DabPars)):\n","\t\t\t\t\t\t\tif set(DabPars[ind1][0]).difference(set(Dpars[D][ind][D[0].index(Nodea)])) == set() and set(DabPars[ind1][1]).difference(set(Dpars[D][ind][D[0].index(Nodeb)])) == set() and self.originalScores[Dab][DabPars[ind1]] > maxab:\n","\t\t\t\t\t\t\t\tmaxab = self.originalScores[Dab][DabPars[ind1]]\n","\t\t\t\t\t\tfor ind1 in range(len(DbcPars)):\n","\t\t\t\t\t\t\tif set(DbcPars[ind1][0]).difference(set(Dpars[D][ind][D[0].index(Nodeb)])) == set() and set(DbcPars[ind1][1]).difference(set(Dpars[D][ind][D[0].index(Nodec)])) == set() and self.originalScores[Dbc][DbcPars[ind1]] > maxbc:\n","\t\t\t\t\t\t\t\tmaxbc = self.originalScores[Dbc][DbcPars[ind1]]\n","\t\t\t\t\t\tfor ind1 in range(len(DacPars)):\n","\t\t\t\t\t\t\tif set(DacPars[ind1][0]).difference(set(Dpars[D][ind][D[0].index(Nodea)])) == set() and set(DacPars[ind1][1]).difference(set(Dpars[D][ind][D[0].index(Nodec)])) == set() and self.originalScores[Dac][DacPars[ind1]] > maxac:\n","\t\t\t\t\t\t\t\tmaxac = self.originalScores[Dac][DacPars[ind1]]\n","\t\t\t\t\t\tDabcPars = list(self.originalScores[Dabc].keys())\n","\t\t\t\t\t\tDbcaPars = list(self.originalScores[Dbca].keys())\n","\t\t\t\t\t\tDcabPars = list(self.originalScores[Dcab].keys())\n","\t\t\t\t\t\tmaxabc = -float('inf')\n","\t\t\t\t\t\tmaxbca = -float('inf')\n","\t\t\t\t\t\tmaxcab = -float('inf')\n","\t\t\t\t\t\tfor ind1 in range(len(DabcPars)):\n","\t\t\t\t\t\t\tif set(DabcPars[ind1][0]).difference(set(Dpars[D][ind][D[0].index(Nodea)])) == set() and set(DabcPars[ind1][1]).difference(set(Dpars[D][ind][D[0].index(Nodeb)])) == set() and set(DabcPars[ind1][2]).difference(set(Dpars[D][ind][D[0].index(Nodec)])) == set() and self.originalScores[Dabc][DabcPars[ind1]] > maxabc:\n","\t\t\t\t\t\t\t\tmaxabc = self.originalScores[Dabc][DabcPars[ind1]]\n","\t\t\t\t\t\tfor ind1 in range(len(DbcaPars)):\n","\t\t\t\t\t\t\tif set(DbcaPars[ind1][0]).difference(set(Dpars[D][ind][D[0].index(Nodea)])) == set() and set(DbcaPars[ind1][1]).difference(set(Dpars[D][ind][D[0].index(Nodeb)])) == set() and set(DbcaPars[ind1][2]).difference(set(Dpars[D][ind][D[0].index(Nodec)])) == set() and self.originalScores[Dbca][DbcaPars[ind1]] > maxbca:\n","\t\t\t\t\t\t\t\tmaxbca = self.originalScores[Dbca][DbcaPars[ind1]]\n","\t\t\t\t\t\tfor ind1 in range(len(DcabPars)):\n","\t\t\t\t\t\t\tif set(DcabPars[ind1][0]).difference(set(Dpars[D][ind][D[0].index(Nodea)])) == set() and set(DcabPars[ind1][1]).difference(set(Dpars[D][ind][D[0].index(Nodeb)])) == set() and set(DcabPars[ind1][2]).difference(set(Dpars[D][ind][D[0].index(Nodec)])) == set() and self.originalScores[Dcab][DcabPars[ind1]] > maxcab:\n","\t\t\t\t\t\t\t\tmaxcab = self.originalScores[Dcab][DcabPars[ind1]]\n","\t\t\t\t\t\t# vs a,b,c\n","\t\t\t\t\t\tif self.originalScores[D][Dpars[D][ind]] <= maxa+maxb+maxc:\n","\t\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\t\tcontinue\n","\t\t\t\t\t\t# vs a<->b,c\n","\t\t\t\t\t\tif self.originalScores[D][Dpars[D][ind]] <= maxab+maxc:\n","\t\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\t\tcontinue\n","\t\t\t\t\t\t# vs a, b<->c\n","\t\t\t\t\t\tif self.originalScores[D][Dpars[D][ind]] <= maxa+maxbc:\n","\t\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\t\tcontinue\n","\t\t\t\t\t\t# vs b, c<->a\n","\t\t\t\t\t\tif self.originalScores[D][Dpars[D][ind]] <= maxac+maxb:\n","\t\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\t\tcontinue\n","\t\t\t\t\t\t# vs a<->b<->c\n","\t\t\t\t\t\tif self.originalScores[D][Dpars[D][ind]] <= maxabc:\n","\t\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\t\tcontinue\n","\t\t\t\t\t\t# vs b<->c<->a\n","\t\t\t\t\t\tif self.originalScores[D][Dpars[D][ind]] <= maxbca:\n","\t\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\t\tcontinue\n","\t\t\t\t\t\t# vs c<->a<->b\n","\t\t\t\t\t\tif self.originalScores[D][Dpars[D][ind]] <= maxcab:\n","\t\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\t\tcontinue\n","\t\t\t\t\t\t# vs a<->b<->c<->a\n","\t\t\t\t\t\tdelInd = False\n","\t\t\t\t\t\tfor i in range(ind):\n","\t\t\t\t\t\t\tif set(Dpars[D][i][0]).difference(set(Dpars[D][ind][0])) == set() and set(Dpars[D][i][1]).difference(set(Dpars[D][ind][1])) == set() and set(Dpars[D][i][2]).difference(set(Dpars[D][ind][2])) == set() and self.originalScores[D][Dpars[D][ind]] <= self.originalScores[D][Dpars[D][i]]:\n","\t\t\t\t\t\t\t\tDparscopy.remove(Dpars[D][ind])\n","\t\t\t\t\t\t\t\tdelInd = True\n","\t\t\t\t\t\t\t\tbreak\n","\t\t\t\t\t\tif delInd == True:\n","\t\t\t\t\t\t\tcontinue\n","\t\t\t\tsum1 = sum1+len(Dpars[D])\n","\t\t\t\tDpars[D] = Dparscopy.copy()\n","\t\t\t\tsum2 = sum2+len(Dpars[D])\n","\t\t\telse:\n","\t\t\t\tDpars[D] = list(self.originalScores[D].keys())\n","\t\t\t\tsum1 = sum1+len(Dpars[D])\n","\t\t\t\tsum2 = sum2+len(Dpars[D])\n","\t\tprint(str(sum1)+\" vs \"+str(sum2)+\", pruning time: \"+str(time.time()-t0P))\n","\t\tfileName = self.instance+'.log'\n","\t\tf = open(fileName,\"a\")\n","\t\tf.write(str(sum1)+\" vs \"+str(sum2)+\", pruning time: \"+str(time.time()-t0P))\n","\t\tf.close\n","\n","\t\tself.scores = {}\n","\t\tfor D in self.originalScores.keys():\n","\t\t\tfor Dpar in Dpars[D]:\n","\t\t\t\tif D not in self.scores.keys():\n","\t\t\t\t\tself.scores[D] = {}\n","\t\t\t\tself.scores[D][Dpar] = self.originalScores[D][Dpar]\n","\n","\tdef Initialize(self,prune=True,dag=False,printsc=False):\n","\t\tif prune == True:\n","\t\t\tself.Prune_scores()\n","\t\telse:\n","\t\t\tself.scores = self.originalScores\n","\t\tself.V = set()\n","\t\tself.cComps = []\n","\t\tfor D in self.scores.keys():\n","\t\t\tself.cComps.append(D)\n","\t\t\tself.V = self.V.union(set(D[0]))\n","\t\tself.iComps = {}\n","\t\tfor i in self.V:\n","\t\t\tself.iComps[i] = []\n","\t\t\tfor D in self.cComps:\n","\t\t\t\tif i in D[0]:\n","\t\t\t\t\tself.iComps[i].append(self.cComps.index(D))\n","\t\tself.dPars = {}\n","\t\tfor d in range(len(self.cComps)):\n","\t\t\tself.dPars[d] = []\n","\t\t\tfor par in self.scores[self.cComps[d]].keys():\n","\t\t\t\tself.dPars[d].append(par)\n","\t\tself.iPars = {}\n","\t\tfor i in self.V:\n","\t\t\tself.iPars[i] = []\n","\t\t\tfor d in self.iComps[i]:\n","\t\t\t\tfor W in self.dPars[d]:\n","\t\t\t\t\tif W[self.cComps[d][0].index(i)] not in self.iPars[i]:\n","\t\t\t\t\t\tself.iPars[i].append(W[self.cComps[d][0].index(i)])\n","\t\tif printsc == True:\n","\t\t\tfor d in range(len(self.cComps)):\n","\t\t\t\tprint(str(self.cComps[d])+':')\n","\t\t\t\tprint(self.scores[self.cComps[d]])\n","\t\t\t\tprint('\\n')\n","\n","\n","\t\tself.biPars = {}\n","\t\tfor D in self.cComps:\n","\t\t\tfor bi in D[1]:\n","\t\t\t\tif bi not in self.biPars.keys():\n","\t\t\t\t\tself.biPars[bi] = []\n","\t\t\t\tfor W in self.dPars[self.cComps.index(D)]:\n","\t\t\t\t\tbiPar = (W[D[0].index(bi[0])],W[D[0].index(bi[1])])\n","\t\t\t\t\tif biPar not in self.biPars[bi]:\n","\t\t\t\t\t\tself.biPars[bi].append(biPar)\n","\n","\t\tself.m = Model()\n","\t\tself.m.modelSense = GRB.MAXIMIZE\n","\t\tself.m.Params.MIPGAP = 1e-6\n","\t\tself.z = {}\n","\t\tfor d in range(len(self.cComps)):\n","\t\t\tfor dp in range(len(self.dPars[d])):\n","\t\t\t\tself.z[d,dp] = self.m.addVar(vtype=GRB.BINARY,obj=self.scores[self.cComps[d]][self.dPars[d][dp]],name='z'+str(d)+','+str(dp))\n","\t\t\t\tif dag == True:\n","\t\t\t\t\tif len(self.cComps[d][0]) > 1:\n","\t\t\t\t\t\tself.z[d,dp].ub = 0.0\n","\n","\t\tfor i in self.V:\n","\t\t\tself.m.addConstr(quicksum(self.z[d,dp] for d in self.iComps[i] for dp in range(len(self.dPars[d]))) == 1)\n","\n","\t\tself.indInv = []\n","\t\tfor i in self.V:\n","\t\t\tfor j in range(i+1,len(self.V)):\n","\t\t\t\tself.indInv.append((i,j))\n","\n","\t\tself.udE = range(len(self.indInv))\n","\n","\t\tself.bi = {}\n","\t\tfor e in self.udE:\n","\t\t\tself.bi[e] = self.m.addVar(name='bi'+str(e))\n","\t\t\tself.m.addConstr(self.bi[e] == quicksum(self.z[d,dp] for d in range(len(self.cComps)) for dp in range(len(self.dPars[d])) if self.indInv[e] in self.cComps[d][1]))\n","\n","\t\tself.x = {}\n","\t\tfor i in self.V:\n","\t\t\tfor ip in range(len(self.iPars[i])):\n","\t\t\t\tself.x[i,ip] = self.m.addVar(name='x'+str(i)+','+str(ip))\n","\t\t\t\tself.m.addConstr(self.x[i,ip] == quicksum(self.z[d,dp] for d in self.iComps[i] for dp in range(len(self.dPars[d])) if self.dPars[d][dp][self.cComps[d][0].index(i)] == self.iPars[i][ip]))\n","\n","\t\tself.m.update()\n","\n","\tdef biClusterToIneq(self,C,ii,jj):\n","\t\tif jj < ii:\n","\t\t\tcp = jj\n","\t\t\tjj = ii\n","\t\t\tii = cp\n","\t\tifLHS = {(d,dp):False for d in range(len(self.cComps)) for dp in range(len(self.dPars[d]))}\n","\t\tfor d in range(len(self.cComps)):\n","\t\t\tif len(set(self.cComps[d][0])&set([ii,jj]))!=1:\n","\t\t\t\tvs = [v for v in C if v in self.cComps[d][0]]\n","\t\t\t\tif len(vs) > 0:\n","\t\t\t\t\tfor dp in range(len(self.dPars[d])):\n","\t\t\t\t\t\tfor v in vs:\n","\t\t\t\t\t\t\tif set(self.dPars[d][dp][self.cComps[d][0].index(v)])&C.union(set([ii,jj])) == set():\n","\t\t\t\t\t\t\t\tifLHS[d,dp] = True\n","\t\t\t\t\t\t\t\tbreak\n","\t\t\t\tif (ii,jj) in self.cComps[d][1]:\n","\t\t\t\t\tfor dp in range(len(self.dPars[d])):\n","\t\t\t\t\t\tif set(self.dPars[d][dp][self.cComps[d][0].index(ii)])&C.union(set([ii,jj])) == set() and set(self.dPars[d][dp][self.cComps[d][0].index(jj)])&C.union(set([ii,jj])) == set():\n","\t\t\t\t\t\t\tifLHS[d,dp] = True\n","\t\treturn ifLHS\n","\n","\tdef ClusterToIneq(self,C):\n","\t\tifLHS = {(d,dp):False for d in range(len(self.cComps)) for dp in range(len(self.dPars[d]))}\n","\t\tfor d in range(len(self.cComps)):\n","\t\t\tvs = [v for v in C if v in self.cComps[d][0]]\n","\t\t\tif len(vs) > 0:\n","\t\t\t\tfor dp in range(len(self.dPars[d])):\n","\t\t\t\t\t\tfor v in vs:\n","\t\t\t\t\t\t\tif set(self.dPars[d][dp][self.cComps[d][0].index(v)])&set(C) == set():\n","\t\t\t\t\t\t\t\tifLHS[d,dp] = True\n","\t\t\t\t\t\t\t\tbreak\n","\t\treturn ifLHS\n","\n","\tdef Solve_with_cb(self,CG=False):\n","\t\tt0 = time.time()\n","\t\tContinueCondt = True\n","\t\tLPiter = 0\n","\t\tObjvalue = float('inf')\n","\t\tnvar = sum(len(self.dPars[d]) for d in range(len(self.cComps)))\n","\t\tnbi = len(self.udE)\n","\t\tncluster = 0\n","\t\tnbicluster = 0\n","\n","\t\twhile ContinueCondt == True and LPiter < 100:\n","\t\t\tnz_bi = 0\n","\t\t\tnz_z = 0\n","\t\t\tContinueCondt = False\n","\t\t\tLPiter = LPiter+1\n","\t\t\tself.m.update()\n","\t\t\tLPrelax = self.m.relax()\n","\t\t\tLPrelax.setParam('OutputFlag', False)\n","\t\t\tLPrelax.update()\n","\t\t\tLPrelax.optimize()\n","\t\t\tPrevObjvalue = Objvalue\n","\t\t\tObjvalue = LPrelax.ObjVal\n","\n","\n","\t\t\tfor d in range(len(self.cComps)):\n","\t\t\t\tfor dp in range(len(self.dPars[d])):\n","\t\t\t\t\tif LPrelax.getVarByName('z'+str(d)+','+str(dp)).x > 0:\n","\t\t\t\t\t\tnz_z = nz_z+1\n","\t\t\tfor e in self.udE:\n","\t\t\t\tif LPrelax.getVarByName('bi'+str(e)).x > 0:\n","\t\t\t\t\tnz_bi = nz_bi+1\n","\n","\t\t\tprint('LP iter '+str(LPiter)+', ObjVal: '+str(LPrelax.ObjVal)+', time: '+str(time.time()-t0)+', frac. of nonzero variables: '+\\\n","\t\t\t\tstr(nz_z)+'/'+str(nvar)+', frac. of nonzero bidirected edges: '+str(nz_bi)+'/'+str(nbi)+', # cluster: '+str(ncluster)+', # bi-cluster: '+str(nbicluster))\n","\n","\t\t\tncluster = 0\n","\t\t\tnbicluster = 0\n","\t\t\tbi_value = {}\n","\t\t\tx_value = {}\n","\t\t\tz_value = {}\n","\t\t\tfor e in self.udE:\n","\t\t\t\tbi_value[e] =  LPrelax.getVarByName('bi'+str(e)).x\n","\t\t\tfor i in self.V:\n","\t\t\t\tfor ip in range(len(self.iPars[i])):\n","\t\t\t\t\tx_value[i,ip] = LPrelax.getVarByName('x'+str(i)+','+str(ip)).x\n","\t\t\tfor d in range(len(self.cComps)):\n","\t\t\t\tfor dp in range(len(self.dPars[d])):\n","\t\t\t\t\tz_value[d,dp] = LPrelax.getVarByName('z'+str(d)+','+str(dp)).x\n","\n","\t\t\twt = {}\n","\t\t\tfor i in self.V:\n","\t\t\t\tfor ip in range(len(self.iPars[i])):\n","\t\t\t\t\tif x_value[i,ip] > 1e-6:\n","\t\t\t\t\t\tfor par in self.iPars[i][ip]:\n","\t\t\t\t\t\t\tif (par,i) not in wt.keys():\n","\t\t\t\t\t\t\t\twt[(par,i)] = x_value[i,ip]\n","\t\t\t\t\t\t\telse:\n","\t\t\t\t\t\t\t\twt[(par,i)] = wt[(par,i)]+x_value[i,ip]\n","\t\t\ttelist = []\n","\t\t\tfor (i,j) in wt.keys():\n","\t\t\t\tif wt[(i,j)] >= 1-1e-6:\n","\t\t\t\t\ttelist.append(i)\n","\t\t\t\t\ttelist.append(j)\n","\t\t\tallcyc = []\n","\n","\t\t\tallcyc = dircyc(len(self.V),int(len(telist)/2),telist)\n","\t\t\tfor Cluster in allcyc:\n","\t\t\t\tifLHS = self.ClusterToIneq(Cluster)\n","\t\t\t\tself.m.addConstr(quicksum(self.z[d,dp] for d in range(len(self.cComps)) for dp in range(len(self.dPars[d])) if ifLHS[d,dp]==True) >= 1 )\n","\n","\t\t\tif len(allcyc) > 0:\n","\t\t\t\tncluster = len(allcyc)\n","\t\t\t\tContinueCondt = True\n","\t\t\telse:\n","\t\t\t\t# Contracting heursitics for separating cluster ineqs and bi-cluster ineqs\n","\t\t\t\tnnode = len(self.V)\n","\t\t\t\tgcnodes = []\n","\t\t\t\tgcweight = []\n","\t\t\t\tgcparents = []\n","\t\t\t\tfor d in range(len(self.cComps)):\n","\t\t\t\t\tfor dp in range(len(self.dPars[d])):\n","\t\t\t\t\t\tif z_value[d,dp] > 0:\n","\t\t\t\t\t\t\tgcnodes.append(list(self.cComps[d][0]))\n","\t\t\t\t\t\t\tgcweight.append(z_value[d,dp])\n","\t\t\t\t\t\t\tgcparents.append(list(list(pars) for pars in self.dPars[d][dp]))\n","\t\t\t\tfor i in range(len(gcparents)):\n","\t\t\t\t\tfor j in range(len(gcparents[i])):\n","\t\t\t\t\t\tif len(gcparents[i][j]) == 0:\n","\t\t\t\t\t\t\tgcparents[i][j].append(nnode)\n","\t\t\t\tdircycs = contract_heur(nnode+1, gcnodes, gcparents, gcweight,1.0)\n","\t\t\t\tfor Cluster in dircycs:\n","\t\t\t\t\tifLHS = self.ClusterToIneq(Cluster)\n","\t\t\t\t\tself.m.addConstr(quicksum(self.z[d,dp] for d in range(len(self.cComps)) for dp in range(len(self.dPars[d])) if ifLHS[d,dp]==True) >= 1 )\n","\t\t\t\tncluster = ncluster+len(dircycs)\n","\n","\t\t\t\taldircycs = contract_heur_bdir(nnode+1, gcnodes, gcparents, gcweight)\n","\t\t\t\tfor Cluster in aldircycs:\n","\t\t\t\t\tii = Cluster[0]\n","\t\t\t\t\tjj = Cluster[1]\n","\t\t\t\t\te = self.indInv.index((ii,jj))\n","\t\t\t\t\tC = set(Cluster[2:])\n","\t\t\t\t\tifLHS = self.biClusterToIneq(C,ii,jj)\n","\t\t\t\t\tself.m.addConstr(quicksum(self.z[d,dp] for d in range(len(self.cComps)) for dp in range(len(self.dPars[d])) if ifLHS[d,dp]==True) >= self.bi[e])\n","\t\t\t\tnbicluster = nbicluster+len(aldircycs)\n","\n","\t\t\t\tif ncluster+nbicluster >0 and Objvalue > PrevObjvalue:\n","\t\t\t\t\tContinueCondt = True\n","\n","\t\ttRoot = time.time()-t0\n","\n","\t\tdef cb(model,where):\n","\t\t\tif where == GRB.Callback.MIPSOL:\n","\t\t\t\tNoCluster = False\n","\t\t\t\tbi_value = {}\n","\t\t\t\tx_value = {}\n","\t\t\t\tfor e in self.udE:\n","\t\t\t\t\tbi_value[e] =  model.cbGetSolution(self.bi[e])\n","\t\t\t\tfor i in self.V:\n","\t\t\t\t\tfor ip in range(len(self.iPars[i])):\n","\t\t\t\t\t\tx_value[i,ip] = model.cbGetSolution(self.x[i,ip])\n","\n","\t\t\t\tActiveEdgeList = []\n","\n","\t\t\t\tfor i in self.V:\n","\t\t\t\t\tfor ip in range(len(self.iPars[i])):\n","\t\t\t\t\t\tif x_value[i,ip] > 0.5:\n","\t\t\t\t\t\t\tfor par in self.iPars[i][ip]:\n","\t\t\t\t\t\t\t\tActiveEdgeList.append(par)\n","\t\t\t\t\t\t\t\tActiveEdgeList.append(i)\n","\t\t\t\tne = int(len(ActiveEdgeList)/2)\n","\n","\t\t\t\t# Detecting directed cycles and adding cluster inequalities\n","\t\t\t\tcycList = dircyc(len(self.V),ne,ActiveEdgeList)\n","\t\t\t\tfor Cluster in cycList:\n","\t\t\t\t\tifLHS = self.ClusterToIneq(Cluster)\n","\t\t\t\t\tmodel.cbLazy(quicksum(self.z[d,dp] for d in range(len(self.cComps)) for dp in range(len(self.dPars[d])) if ifLHS[d,dp]==True) >= 1 )\n","\n","\t\t\t\t# Detecting almost directed cycles and adding bi-cluster inequalities\n","\t\t\t\tfor e in self.udE:\n","\t\t\t\t\tif bi_value[e] > 0.5:\n","\t\t\t\t\t\tii = self.indInv[e][0]\n","\t\t\t\t\t\tjj = self.indInv[e][1]\n","\t\t\t\t\t\tadcycList = almostdircyc(len(self.V),ne,ActiveEdgeList,ii,jj)+almostdircyc(len(self.V),ne,ActiveEdgeList,jj,ii)\n","\t\t\t\t\t\tfor Cluster in adcycList:\n","\t\t\t\t\t\t\tC = set(Cluster[1:-1])\n","\t\t\t\t\t\t\tifLHS = self.biClusterToIneq(C,ii,jj)\n","\t\t\t\t\t\t\tmodel.cbLazy(quicksum(self.z[d,dp] for d in range(len(self.cComps)) for dp in range(len(self.dPars[d])) if ifLHS[d,dp]==True) >= self.bi[e])\n","\n","\n","\n","\t\tself.m.Params.Heuristics = 0.0\n","\t\tself.m.Params.lazyConstraints = 1\n","\t\tself.m.Params.LogFile = self.instance+'.log'\n","\t\tself.m.update()\n","\t\tself.m.optimize(cb)\n","\t\tfileName = self.instance+'.log'\n","\t\twrtStr = 'Time at root: '+str(tRoot)+'\\n'\n","\t\twrtStr = 'Total solution time: '+str(time.time()-t0)+'\\n'\n","\t\twith open(\"pruned_edges.tsv\", 'w') as f:\n","\t\t\tf.write(\"source\\ttarget\\tweight\\n\")\n","\t\t\tprint('Bidirected edges: ')\n","\t\t\twrtStr = wrtStr+'Bidirected edges: \\n'\n","\t\t\tfor e in self.udE:\n","\t\t\t\tif self.bi[e].x > 0.5:\n","\t\t\t\t\tprint(self.indInv[e])\n","\t\t\t\t\tfor bi_a,bi_b in list(itertools.combinations(range(len(self.indInv[e])), 2)):\n","\t\t\t\t\t\t\tprint(self.indInv[e],bi_a,bi_b)\n","\t\t\t\t\t\t\tf.write(f\"{str(self.indInv[e][bi_a])}\\t{str(self.indInv[e][bi_b])}\\t{'1'}\\n\")\n","\t\t\t\t\t\t\tf.write(f\"{str(self.indInv[e][bi_b])}\\t{str(self.indInv[e][bi_a])}\\t{'1'}\\n\")\n","\t\t\t\t\twrtStr = wrtStr+str(self.indInv[e])+'\\n'\n","\t\t\tprint('Parent sets: ')\n","\t\t\twrtStr = wrtStr+'Parent sets: \\n'\n","\t\t\tfor i in self.V:\n","\t\t\t\tfor ip in range(len(self.iPars[i])):\n","\t\t\t\t\tif self.x[i,ip].x > 0.5:\n","\t\t\t\t\t\tprint(str(i)+': '+str(self.iPars[i][ip]))\n","\t\t\t\t\t\tfor ip_ip in range(len(self.iPars[i][ip])):\n","\t\t\t\t\t\t\tf.write(f\"{str(self.iPars[i][ip][ip_ip])}\\t{str(i)}\\t{'1'}\\n\")\n","\t\t\t\t\t\twrtStr = wrtStr+str(i)+': '+str(self.iPars[i][ip])+'\\n'\n","\t\t\tprint('z solution: ')\n","\t\t\twrtStr = wrtStr+'z solution: '\n","\t\t\tfor d in range(len(self.cComps)):\n","\t\t\t\tfor dp in range(len(self.dPars[d])):\n","\t\t\t\t\tif self.z[d,dp].x > 0.5:\n","\t\t\t\t\t\tprint(str(self.cComps[d])+': '+str(self.dPars[d][dp])+', score: '+str(self.scores[self.cComps[d]][self.dPars[d][dp]]))\n","\t\t\t\t\t\t'''\n","\t\t\t\t\t\tfor ip_cp in range(len(self.cComps[d])):\n","\t\t\t\t\t\t\tfor ip_ip in range(len(self.dPars[d][dp])):\n","\t\t\t\t\t\t\t\tf.write(f\"{str(self.dPars[d][dp][ip_ip])}\\t{str(self.cComps[d][ip_cp])}\\t{str(self.scores[self.cComps[d]][self.dPars[d][dp]])}\\n\")\n","\t\t\t\t\t\t'''\n","\t\t\t\t\t\twrtStr = wrtStr+str(self.cComps[d])+': '+str(self.dPars[d][dp])+', score: '+str(self.scores[self.cComps[d]][self.dPars[d][dp]])+'\\n'\n","\t\t\tf = open(fileName,\"a\")\n","\t\t\tf.write(wrtStr)\n","\t\t\tf.close\n","\n","'''\n","Bidirected edges:\n","(15, 16)\n","Parent sets:\n","0: ()\n","1: ()\n","2: (6, 11, 14)\n","\n","z solution:\n","((0,), ()): ((),), score: -14068.377125836885\n","((1,), ()): ((),), score: -14263.663318256287\n","((2,), ()): ((6, 11, 14),), score: -14174.797387361239\n","((15, 16), ((15, 16),)): ((3,), (11,)), score: -29266.559604776034\n","'''\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":107},"id":"lmUgHNtEWy3o","executionInfo":{"status":"ok","timestamp":1748516566591,"user_tz":-60,"elapsed":917,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"}},"outputId":"f8c430dd-674a-4ef3-9a76-0b5dec8d05ec"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nBidirected edges:\\n(15, 16)\\nParent sets:\\n0: ()\\n1: ()\\n2: (6, 11, 14)\\n\\nz solution:\\n((0,), ()): ((),), score: -14068.377125836885\\n((1,), ()): ((),), score: -14263.663318256287\\n((2,), ()): ((6, 11, 14),), score: -14174.797387361239\\n((15, 16), ((15, 16),)): ((3,), (11,)), score: -29266.559604776034\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["## dircycle2&heuristic2"],"metadata":{"id":"CH4DRbJbaxkW"}},{"cell_type":"code","source":["import array as arr\n","\n","def dircyc (n , ne, elist):\n","    ideg = [0 for i in range(n)]\n","    odeg = [0 for i in range(n)] #outdegree\n","    oadjn = [0 for i in range(n*n)] #out adjacency list\n","    mark = [0 for i in range(n)] #processed nodes\n","    active = arr.array('i', []) #same as stack\n","    nchild = arr.array('i', []) #number of processed children\n","    isactive = [0 for i in range(n)] #idicates if node is on the stack\n","\n","    nproc = 0\n","    allcyc = []\n","\n","    for i in range(ne):\n","        n1 = elist[2*i]\n","        n2 = elist[2*i+1]\n","        oadjn[n1*n + odeg[n1]] = n2\n","        odeg[n1] += 1\n","        ideg[n2] += 1\n","\n","    while nproc < n:\n","        # Find an unmarked node to start from, preferably zero indeg node*/\n","        start = -1\n","        pstart = -1\n","        for i in range(n):\n","            if mark[i] == 0 and pstart == -1:\n","                pstart = i\n","                if ideg[i] == 0:\n","                    start = i\n","                    break\n","        if start == -1 and pstart >= 0:\n","            start = pstart\n","\n","        #print('start =', start, ', pstart=',  pstart)\n","        if start == -1:\n","            break\n","\n","        active.append(start)\n","        nchild.append(0)\n","        mark[start] = 1\n","        isactive[start] = 1\n","\n","        while len(active) > 0:\n","            cnode = active[len(active)-1]\n","            nchildproc = nchild[len(nchild)-1]\n","            #print('cnode=',cnode,',nchildproc=',nchildproc, 'act=',len(active), len(nchild))\n","\n","            if nchildproc == odeg[cnode]:\n","                nproc = nproc + 1\n","                isactive[cnode] = 0\n","                active.pop()\n","                nchild.pop()\n","                if len(nchild) > 0:\n","                    nchild[len(nchild)-1] = nchild[len(nchild)-1] + 1\n","\n","            else:\n","                n1 = oadjn[cnode*n + nchildproc]\n","                #print(n1,'mark=',mark[n1])\n","                if mark[n1] == 0:\n","                    active.append(n1)\n","                    nchild.append(0)\n","                    mark[n1] = 1\n","                    isactive[n1] = 1\n","                else:\n","                    #if n1 in active:\n","                    if isactive[n1] != 0:\n","                        # Found previously marked node trace back to cycle\n","                        pos = len(active)-1\n","                        cur = active[pos]\n","                        cyc = [cnode]\n","\n","                        while cur != n1 and pos > 0:\n","                            pos = pos -1\n","                            cur = active[pos]\n","                            cyc.append(cur)\n","                        if (cur == n1):\n","                            #print('cycle=',cyc)\n","                            allcyc.append(cyc[::-1])\n","                        else:\n","                            print('error in computing cycle')\n","                            exit(-1)\n","\n","                    # at this point we have a marked child\n","                    nchild[len(nchild)-1] = nchild[len(nchild)-1] + 1\n","\n","    return allcyc\n","\n","def almostdircyc (n , ne, elist, bnode, enode):\n","    ideg = [0 for i in range(n)]\n","    odeg = [0 for i in range(n)] #outdegree\n","    oadjn = [0 for i in range(n*n)] #out adjacency list\n","    mark = [0 for i in range(n)] #processed nodes\n","    active = arr.array('i', []) #same as stack\n","    nchild = arr.array('i', []) #number of processed children\n","    isactive = [0 for i in range(n)] #idicates if node is on the stack\n","\n","    nproc = 0\n","    allcyc = []\n","\n","    for i in range(ne):\n","        n1 = elist[2*i]\n","        n2 = elist[2*i+1]\n","        oadjn[n1*n + odeg[n1]] = n2\n","        odeg[n1] += 1\n","        ideg[n2] += 1\n","\n","\n","    mark[bnode] = 1\n","    active.append(enode)\n","    nchild.append(0)\n","    mark[enode] = 1\n","    isactive[enode] = 1\n","\n","    while len(active) > 0:\n","        cnode = active[len(active)-1]\n","        nchildproc = nchild[len(nchild)-1]\n","        #print('cnode=',cnode,',nchildproc=',nchildproc, 'act=',len(active), len(nchild))\n","\n","        if nchildproc == odeg[cnode]:\n","            nproc = nproc + 1\n","            isactive[cnode] = 0\n","            active.pop()\n","            nchild.pop()\n","            if len(nchild) > 0:\n","                nchild[len(nchild)-1] = nchild[len(nchild)-1] + 1\n","\n","        else:\n","            n1 = oadjn[cnode*n + nchildproc]\n","            #print(n1,'mark=',mark[n1])\n","            if mark[n1] == 0:\n","                active.append(n1)\n","                nchild.append(0)\n","                mark[n1] = 1\n","                isactive[n1] = 1\n","            else:\n","                if  n1 == bnode:\n","                    # Found previously marked node trace back to cycle\n","                    pos = len(active)-1\n","                    cur = active[pos]\n","                    cyc = [cnode]\n","\n","                    while cur != enode and pos > 0:\n","                        pos = pos -1\n","                        cur = active[pos]\n","                        cyc.append(cur)\n","                    if (cur == enode):\n","                        #print('cycle=',cyc)\n","                        cyc.reverse()\n","                        cyc.append(bnode)\n","                        allcyc.append(cyc)\n","                    else:\n","                        print('error in computing cycle')\n","                        exit(-1)\n","\n","                # at this point we have a marked child\n","                nchild[len(nchild)-1] = nchild[len(nchild)-1] + 1\n","\n","    return allcyc\n","\n","'''\n","#n = 3\n","#ne = 3\n","#elist = arr.array('i', [0,1, 1, 2, 2, 0])\n","n = 6\n","ne = 7\n","elist = arr.array('i', [0,1, 1, 2, 2,0, 3,4,4,5,5,3, 3,1])\n","allc = almostdircyc(n, ne, elist, 2, 5)\n","print(allc)\n","'''\n","\n","\n","import array as arr\n","import re\n","import sys\n","import random\n","#import pdb; pdb.set_trace()\n","\n","# TODO: deal with cases 1) when district size > 2 2) nodes in the district being parents of other nodes\n","\n","def dircyc (n , ne, elist):\n","    ideg = [0 for i in range(n)]\n","    odeg = [0 for i in range(n)] #outdegree\n","    oadjn = [0 for i in range(n*n)] #out adjacency list\n","    mark = [0 for i in range(n)] #processed nodes\n","    active = arr.array('i', []) #same as stack\n","    nchild = arr.array('i', []) #number of processed children\n","    isactive = [0 for i in range(n)] #idicates if node is on the stack\n","\n","    nproc = 0\n","    allcyc = []\n","\n","    for i in range(ne):\n","        n1 = elist[2*i]\n","        n2 = elist[2*i+1]\n","        oadjn[n1*n + odeg[n1]] = n2\n","        odeg[n1] = odeg[n1] + 1\n","        ideg[n2] = ideg[n2] + 1\n","\n","    while nproc < n:\n","        # Find an unmarked node to start from, preferably zero indeg node*/\n","        start = -1\n","        pstart = -1\n","        for i in range(n):\n","            if mark[i] == 0 and pstart == -1:\n","                pstart = i\n","                if ideg[i] == 0:\n","                    start = i\n","                    break\n","        if start == -1 and pstart >= 0:\n","            start = pstart\n","\n","        #print 'start =', start, ', pstart=',  pstart\n","        if start == -1:\n","            break\n","\n","        active.append(start)\n","        nchild.append(0)\n","        mark[start] = 1\n","        isactive[start] = 1\n","\n","        while len(active) > 0:\n","            cnode = active[len(active)-1]\n","            nchildproc = nchild[len(nchild)-1]\n","            #print 'cnode=',cnode,',nchildproc=',nchildproc, 'act=',len(active), len(nchild)\n","\n","            if nchildproc == odeg[cnode]:\n","                nproc = nproc + 1\n","                isactive[cnode] = 0\n","                active.pop()\n","                nchild.pop()\n","                if len(nchild) > 0:\n","                    nchild[len(nchild)-1] = nchild[len(nchild)-1] + 1\n","\n","            else:\n","                n1 = oadjn[cnode*n + nchildproc]\n","                #print n1,'mark=',mark[n1]\n","                if mark[n1] == 0:\n","                    active.append(n1)\n","                    nchild.append(0)\n","                    mark[n1] = 1\n","                    isactive[n1] = 1\n","                else:\n","                    #if n1 in active:\n","                    if isactive[n1] != 0:\n","                        # Found previously marked node trace back to cycle\n","                        pos = len(active)-1\n","                        cur = active[pos]\n","                        cyc = [cnode]\n","\n","                        while cur != n1 and pos > 0:\n","                            pos = pos -1\n","                            cur = active[pos]\n","                            cyc.append(cur)\n","                        if (cur == n1):\n","                            # print 'cycle=',cyc\n","                            allcyc.append(cyc[::-1])\n","                        else:\n","                            print('error in computing cycle')\n","                            exit(-1)\n","\n","                    # at this point we have a marked child\n","                    nchild[len(nchild)-1] = nchild[len(nchild)-1] + 1\n","\n","    return allcyc\n","\n","def almostdircyc (n , ne, elist, bnode, enode):\n","    ideg = [0 for i in range(n)]\n","    odeg = [0 for i in range(n)] #outdegree\n","    oadjn = [0 for i in range(n*n)] #out adjacency list\n","    mark = [0 for i in range(n)] #processed nodes\n","    active = arr.array('i', []) #same as stack\n","    nchild = arr.array('i', []) #number of processed children\n","    isactive = [0 for i in range(n)] #idicates if node is on the stack\n","\n","    nproc = 0\n","    allcyc = []\n","\n","    for i in range(ne):\n","        n1 = elist[2*i]\n","        n2 = elist[2*i+1]\n","        oadjn[n1*n + odeg[n1]] = n2\n","        odeg[n1] = odeg[n1] + 1\n","        ideg[n2] = ideg[n2] + 1\n","\n","\n","    mark[bnode] = 1\n","    active.append(enode)\n","    nchild.append(0)\n","    mark[enode] = 1\n","    isactive[enode] = 1\n","\n","    while len(active) > 0:\n","        cnode = active[len(active)-1]\n","        nchildproc = nchild[len(nchild)-1]\n","        #print 'cnode=',cnode,',nchildproc=',nchildproc, 'act=',len(active), len(nchild)\n","\n","        if nchildproc == odeg[cnode]:\n","            nproc = nproc + 1\n","            isactive[cnode] = 0\n","            active.pop()\n","            nchild.pop()\n","            if len(nchild) > 0:\n","                nchild[len(nchild)-1] = nchild[len(nchild)-1] + 1\n","\n","        else:\n","            n1 = oadjn[cnode*n + nchildproc]\n","            #print n1,'mark=',mark[n1]\n","            if mark[n1] == 0:\n","                active.append(n1)\n","                nchild.append(0)\n","                mark[n1] = 1\n","                isactive[n1] = 1\n","            else:\n","                if  n1 == bnode:\n","                    # Found previously marked node trace back to cycle\n","                    pos = len(active)-1\n","                    cur = active[pos]\n","                    cyc = [cnode]\n","\n","                    while cur != enode and pos > 0:\n","                        pos = pos -1\n","                        cur = active[pos]\n","                        cyc.append(cur)\n","                    if (cur == enode):\n","                        #print 'cycle=',cyc\n","                        cyc.reverse()\n","                        cyc.append(bnode)\n","                        allcyc.append(cyc)\n","                    else:\n","                        print('error in computing cycle')\n","                        exit(-1)\n","\n","                # at this point we have a marked child\n","                nchild[len(nchild)-1] = nchild[len(nchild)-1] + 1\n","\n","    return allcyc\n","\n","def parse(filename, n, cnodes, cparents, cweight):\n","    valline = re.compile(':')\n","    val = re.compile(': ([0-9.]+)')\n","    parent = re.compile('\\(\\(([\\d+, ]*)\\)')\n","    #parent = re.compile('\\(\\((\\d+[, \\d+]*)\\)')\n","    parent2 = re.compile('\\(\\(([\\d+, ]*)\\), \\(([\\d+, ]*)\\)')\n","    #parent2 = re.compile('\\(\\((\\d+[, \\d+]*)\\), \\(([\\d+, ]*)\\)')\n","    file = open(filename, \"r\")\n","    a = file.readlines()\n","\n","    for l in a:\n","        if valline.search(l) == None:\n","            m = parent.match(l).group(1)\n","            ccomp = [int(num) for num in m.strip(',').split(',')]\n","        if valline.search(l) != None:\n","            #print curpar\n","            ll = l.split(': ')\n","            pset = [n]\n","            pset2= [n]\n","            if parent.match(ll[0]) != None:\n","                mm = parent.match(ll[0]).group(1)\n","                if len(mm) != 0:\n","                    pset = [int(num) for num in mm.strip(',').split(',')]\n","                if len(ccomp) > 1:\n","                    mm2 = parent2.match(ll[0]).group(2)\n","                    #print mm2, len(mm2)\n","                    if len(mm2) != 0:\n","                        pset2 = [int(num) for num in mm2.strip(',').split(',')]\n","                        if len(pset2) == 0:\n","                            pset2 = [n]\n","            cweight.append(float(ll[1].strip()))\n","            cnodes.append(ccomp[:])\n","            if len(ccomp) > 1:\n","                cparents.append([pset, pset2])\n","            else:\n","                cparents.append([pset])\n","\n","    #print cnodes\n","    #print cparents\n","    #print cweight\n","    #return cnodes, cparents, cweight\n","\n","def find_edge(n, wt, elist):\n","    pos = 0\n","    e = len(wt)-1\n","    if e < 0:\n","        return e\n","\n","    sum = 0.0\n","    for i in range(len(wt)):\n","        sum = sum + wt[i]\n","\n","    randval = (sum-1e-6)*random.random()\n","    #print \"r =\", randval, sum, e\n","\n","    sum = 0.0\n","    for i in range(len(wt)):\n","        sum = sum + wt[i]\n","        if sum >= randval:\n","            e = i\n","            break\n","\n","    te = e\n","    while elist[2*te] == n-1 or elist[2*te+1] == n-1:\n","        te = te - 1\n","        if te < 0:\n","            break\n","    if te < 0:\n","        te = e\n","        while elist[2*te] == n-1 or elist[2*te+1] == n-1:\n","            te = te + 1\n","            if te >= len(wt):\n","                break\n","    return te\n","\n","def create_undir_edges_from_par(cnodes, cparents, cweight, elist, bdir, wt, inwt):\n","    edgemap = {}\n","    for i in range(len(inwt)):\n","        inwt[i] = 0.0\n","\n","    for i in range(len(cnodes)):\n","        if cweight[i] <= 0.001:\n","            continue\n","\n","        cset = cnodes[i]\n","        parent = cparents[i]\n","\n","        if len(cset) > 1:\n","            for j in cset:\n","                bdir.append(j)\n","\n","        for j in range(len(cset)):\n","            node = cset[j]\n","            par = parent[j]\n","            if node in par:\n","                print('mayday', cweight[i], i, cset, par)\n","                return []\n","                exit(-1)\n","            inwt[node] = inwt[node] + cweight[i]\n","\n","            for k in par:\n","                n1 = k\n","                n2 = node\n","\n","                if k > node:\n","                    n1 = node\n","                    n2 = k\n","\n","                nodepair = n1*1000 + n2\n","                if len(edgemap) == 0 or nodepair not in edgemap:\n","                    edgemap[nodepair] = cweight[i]\n","                else:\n","                    edgemap[nodepair] = edgemap[nodepair] + cweight[i]\n","\n","    #print len(edgemap), edgemap\n","    for i in edgemap:\n","        wt.append(edgemap[i])\n","        n1 = int(i / 1000)\n","        n2 = int(i % 1000)\n","        #print n1, n2\n","        elist.append(n1)\n","        elist.append(n2)\n","\n","    #exit(-1)\n","    #for i in range(len(wt)):\n","    #    n1 = elist[2*i]\n","    #    n2 = elist[2*i+1]\n","    #    print n1, n2, wt[i]\n","\n","def create_edges_from_par(cnodes, cparents, cweight, elist, bdir, bdirwt, wt, inwt):\n","    edgemap = {}\n","    bdirmap = {}\n","\n","    for i in range(len(inwt)):\n","        inwt[i] = 0.0\n","\n","    for i in range(len(cnodes)):\n","        if cweight[i] <= 0.001:\n","            continue\n","\n","        cset = cnodes[i]\n","        parent = cparents[i]\n","\n","        if len(cset) > 1:\n","            n1 = cset[0]\n","            n2 = cset[1]\n","            if n1 > n2:\n","                temp = n2\n","                n2 = n1\n","                n1 = temp\n","\n","            nodepair = n1*1000 + n2\n","            if nodepair not in bdirmap:\n","                bdirmap[nodepair] = cweight[i]\n","            else:\n","                bdirmap[nodepair] = bdirmap[nodepair] + cweight[i]\n","\n","        for j in range(len(cset)):\n","            node = cset[j]\n","            par = parent[j]\n","            if node in par:\n","                print('mayday', cweight[i], i, cset, par)\n","                return []\n","                exit(-1)\n","            inwt[node] = inwt[node] + cweight[i]\n","\n","            for k in par:\n","                #elist.append(k)\n","                #elist.append(node)\n","                #wt.append(cweight[i])\n","\n","                nodepair = k*1000 + node\n","                if nodepair not in edgemap:\n","                    edgemap[nodepair] = cweight[i]\n","                else:\n","                    edgemap[nodepair] = edgemap[nodepair] + cweight[i]\n","\n","    for i in bdirmap:\n","        bdirwt.append(bdirmap[i])\n","        n1 = int(i / 1000)\n","        n2 = int(i % 1000)\n","        #print n1, n2\n","        bdir.append(n1)\n","        bdir.append(n2)\n","\n","    for i in edgemap:\n","        wt.append(edgemap[i])\n","        n1 = int(i / 1000)\n","        n2 = int(i % 1000)\n","        #print n1, n2\n","        elist.append(n1)\n","        elist.append(n2)\n","\n","    #print len(elist), elist\n","    #exit(-1)\n","    #for i in range(len(wt)):\n","    #    n1 = elist[2*i]\n","    #    n2 = elist[2*i+1]\n","    #    print n1, n2, wt[i]\n","\n","def contract_edge (e, wt, elist, nodelist, cnodes, cparents, cweight, containsbdir):\n","    node1 = elist[2*e]\n","    node2 = elist[2*e+1]\n","    #print node1, node2\n","\n","    if node1 == node2:\n","        print('mayday2')\n","        exit(-1)\n","    #print node1, node2, len(cnodes), len(cparents), len(cweight)\n","    #print ' '\n","    #print 'cnodes = ', cnodes\n","    #print 'cparents = ', cparents\n","    #print cweight\n","    #print 'elist =', elist\n","\n","    for i in nodelist[node1]:\n","        nodelist[node2].append(i)\n","    nodelist[node1] = []\n","    if containsbdir[node1] == 1:\n","        containsbdir[node2] = 1\n","\n","    for i in range(len(cnodes)):\n","        cset = cnodes[i]\n","        parent = cparents[i]\n","\n","#        if len(cset) > 1:\n","#            #assume for now that cset can have only two nodes\n","#            if node1 in cset and node2 in cset:\n","#                cnodes[i] = [node2]\n","#                cparents[i] = list(set(parent[0]).union(parent[1]))\n","#                containsbdir[node2] = 1\n","#                if node1 in cparents[i] or node2 in cparents[i]:\n","#                    cweight[i] = 0.0\n","#                continue\n","#            else:\n","#                if node2 == cset[0] and node1 in parent[0]:\n","#                    cnodes[i] = [cset[1]]\n","#                    cparents[i] = [parent[1]]\n","#                    if node1 in cparents[i]:\n","#                        ix = cparents[i].index(node1)\n","#                        cparents[i][ix] = node2\n","#                    continue\n","#                else:\n","#                    if node2 == cset[1] and node1 in parent[1]:\n","#                        cnodes[i] = [cset[0]]\n","#                        cparents[i] = [parent[0]]\n","#                        if node1 in cparents[i]:\n","#                            ix = cparents[i].index(node1)\n","#                            cparents[i][ix] = node2\n","#                        continue\n","\n","        deln = [0 for j in range(len(cset))]\n","        ndel = 0\n","        for j in range(len(cset)):\n","\n","            node = cset[j]\n","            par = parent[j]\n","            if node == node2 and node1 in par:\n","                deln[j] = 1\n","                ndel = ndel + 1\n","                #cweight[i] = 0.0\n","                #print('*',cset, par, cweight[i], i)\n","            else:\n","               if node == node1:\n","                   if node2 in par:\n","                       deln[j] = 1\n","                       #cweight[i] = 0.0\n","                       #print('+',cset, par)\n","                   else:\n","                       #print('bb',cset, par)\n","                       cset[j] = node2\n","                       #print('aa',cset, par)\n","               else:\n","                   if node1 in par:\n","                       ix = par.index(node1)\n","                       if node2 not in par:\n","                           #print('b',cset, par, cweight[i], i)\n","                           par[ix] = node2\n","                           #print('a',cset, par, cweight[i], i)\n","                       else:\n","                           #print('br',cset, par)\n","                           par.remove(node1)\n","                           #print('br',cset, par)\n","\n","\n","        if ndel > 0:\n","            if ndel == len(cset):\n","                cweight[i] = 0.0\n","            else:\n","                newcset = []\n","                newpar = []\n","                for j in range(len(cset)):\n","                    if deln[j] == 0:\n","                        newcset.append(cset[j])\n","                        newpar.append(parent[j])\n","                cnodes[i] = newcset\n","                cparents[i] = newpar\n","                del deln\n","        #end for j\n","    #end for i\n","\n","def contract_bdir_edge (node1, node2, wt, elist, nodelist, cnodes, cparents, cweight, containsbdir):\n","    if node1 == node2:\n","        print('mayday2')\n","        exit(-1)\n","\n","    #print node1, node2, len(cnodes), len(cparents), len(cweight)\n","    #print ' '\n","    #print 'cnodes = ', cnodes\n","    #print 'cparents = ', cparents\n","    #print cweight\n","    #print 'elist =', elist\n","\n","    for i in nodelist[node1]:\n","        nodelist[node2].append(i)\n","    nodelist[node1] = []\n","    containsbdir[node1] = 0\n","    containsbdir[node2] = 1\n","\n","    for i in range(len(cnodes)):\n","        cset = cnodes[i]\n","        parent = cparents[i]\n","\n","        if len(cset) == 1:\n","            if node1 in cset or node2 in cset:\n","                cweight[i] = 0.0\n","                continue\n","        if len(cset) > 1:\n","            if node1 in cset and node2 not in cset:\n","                cweight[i] = 0.0\n","                continue\n","            if node2 in cset and node1 not in cset:\n","                cweight[i] = 0.0\n","                continue\n","            if node1 in cset and node2 in cset:\n","                cnodes[i] = [node2]\n","                cparents[i] = [list(set(parent[0]).union(parent[1]))]\n","                continue\n","\n","    for i in range(len(cnodes)):\n","        cset = cnodes[i]\n","        parent = cparents[i]\n","\n","        if node1 in cset or node2 in cset:\n","            continue\n","        for j in range(len(cset)):\n","            node = cset[j]\n","            par = parent[j]\n","            if node1 in par:\n","                ix = par.index(node1)\n","                if node2 not in par:\n","                    #print('b',cset, par, cweight[i], i)\n","                    par[ix] = node2\n","                    #print('a',cset, par, cweight[i], i)\n","                else:\n","                    #print('br',cset, par)\n","                    par.remove(node1)\n","                    #print('br',cset, par)\n","\n","def single_contraction_round(n, cnodes, cparents, cweight, allcyc, cutwt, dbg):\n","    elist = arr.array('i',[]) #array to store edges\n","    bdir = arr.array('i',[]) #array to store bidirected edges\n","    wt = arr.array('d',[]) #array to store edges\n","    inwt = arr.array('d', [0.0 for i in range(n)])\n","    nodelist = [[i] for i in range(n)]\n","    containsbdir = [0 for i in range(n)]\n","\n","    create_undir_edges_from_par(cnodes, cparents, cweight, elist, bdir, wt, inwt)\n","    #print 'bef', len(cnodes), len(cweight), inwt\n","    over = n-5\n","    while over >= 0:\n","        e = find_edge(n, wt, elist)\n","\n","        if e < 0 or e >= len(wt):\n","            #print e\n","            #print ('no edge to contract')\n","            over = -1\n","            break\n","        if dbg > 0:\n","            print('e =', e, 'len =', len(wt), 'n1,n2=', elist[2*e], elist[2*e+1])\n","            for i in range(len(cnodes)):\n","                print(cnodes[i], cparents[i], cweight[i])\n","        contract_edge (e, wt, elist, nodelist, cnodes, cparents, cweight, containsbdir)\n","\n","        del wt\n","        del elist\n","        del bdir\n","        wt = arr.array('d',[]) #array to store edges\n","        elist = arr.array('i',[]) #array to store edges\n","        bdir = arr.array('i',[]) #array to store bidirected edges\n","\n","        create_undir_edges_from_par(cnodes, cparents, cweight, elist, bdir, wt, inwt)\n","\n","        for i in range(len(inwt)):\n","            if inwt[i] < 0.98*cutwt and len(nodelist[i]) > 1 and nodelist[i] not in allcyc:\n","                allcyc.append(nodelist[i][:])\n","                #print('hello', nodelist[i],  inwt[i])\n","\n","        if dbg > 0:\n","            print (nodelist)\n","            print (inwt)\n","        over = over - 1\n","    #end while\n","#end function\n","\n","def contract_heur(n, icnodes, icparents, icweight, cutwt):\n","    #first locate edges with weight>= 0.99 and check if almost directed cycle exists\n","    wt = arr.array('d',[]) #array to store edges\n","    elist = arr.array('i',[]) #array to store edges\n","    bdir = arr.array('i',[]) #array to store bidirected edges\n","    bdirwt = arr.array('d',[]) #array to store bidirected edges\n","    #telist = arr.array('i',[]) #array to store edges\n","    allcyc = []\n","    inwt = arr.array('d', [0 for i in range(n)])\n","    cnodes = []\n","    cparents = []\n","    cweight = []\n","\n","    # copy all input arrays as we will modify them\n","    for i in range(len(icnodes)):\n","        if icweight[i] > 0.001:\n","            cnodes.append(icnodes[i][:])\n","            cparents.append(icparents[i][:])\n","            cweight.append(icweight[i])\n","\n","    nccomp = len(cnodes)\n","    #print('n = ', n, 'nccomp = ', nccomp)\n","\n","    #for k in range(len(cnodes)):\n","    #    print 'he', k, cnodes[k], cparents[k], cweight[k]\n","\n","    create_edges_from_par(cnodes, cparents, cweight, elist, bdir, bdirwt, wt, inwt)\n","\n","    '''\n","    #now create array of wt 0.95+ edges and test for directed cycles\n","    for i in range(len(wt)):\n","        if wt[i] >= 0.95:\n","            telist.append(elist[2*i])\n","            telist.append(elist[2*i+1])\n","\n","    allcyc = dircyc(n, len(telist)/2, telist)\n","    if len(allcyc) > 0:\n","        return allcyc\n","    # at this point we do not have any directed cycles\n","    '''\n","\n","    '''\n","    # now look for cluster ineqs. First modify bidirected sets, here we assume we are splitting it up\n","    if len(bdir) > 0:\n","        cl = len(cnodes)\n","        for i in range(cl):\n","            cset = cnodes[i]\n","            parent = cparents[i]\n","            twt = cweight[i]\n","\n","            if len(cset) > 1:\n","                #print (cset, len(cset))\n","                cnodes[i] = [cset[0]]\n","                cparents[i] = [parent[0][:]]\n","                cnodes.append([cset[1]])\n","                cweight.append(twt)\n","                cparents.append([parent[1][:]])\n","        #print ('old len = ', cl, ' new len = ', len(cnodes))\n","\n","        i = len(cnodes)-1\n","        while i >=0:\n","            if cweight[i] <= 0.001:\n","                del cnodes[i]\n","                del cparents[i]\n","                del cweight[i]\n","            i = i-1\n","    '''\n","\n","    for numrep in range(20):\n","        dbg = 0\n","        # now modify cnodes, cparents, cweight to find regular cluster inequalities\n","        tnodes = []\n","        tparents = []\n","        tweight = arr.array('d', [])\n","\n","        # now copy all parent set info as it is used destructively inside single_contraction round\n","        for i in range(len(cnodes)):\n","            cset = []\n","            par = []\n","            for j in range(len(cnodes[i])):\n","                cset.append(cnodes[i][j])\n","\n","            for j in range(len(cparents[i])):\n","                par.append(cparents[i][j][:])\n","\n","            tnodes.append(cset)\n","            tparents.append(par)\n","            tweight.append(cweight[i])\n","\n","        if dbg > 0:\n","            for i in range(len(tnodes)):\n","                print(cnodes[i], cparents[i], cweight[i])\n","\n","        single_contraction_round (n, tnodes, tparents, tweight, allcyc, cutwt, dbg)\n","\n","        if len(allcyc) > 10:\n","            break\n","    #end repeat\n","\n","    return allcyc\n","#end of function\n","\n","def contract_heur_bdir(n, icnodes, icparents, icweight):\n","    #first locate edges with weight>= 0.99 and check if almost directed cycle exists\n","    wt = arr.array('d',[]) #array to store edges\n","    elist = arr.array('i',[]) #array to store edges\n","    bdir = arr.array('i',[]) #array to store bidirected edges\n","    bdirwt = arr.array('d',[]) #array to store bidirected edges\n","    inwt = arr.array('d', [0 for i in range(n)])\n","    cnodes = []\n","    cparents = []\n","    cweight = []\n","    allcyc = []\n","\n","    # copy all input arrays as we will modify them\n","    for i in range(len(icnodes)):\n","        if icweight[i] > 0.001:\n","            cnodes.append(icnodes[i][:])\n","            cparents.append(icparents[i][:])\n","            cweight.append(icweight[i])\n","\n","    nccomp = len(cnodes)\n","    #print('n = ', n, 'nccomp = ', nccomp)\n","\n","\n","    create_edges_from_par(cnodes, cparents, cweight, elist, bdir, bdirwt, wt, inwt)\n","\n","    for b in range(int(len(bdir)/2)):\n","\n","        # now modify cnodes, cparents, cweight to find regular cluster inequalities\n","        tnodes = []\n","        tparents = []\n","        tweight = arr.array('d', [])\n","        nodelist = [[i] for i in range(n)]\n","        containsbdir = [0 for i in range(n)]\n","\n","        #print('bdir = ', bdir[2*b], bdir[2*b+1], bdirwt[b])\n","\n","        for i in range(len(cnodes)):\n","            cset = []\n","            par = []\n","            for j in range(len(cnodes[i])):\n","                cset.append(cnodes[i][j])\n","\n","            for j in range(len(cparents[i])):\n","                par.append(cparents[i][j][:])\n","\n","            tnodes.append(cset)\n","            tparents.append(par)\n","            tweight.append(cweight[i])\n","\n","\n","        contract_bdir_edge (bdir[2*b], bdir[2*b+1], wt, elist, nodelist, tnodes, tparents, tweight, containsbdir)\n","\n","        #for k in range(len(tnodes)):\n","        #    print 'll', k, tnodes[k], tparents[k], tweight[k]\n","\n","        newcyc = contract_heur (n, tnodes, tparents, tweight, bdirwt[b])\n","        if len(newcyc) > 0:\n","            for cyc in newcyc:\n","                if bdir[2*b+1] in cyc:\n","                    cyc1 = cyc\n","                    cyc1.remove(bdir[2*b+1])\n","                    cyc1.sort()\n","                    newc = [bdir[2*b], bdir[2*b+1]] + cyc\n","\n","                    if not newc in allcyc:\n","                        allcyc.append(newc)\n","                        #print('adding ', newc)\n","\n","    return allcyc\n","#end of function\n","\n","def add_dummy_node(n, cnodes, cparents, cweight):\n","    for i in range(len(cnodes)):\n","        cset = cnodes[i]\n","        parent = cparents[i]\n","\n","        for j in range(len(cset)):\n","            if len(parent[j]) == 0:\n","                parent[j].append(n)\n","\n","#n = 3\n","#ne = 3\n","#elist = arr.array('i', [0,1, 1, 2, 2, 0])\n","#n = 6\n","#ne = 7\n","#elist = arr.array('i', [0,1, 1, 2, 2,0, 3,4,4,5,5,3, 3,1])\n","#allc = almostdircyc(n, ne, elist, 3, 2)\n","#print(allc)\n","'''\n","#parse(\"tst1.sol\", 20)\n","nco = [7, 6, 11, 6, 0, 6, 13, 6, 10, 6, 15, 6, 4, 6]\n","ncount = 0\n","\n","n = 5\n","gcnodes = [[0], [1], [2], [3,4]]\n","gcweight = [1.0, 1.0, 1.0, 1.0]\n","gcparents = [[[1,2]], [[2, 3]], [[]], [[], [1]]]\n","\n","#add_dummy_node(n, gcnodes, gcparents, gcweight)\n","#print gcnodes\n","#print gcparents\n","\n","gcnodes = []\n","gcparents = []\n","gcweight = arr.array('d', [])\n","\n","bdiredgewt = 0.0\n","\n","if len(sys.argv) > 1:\n","    n=int(sys.argv[1])\n","    filename = sys.argv[2]\n","\n","    parse(filename, n, gcnodes, gcparents, gcweight)\n","\n","random.seed(1)\n","rset = contract_heur_bdir(n+1, gcnodes, gcparents, gcweight )\n","print(rset)\n","'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":178},"id":"8k9JLboZawDX","executionInfo":{"status":"ok","timestamp":1748516633032,"user_tz":-60,"elapsed":66,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"}},"outputId":"5c26a3ff-d837-43de-8580-63a56f8d74b7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n#parse(\"tst1.sol\", 20)\\nnco = [7, 6, 11, 6, 0, 6, 13, 6, 10, 6, 15, 6, 4, 6]\\nncount = 0\\n\\nn = 5\\ngcnodes = [[0], [1], [2], [3,4]]\\ngcweight = [1.0, 1.0, 1.0, 1.0]\\ngcparents = [[[1,2]], [[2, 3]], [[]], [[], [1]]]\\n\\n#add_dummy_node(n, gcnodes, gcparents, gcweight)\\n#print gcnodes\\n#print gcparents\\n\\ngcnodes = []\\ngcparents = []\\ngcweight = arr.array(\\'d\\', [])\\n\\nbdiredgewt = 0.0\\n\\nif len(sys.argv) > 1:\\n    n=int(sys.argv[1])\\n    filename = sys.argv[2]\\n\\n    parse(filename, n, gcnodes, gcparents, gcweight)\\n\\nrandom.seed(1)\\nrset = contract_heur_bdir(n+1, gcnodes, gcparents, gcweight )\\nprint(rset)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"qfoLEpKqJU3A"},"source":["# load_problem\n","\n","*   cds\n","*   krebs\n","*   Sachs\n","*   bnlearn/nips2023\n","*   dynamic\n","*   er/sf/PATH/PATHPERM/G2\n","*   ermag  \n","*   bowfree_admg  \n","*   admissions\n","*   load_from_file\n","\n","\n","        \n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hfItrrtGIu-h"},"outputs":[],"source":["import random\n","from os.path import join\n","import networkx as nx\n","import numpy as np\n","from omegaconf import DictConfig\n","\n","from dagsolvers import sachs_utils, krebs_utils, admg_generators\n","from dagsolvers.dagsolver_utils import ExDagDataException\n","from notears import utils\n","\n","def normalize_data(X, Y):\n","    mean = np.mean(X, axis=0)\n","    std = np.std(X, axis=0)\n","    X = X - mean\n","    X = X / std\n","\n","    for i, _ in enumerate(Y):\n","        Y[i] = Y[i] - mean\n","        Y[i] = Y[i] / std\n","\n","    return X, Y\n","\n","def load_problem(cfg: DictConfig, run):\n","    '''\n","    Return: 对应的因果图结构（W_true, B_true等）和数据集（X, Y等）\n","            W_true                    因果结构权重矩阵，表示因果关系强度\n","            B_true\t                  因果关系的二值表示，即 W_true 是否存在\n","            A_true                  \t动态因果图中的滞后影响矩阵\n","            X, Y\t                    数据集，X 是当前时间步数据，Y 是滞后数据\n","            W_bi_true, B_bi_true\t    带双向边的因果结构（用于 ADMG）\n","            tabu_edges\t              禁止连接的边（用于因果约束）\n","            intra_nodes, inter_nodes\t内部节点和跨时间步的节点\n","\n","    '''\n","    graph_type = cfg.problem.name\n","    #run.log_param('problem', graph_type)\n","    tabu_edges = []\n","    intra_nodes = None\n","    inter_nodes = None #TODO: all problems should define this\n","    if graph_type == 'cds':\n","        from dagsolvers import cds_utils\n","        W_true, B_true, A_true, X, Y, intra_nodes, inter_nodes, tabu_edges = cds_utils.load_data(cfg.problem.n, cfg.problem.granularity, cfg.problem.p, cfg.problem.data_path)\n","        W_bi_true = np.zeros_like(W_true)\n","        B_bi_true = np.zeros_like(B_true)\n","    elif graph_type == 'krebs':\n","        p = cfg.problem.p\n","        measurements = cfg.problem.measurements\n","        variant = cfg.problem.variant\n","        #run.log_param('measurements', measurements)\n","        #run.log_param('variant', variant)\n","        W_true, B_true, A_true, X, Y, X_lag, intra_nodes, inter_nodes = krebs_utils.load_data(variant, measurements, p, cfg.problem.data_path)\n","        W_bi_true = None\n","        B_bi_true = None\n","        #n, d = X.shape\n","\n","    elif graph_type == 'Sachs':\n","        variant = cfg.problem.variant\n","        #run.log_param('variant', variant)\n","        #normalize = cfg.problem.get('normalize')\n","        #run.log_param('normalize', normalize)\n","        X, B_true, W_true = sachs_utils.load_data(variant, False, cfg.problem.data_path)\n","        # n, d = X.shape\n","        # p = 0\n","        Y = []\n","        A_true = []\n","        W_bi_true = None\n","        B_bi_true = None\n","\n","    elif graph_type == 'bnlearn' or graph_type == 'nips2023':\n","        #run.log_param('variant', cfg.problem.variant)\n","        if graph_type == 'bnlearn':\n","            n = cfg.problem.get('number_of_samples')\n","            # normalize = cfg.problem.get('normalize', False)\n","            # run.log_param('normalize', normalize)\n","            from dagsolvers import bnlearn_utils\n","            X, W_true = bnlearn_utils.load_dataset(cfg.problem.variant, n=n, normalize=False)\n","        elif graph_type == 'nips2023':\n","            from dagsolvers import nips_comp_utils\n","            X, W_true = nips_comp_utils.load_dataset(cfg.problem.variant, cfg.problem.data_path)\n","        else:\n","            assert False\n","        B_true = W_true\n","        # n, d = X.shape\n","        # p = 0\n","        Y = []\n","        A_true = []\n","        W_bi_true = None\n","        B_bi_true = None\n","\n","    elif graph_type == 'dynamic':\n","        #run.log_param('variant', cfg.problem.variant)\n","        p = cfg.problem.p\n","        d = cfg.problem.number_of_variables\n","        n = cfg.problem.number_of_samples\n","        degree_intra = cfg.problem.intra_edge_ratio * 2\n","        #run.log_param('intra_edge_ratio', cfg.problem.intra_edge_ratio)\n","        degree_inter = cfg.problem.inter_edge_ratio * 2\n","        #run.log_param('inter_edge_ratio', cfg.problem.inter_edge_ratio)\n","        w_max_inter = cfg.problem.w_max_inter\n","        #run.log_param('w_max_inter', w_max_inter)\n","        w_min_inter = cfg.problem.w_min_inter\n","        #run.log_param('w_min_inter', w_min_inter)\n","        w_decay = cfg.problem.w_decay\n","        #run.log_param('w_decay', w_decay)\n","        if p == 0:\n","            degree_inter = 0\n","        variant = cfg.problem.graph_type_intra\n","        if variant == 'er':\n","            graph_type_intra = 'erdos-renyi'\n","        elif variant == 'sf':\n","            graph_type_intra = 'barabasi-albert'\n","        else:\n","            assert False\n","\n","        graph_type_inter = cfg.problem.graph_type_inter\n","        if graph_type_inter == 'er':\n","            graph_type_inter = 'erdos-renyi'\n","\n","        #from structure.data_generators.wrappers import DataGenerationException\n","        try:\n","            generator = cfg.problem.generator\n","            noise_scale = cfg.problem.noise_scale\n","            noise_scale_variance = cfg.problem.get('noise_scale_variance', None)\n","            if noise_scale_variance is not None:\n","                noise_scale_vector = [random.uniform(noise_scale - noise_scale_variance, noise_scale + noise_scale_variance) for _ in range(d)]\n","            else:\n","                noise_scale_vector = [noise_scale] * d\n","            from structure.data_generators import gen_stationary_dyn_net_and_df\n","            g,df, intra_nodes, inter_nodes = gen_stationary_dyn_net_and_df(num_nodes=d, n_samples=n, p=p,\n","                                                                           degree_intra=degree_intra, degree_inter=degree_inter,\n","                                                                           graph_type_intra=graph_type_intra, graph_type_inter=graph_type_inter,\n","                                                                           w_max_intra=cfg.problem.w_max_intra, w_min_intra=cfg.problem.w_min_intra, w_min_inter=w_min_inter, w_max_inter=w_max_inter,\n","                                                                           w_decay=w_decay, noise_scale=noise_scale_vector, max_data_gen_trials=1000,\n","                                                                           generator=generator) #, w_min_inter=0.01, w_max_inter=0.2)\n","        except Exception as e: # DataGenerationException as e:\n","            run.log_text(f'Error: Cannot generate samples data. Exception: {e}', 'error.txt')\n","            run.log_metric('infeasible', True)\n","            raise ExDagDataException(e)\n","\n","        W_true = nx.to_numpy_array(g, nodelist=intra_nodes)\n","        B_true = W_true != 0\n","        a_mat = nx.to_numpy_array(g, nodelist=intra_nodes + inter_nodes)[len(intra_nodes) :, : len(intra_nodes)]\n","        df_x = df[intra_nodes]\n","        df_x_lag = df[inter_nodes]\n","        X = df_x.to_numpy()\n","        W_bi_true = None\n","        B_bi_true = None\n","        # s0 = degree_intra / 2 * d\n","        # B_true = utils.simulate_dag(d, s0, 'SF')\n","        # W_true = utils.simulate_parameter(B_true)\n","        # X = utils.simulate_linear_sem(W_true, n, 'gauss', noise_scale=1.0)\n","        # X_lag = df_x_lag.to_numpy()\n","        #X2 = utils.simulate_linear_sem(W_true, n, 'gauss', noise_scale=1.0)\n","\n","        Y = []\n","        A_true = []\n","        for lag in range(1, p + 1):\n","            lag_cols = [c for c in inter_nodes if f'_lag{lag}' in c]\n","            df_x_lag = df[lag_cols]\n","            Y_lag = df_x_lag.to_numpy()\n","            Y.append(Y_lag)\n","\n","            idxs = [f'_lag{lag}' in c for c in inter_nodes]\n","            a_mat_lag = a_mat[idxs,:]\n","            A_true.append(a_mat_lag)\n","\n","    elif graph_type == 'er' or graph_type == 'sf' or graph_type == 'PATH' or graph_type == 'PATHPERM' or graph_type == 'G2':\n","        d = cfg.problem.number_of_variables\n","        n = cfg.problem.number_of_samples\n","        edge_ratio = cfg.problem.get('edge_ratio')\n","        s0 = edge_ratio * d if edge_ratio is not None else None\n","        sem_type = cfg.problem.sem_type\n","        noise_scale = cfg.problem.noise_scale\n","        noise_scale_variance = cfg.problem.get('noise_scale_variance', None)\n","        if noise_scale_variance is not None:\n","            noise_scale = [random.uniform(noise_scale - noise_scale_variance, noise_scale + noise_scale_variance) for _ in range(d)]\n","        try:\n","            B_true = utils.simulate_dag(d, s0, graph_type.upper())\n","        except Exception as e:\n","            run.log_text(f'Error: Cannot generate samples data. Exception: {e}', 'error.txt')\n","            raise ExDagDataException(e)\n","\n","        if cfg.problem.get('only_01', False):\n","            W_true = B_true\n","        elif cfg.problem.get('only_positive', False):\n","            W_true = utils.simulate_parameter(B_true, w_ranges=((0.5, 2.0),))\n","        else:\n","            W_true = utils.simulate_parameter(B_true)\n","        X = utils.simulate_linear_sem(W_true, n, sem_type, noise_scale=noise_scale, internal_normalization=cfg.problem.get('internal_normalization', False))\n","        Y = []\n","        A_true = []\n","        W_bi_true = None\n","        B_bi_true = None\n","        #p = 0\n","\n","    elif graph_type == 'ermag':\n","        d = cfg.problem.number_of_variables\n","        n = cfg.problem.number_of_samples\n","        edge_ratio = cfg.problem.get('edge_ratio', 1)\n","        run.log_param('edge_ratio', edge_ratio)\n","        s0 = edge_ratio * d\n","        sem_type = cfg.problem.sem_type\n","        noise_scale = cfg.problem.get('noise_scale', 1.0)\n","        tabu_edges_ratio = cfg.problem.get('tabu_edges_ratio', 0.2)\n","        hidden_vertices_ratio = cfg.problem.get('hidden_vertices_ratio', 0.2)\n","        run.log_param('sem_type', sem_type)\n","        run.log_param('noise_scale', noise_scale)\n","        try:\n","            B_true = utils.simulate_dag(d, s0, \"ER\")\n","        except Exception as e:\n","            run.log_text(f'Error: Cannot generate samples data. Exception: {e}', 'error.txt')\n","            run.log_metric('infeasible', True)\n","            raise ExDagDataException(e)\n","\n","        if cfg.problem.get('only_01', False):\n","            W_true = B_true\n","        elif cfg.problem.get('only_positive', False):\n","            W_true = utils.simulate_parameter(B_true, w_ranges=((0.5, 2.0),))\n","        else:\n","            W_true = utils.simulate_parameter(B_true)\n","        X = utils.simulate_linear_sem(W_true, n, sem_type, noise_scale=noise_scale)\n","        Y = []\n","        A_true = []\n","\n","\n","        # p = 0\n","\n","        new_d = int(d * (1-hidden_vertices_ratio))\n","        indices = np.random.choice(range(d), size=new_d, replace=False)\n","        d = new_d\n","        X = X[:, indices]\n","        W_true = W_true[np.ix_(indices, indices)]\n","        B_true = B_true[np.ix_(indices, indices)]\n","        B_bi_true = np.zeros_like(B_true)\n","        for i in range(d):\n","            for j in range(i):\n","                if W_true[i, j] == 0.0 and W_true[j, i] == 0.0:\n","                    if np.random.rand() < tabu_edges_ratio:\n","                        tabu_edges.append((i, j))\n","                        B_bi_true[i, j] = 1.0\n","                        B_bi_true[j, i] = 1.0 # Maybe dubious.\n","\n","        W_bi_true = np.copy(B_bi_true)\n","\n","    elif graph_type == 'bowfree_admg':\n","        B_true, B_bi_true, tabu_edges, X = admg_generators.generate_graph_and_samples(cfg.problem.number_of_variables,cfg.problem.pdir, cfg.problem.pbidir,cfg.problem.number_of_samples)\n","        W_true = B_true\n","        W_bi_true = B_bi_true\n","        Y = []\n","        A_true = []\n","\n","    elif graph_type == 'admissions':\n","        import pandas as pd\n","        from sklearn.preprocessing import LabelEncoder\n","        file_path = cfg.problem.data_path\n","        df = pd.read_csv(file_path, sep=';')\n","        encoder = LabelEncoder()\n","        for col in ['gender', 'admit']:\n","            df[col] = encoder.fit_transform(df[col])\n","        #del df['gender']\n","        #df['gender'] = df['gender']\n","        #df['admit'] = 2 * df['admit']\n","        df = pd.get_dummies(df, columns=['department'], prefix='D', dtype=int)\n","        # for col in df.columns:\n","        #     if 'department' in col:\n","        #         df[col] = df[col] * 0.5\n","        # print(df.to_string())\n","\n","        X = df.to_numpy()\n","        intra_nodes = df.columns.tolist()\n","\n","        W_true = np.zeros((X.shape[1], X.shape[1]))\n","        B_true = np.zeros((X.shape[1], X.shape[1]))\n","        A_true = []\n","        Y = []\n","        W_bi_true = np.zeros((X.shape[1], X.shape[1]))\n","        B_bi_true = np.zeros((X.shape[1], X.shape[1]))\n","        tabu_edges = [(0,1),(1,0)]\n","    elif :\n","\n","\n","\n","\n","\n","    elif graph_type == 'load_from_file':\n","        assert False, 'implement me'\n","\n","    else:\n","        assert False, 'unknown problem'\n","\n","    # Generating default node names.\n","    if intra_nodes is None:\n","        intra_nodes = [f'node_{i}' for i in range(len(X[0]))]\n","    if inter_nodes is None:\n","        inter_nodes = [f'node_{i}_lag_{lag}' for lag in range(1, cfg.problem.get('p', 0) + 1) for i in range(len(X[0]))]\n","\n","    return W_true, W_bi_true, B_true, B_bi_true, A_true, X, Y, tabu_edges, intra_nodes, inter_nodes\n","\n"]},{"cell_type":"markdown","metadata":{"id":"bqFLMZWsXoID"},"source":["# Start Experiment\n","\n","* 这是整个 pipeline 的执行入口，调用多个求解器模块：milp, exmag, gobnilp, notears 等"]},{"cell_type":"markdown","metadata":{"id":"2RPGGmajqiny"},"source":["## Varsortability"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1-npR8-Eqiye"},"outputs":[],"source":["import numpy as np\n","\n","def varsortability(X, W, tol=1e-9):\n","    \"\"\" Takes n x d data and a d x d adjaceny matrix,\n","    where the i,j-th entry corresponds to the edge weight for i->j,\n","    and returns a value indicating how well the variance order\n","    reflects the causal order. \"\"\"\n","    E = W != 0\n","    Ek = E.copy()\n","    var = np.var(X, axis=0, keepdims=True)\n","\n","    n_paths = 0\n","    n_correctly_ordered_paths = 0\n","\n","    for _ in range(E.shape[0] - 1):\n","        n_paths += Ek.sum()\n","        n_correctly_ordered_paths += (Ek * var / var.T > 1 + tol).sum()\n","        n_correctly_ordered_paths += 1/2*(\n","            (Ek * var / var.T <= 1 + tol) *\n","            (Ek * var / var.T >  1 - tol)).sum()\n","        Ek = Ek.dot(E)\n","\n","    return n_correctly_ordered_paths / n_paths\n","\n","if __name__ == \"__main__\":\n","    W = np.array([[0, 1, 0], [0, 0, 2], [0, 0, 0]])\n","    X = np.random.randn(1000, 3).dot(np.linalg.inv(np.eye(3) - W))\n","    print(\"Varsortability:\", varsortability(X, W))\n","\n","    X_std = (X - np.mean(X, axis=0))/np.std(X, axis=0)\n","    print(\"Varsortability standardized:\", varsortability(X_std, W))"]},{"cell_type":"markdown","metadata":{"id":"gQ0Lkg8JqyeX"},"source":["## tracking_utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KUwrPeITqypJ"},"outputs":[],"source":[" from typing import Optional, Union, Dict, Any\n","\n","\n","_tracking_type = None\n","_experiment_name = None\n","\n","class ExperimentRunNeptune:\n","    def __init__(self, description):\n","        import neptune\n","        self.tracking_object = neptune.init_run(tags=[description], monitoring_namespace=\"monitoring\")\n","\n","    def __enter__(self):\n","        return self\n","\n","    def __exit__(self, exc_type, exc_val, exc_tb):\n","        return self.tracking_object.__exit__(exc_type, exc_val, exc_tb)\n","\n","    def log_metric(self, key, value):\n","        self.tracking_object[f'metrics/{key}'] = value\n","\n","\n","    def log_param(self, key, value):\n","        self.tracking_object[f'params/{key}'] = value\n","\n","    def log_artifact(self, local_path: str, artifact_path: Optional[str] = None):\n","        self.tracking_object[f'artifacts/{artifact_path}'].upload(local_path)\n","\n","    def log_text(self, text: str, artifact_file: str):\n","        from neptune.types import File\n","        self.tracking_object[f'texts/{artifact_file}'].upload(File.from_content(text))\n","\n","    def log_table(self, data: Union[Dict[str, Any], \"pandas.DataFrame\"], artifact_file: str,):\n","        if isinstance(data, dict):\n","            import pandas as pd\n","            data = pd.DataFrame.from_dict(data)\n","        from neptune.types import File\n","        self.tracking_object[f'tables/{artifact_file}'].upload(File.as_html(data))\n","\n","\n","class ExperimentRunMLFlow:\n","    import mlflow\n","    def __init__(self):\n","        self.tracking_object = self.mlflow.start_run()\n","\n","    def __enter__(self):\n","        return self\n","\n","    def __exit__(self, exc_type, exc_val, exc_tb):\n","        return self.tracking_object.__exit__(exc_type, exc_val, exc_tb)\n","\n","    def log_metric(self, key, value):\n","        return self.mlflow.log_metric(key, value)\n","\n","    def log_param(self, key, value):\n","        return self.mlflow.log_param(key, value)\n","\n","    def log_artifact(self, local_path: str, artifact_path: Optional[str] = None):\n","        return self.mlflow.log_artifact(local_path, artifact_path)\n","\n","    def log_text(self, text: str, artifact_file: str):\n","        return self.mlflow.log_text(text, artifact_file)\n","\n","    def log_table(self, data: Union[Dict[str, Any], \"pandas.DataFrame\"], artifact_file: str,):\n","        return self.mlflow.log_table(data, artifact_file)\n","\n","\n","def set_tracking(tracking_type: str, experiment_name: str | None = None):\n","    if tracking_type == 'mlflow':\n","        import mlflow\n","        mlflow.set_experiment(experiment_name)\n","    elif tracking_type == 'neptune':\n","        import neptune\n","    else:\n","        assert False, 'Invalid tracking type'\n","    global _tracking_type\n","    global _experiment_name\n","    _tracking_type = tracking_type\n","    _experiment_name = experiment_name\n","\n","\n","def start_run():\n","    global _tracking_type\n","    if _tracking_type == 'mlflow':\n","        return ExperimentRunMLFlow()\n","    elif _tracking_type == 'neptune':\n","        global _experiment_name\n","        return ExperimentRunNeptune(_experiment_name)\n","    else:\n","        assert False\n","\n","\n","# def end_run():\n","#     pass"]},{"cell_type":"markdown","metadata":{"id":"zZtCyb-KrDDY"},"source":["## MLflow 辅助工具集"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1-5blufQlBs6"},"outputs":[],"source":["import os\n","\n","import mlflow\n","from mlflow import log_param\n","from omegaconf import DictConfig, ListConfig\n","\n","\n","def _create_recursive(parent_name, element):\n","    if isinstance(element, DictConfig):\n","        strings = []\n","        for k, v in element.items():\n","            if isinstance(v, DictConfig) or isinstance(v, ListConfig):\n","                strings.append(_create_recursive(f'{parent_name}.{k}', v))\n","            else:\n","                strings.append(f\"{parent_name}.{k} = '{v}'\")\n","        return ' and '.join(strings)\n","    elif isinstance(element, ListConfig):\n","        assert False, 'Lists not supported - cannot make OR query'\n","    else:\n","        return f\"{parent_name} = '{element}'\"\n","\n","def create_mlflow_query_string(params: DictConfig, finished=True):\n","    query_strings = []\n","    if finished:\n","        query_strings.append(\"status = 'FINISHED'\")\n","    for param_name, element in params.items():\n","        query_strings.append(_create_recursive(f'params.{param_name}', element))\n","    return ' and '.join(query_strings)\n","\n","\n","def log_system_info(hydra_config: DictConfig):\n","    mem_per_cpu = hydra_config.launcher.get(\"mem_per_cpu\")\n","    if mem_per_cpu is not None:\n","        log_param('slurm.mem_per_cpu', mem_per_cpu)\n","\n","    cpus_per_task = hydra_config.launcher.get(\"cpus_per_task\")\n","    if cpus_per_task is not None:\n","        log_param('slurm.cpus_per_task', cpus_per_task)\n","\n","    partition = hydra_config.launcher.get(\"partition\")\n","    if partition is not None:\n","        log_param('slurm.partition', partition)\n","    log_param('system.hostname', os.uname()[1])\n","\n","\n","def log_params_from_omegaconf_dict(params, only_keys=None):\n","    for param_name, element in params.items():\n","        if only_keys is None or param_name in only_keys:\n","            _explore_recursive(param_name, element)\n","\n","def _explore_recursive(parent_name, element):\n","    if isinstance(element, DictConfig):\n","        for k, v in element.items():\n","            if isinstance(v, DictConfig) or isinstance(v, ListConfig):\n","                _explore_recursive(f'{parent_name}.{k}', v)\n","            else:\n","                mlflow.log_param(f'{parent_name}.{k}', v)\n","    elif isinstance(element, ListConfig):\n","        for i, v in enumerate(element):\n","            mlflow.log_param(f'{parent_name}.{i}', v)\n","    else:\n","        mlflow.log_param(parent_name, element)"]},{"cell_type":"markdown","metadata":{"id":"dxL6xvCWJMLt"},"source":["## Hydra_MLflow_Experiments"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mss6ieR3Iu34"},"outputs":[],"source":["import time\n","import logging\n","from os.path import join\n","import hydra\n","import numpy as np\n","from hydra.core.hydra_config import HydraConfig\n","from mlflow import log_metric, log_text\n","\n","from dagsolvers.ploting_utils import make_plots\n","from dagsolvers.sortnregress import sortnregress\n","from dagsolvers.varsortability import varsortability\n","\n","logger = logging.getLogger(__name__)\n","\n","from omegaconf import DictConfig, OmegaConf\n","\n","from dagsolvers.dagsolver_utils import apply_threshold, find_optimal_threshold_for_shd, least_square_cost, plot, count_accuracy, \\\n","    find_optimal_multiple_thresholds, compute_norm_distance, ExDagDataException, plot_heatmap\n","from dagsolvers.data_generation_loading_utils import load_problem, normalize_data\n","from dagsolvers.experiments_utils import log_params_from_omegaconf_dict, log_system_info\n","from dagsolvers.metrics_utils import calculate_metrics\n","from dagsolvers.utils import log_exceptions\n","from notears import utils, linear\n","import dagsolvers.solve_milp\n","import dagsolvers.solve_exmag\n","import dagsolvers.solve_gobnilp\n","from structure.dynotears import from_numpy_dynamic\n","import dagsolvers.tracking_utils as tu\n","\n","\n","@hydra.main(version_base=None,  config_path=\"./experiments_conf\", config_name=\"config\")\n","@log_exceptions\n","def start_experiment(cfg: DictConfig) -> None:\n","    tu.set_tracking(cfg.tracking, cfg.experiment) #mlflow.set_experiment(experiment_name=cfg.experiment)\n","    conf_yaml = OmegaConf.to_yaml(cfg)\n","    print(conf_yaml)\n","    app_config = OmegaConf.to_container(cfg)\n","    seed = cfg.problem.seed\n","\n","\n","    utils.set_random_seed(seed)\n","    with tu.start_run() as run:\n","        #log_params_from_omegaconf_dict(cfg)\n","        log_params_from_omegaconf_dict(cfg, {'solver', 'problem'})\n","        log_system_info(HydraConfig.get())\n","        note = cfg.get('note','')\n","        run.log_param('note', note)\n","        output_dir = hydra.core.hydra_config.HydraConfig.get().runtime.output_dir\n","        run.log_text(output_dir, 'work_dir.txt')\n","        logger.info(f'Starting experiment in {output_dir}')\n","        with open(join(output_dir, 'config.yaml'), 'w') as f:\n","            f.write(conf_yaml)\n","        run.log_artifact(join(output_dir, 'config.yaml'))\n","\n","        try:\n","            W_true, W_bi_true, B_true, B_bi_true, A_true, X, Y, tabu_edges, intra_nodes, inter_nodes = load_problem(cfg, run)\n","            varsort = varsortability(X, B_true)\n","            print(f'VARSORT: {varsort}')\n","            run.log_metric('varsortability', varsort)\n","            variances = np.var(X, axis=0)\n","            means = np.mean(X, axis=0)\n","            logger.info(f'DATA MEANS: {means}')\n","            logger.info(f'DATA VARIANCES: {variances}')\n","            if cfg.problem.normalize:\n","                #run.log_param('normalize', cfg.problem.normalize)\n","                X, Y = normalize_data(X,Y)\n","                print(f'varsort: {varsortability(X, B_true)}')\n","                # variances = np.var(X, axis=0)\n","                # means = np.mean(X, axis=0)\n","                logger.info(f'DATA NORMALIZED:')\n","                # print(means)\n","                # print(variances)\n","        except ExDagDataException as e:\n","            logging.critical(e, exc_info=True)\n","            return\n","\n","        n, d = X.shape\n","        p = len(A_true) if A_true is not None else 0\n","\n","        np.savetxt(join(output_dir,'W_true.csv'), W_true, delimiter=',')\n","        run.log_artifact(join(output_dir,'W_true.csv'))\n","        for i, A_i_true in enumerate(A_true):\n","            np.savetxt(join(output_dir,f'A{i}_true.csv'), A_i_true, delimiter=',')\n","            run.log_artifact(join(output_dir,f'A{i}_true.csv'))\n","        if W_bi_true is not None:\n","            np.savetxt(join(output_dir,'W_bi_true.csv'), W_bi_true, delimiter=',')\n","            run.log_artifact(join(output_dir,'W_bi_true.csv'))\n","\n","        np.savetxt(join(output_dir,'X.csv'), X, delimiter=',')\n","        run.log_artifact(join(output_dir,'X.csv'))\n","\n","        for i, Y_i in enumerate(Y):\n","            np.savetxt(join(output_dir,f'Y{i+1}.csv'), Y_i, delimiter=',')\n","            run.log_artifact(join(output_dir,f'Y{i+1}.csv'))\n","\n","        run.log_metric('n', n)\n","        run.log_metric('d', d)\n","        run.log_metric('p', p)\n","        #run.log_param('algo', cfg.solver.name)\n","\n","        #run.log_param('seed', seed)\n","\n","        logger.info(f'DATA GENERATED')\n","\n","        # if lambda1 is not None:\n","        #     run.log_param('lambda1', lambda1)\n","        # if lambda2 is not None:\n","        #     run.log_param('lambda2', lambda2)\n","        # run.log_param('loss_type', loss_type)\n","\n","        logger.info(f'STARTING SOLVER')\n","        start_time = time.time()\n","        Wbi = None\n","        if cfg.solver.name == 'milp':\n","            W_est, A_est, gap, lazy_count, stats = solve_milp.solve(X, cfg.solver, 0, Y=Y,\n","                                                                    B_ref=B_true,\n","                                                                    tabu_edges=tabu_edges if cfg.solver.tabu_edges else None)\n","            if W_est is None:\n","                run.log_text(f'Error: Gurobi has not found a solution', 'error.txt')\n","                run.log_metric('infeasible', True)\n","                return\n","            if stats:\n","                table_data = {}\n","                table_data['Time'] = [s[0] for s in stats]\n","                table_data['Def_thresh_SHD'] = [s[1] for s in stats]\n","                table_data['Best_SHD'] = [s[2] for s in stats]\n","                table_data['Best_threshold'] = [s[3] for s in stats]\n","                table_data['Objective_val'] = [s[4] for s in stats]\n","                table_data['Dag_t'] = [s[5] for s in stats]\n","                run.log_table(table_data, 'solving_progress.json')\n","            run.log_metric('mipgap', gap)\n","            run.log_metric('lazy_added', lazy_count)\n","        elif cfg.solver.name == \"exmag\":\n","            callback_mode = cfg.solver.callback_mode\n","            robust = cfg.solver.robust\n","            weights_bound = cfg.solver.weights_bound\n","            reg_type = cfg.solver.reg_type\n","            run.log_param('reg_type', reg_type)\n","            a_reg_type = cfg.solver.a_reg_type\n","            run.log_param('a_reg_type', a_reg_type)\n","            target_mip_gap = cfg.solver.target_mip_gap\n","            run.log_param('target_mip_gap', target_mip_gap)\n","            run.log_param('robust', robust)\n","            run.log_param('callback_mode', callback_mode)\n","            run.log_param('weights_bound', weights_bound)\n","            #run.log_param('time_limit', cfg.time_limit)\n","\n","            #W_est, A_est, gap, lazy_count, stats = solve_exmag.solve(X, lambda1, loss_type, reg_type,\n","            W_est, Wbi, gap, lazy_count, stats = solve_exmag.solve(X, cfg.solver.lambda1, cfg.solver.loss_type, reg_type,\n","                                                                   0, tabu_edges=tabu_edges,\n","                                                                   B_ref=B_true, mode=callback_mode,\n","                                                                   time_limit=cfg.solver.time_limit,\n","                                                                   robust=robust, weights_bound=weights_bound)\n","            A_est = []\n","            # (X, lambda1, loss_type, reg_type, w_threshold, tabu_edges={}, B_ref=None, mode='shortest_cycle',\n","            #           time_limit=300, robust=False, weights_bound=100.0, constraints_mode='weights')\n","            if W_est is None:\n","                run.log_text(f'Error: Gurobi has not found a solution', 'error.txt')\n","                run.log_metric('infeasible', True)\n","                return\n","            if stats:\n","                table_data = {}\n","                table_data['Time'] = [s[0] for s in stats]\n","                table_data['Def_thresh_SHD'] = [s[1] for s in stats]\n","                table_data['Best_SHD'] = [s[2] for s in stats]\n","                table_data['Best_threshold'] = [s[3] for s in stats]\n","                table_data['Objective_val'] = [s[4] for s in stats]\n","                table_data['Dag_t'] = [s[5] for s in stats]\n","                run.log_table(table_data, 'solving_progress.json')\n","            run.log_metric('mipgap', gap)\n","            run.log_metric('lazy_added', lazy_count)\n","        elif cfg.solver.name == 'gobnilp':\n","            palim = cfg.solver.get('palim')\n","            run.log_param('palim', palim)\n","            print('palim')\n","            print(palim)\n","            W_est = solve_gobnilp.solve(X, cfg.solver)\n","            A_est = []\n","        elif cfg.solver.name == 'micodag':\n","            # pip install micodag\n","            import dagsolvers.solvers.micpnid as mic\n","            moral = [(i+1,j+1) for i in range(d) for j in range(d) if i!=j]\n","            RGAP, W_est, _, obj, _ = mic.optimize(X, moral, cfg.solver.lambda1, timelimit = cfg.solver.time_limit / d)\n","            run.log_metric('objective_value', obj)\n","            run.log_metric('mipgap', RGAP)\n","            A_est = []\n","        elif cfg.solver.name == 'notears':\n","            #threshold = cfg.solver.nonzero_threshold\n","            #log_param('threshold', threshold)\n","            W_est = linear.notears_linear(X, cfg.solver.lambda1, cfg.solver.loss_type, w_threshold=0.1) # Does not work well with 0.\n","            A_est = []\n","        elif cfg.solver.name == 'sortnregress':\n","            W_est = sortnregress(X)\n","            A_est = []\n","        elif cfg.solver.name == 'dagma':\n","            from solve_dagma import solve_dagma\n","            W_est = solve_dagma(X, cfg.solver)\n","            A_est = []\n","        elif cfg.solver.name == 'boss':\n","            from solve_boss import solve_boss\n","            W_est = solve_boss(X, output_dir, cfg.solver.cmd)\n","            A_est = []\n","        elif cfg.solver.name == 'lingam':\n","            from solve_lingam import solve_lingam\n","            W_est, A_est = solve_lingam(X, Y, p)\n","        elif cfg.solver.name == 'dynotears':\n","            X_lag = np.concatenate(Y, axis=1)\n","            _, W_est, A_est_concated = from_numpy_dynamic(X,X_lag, w_threshold=0.1, lambda_w=cfg.solver.lambda1, lambda_a=cfg.solver.lambda2)\n","            A_est = []\n","            for lag in range(p): # range(1, p + 1):\n","                #idxs = [f'_lag{lag}' in c for c in inter_nodes]\n","                idxs = list(range(d*lag, d*(lag+1)))\n","                A_est_lag = A_est_concated[idxs,:]\n","                A_est.append(A_est_lag)\n","            #print(A_est)\n","        else:\n","            assert False\n","        solving_duration = time.time() - start_time\n","        logger.info(f'SOLVER FINISHED')\n","        if not utils.is_dag(W_est):\n","            run.log_text('Error: Graph found is not DAG', 'error.txt')\n","            run.log_metric('infeasible', True)\n","            return\n","        run.log_metric('runtime', solving_duration)\n","        #assert utils.is_dag(W_est)\n","        np.savetxt(join(output_dir,'W_est.csv'), W_est, delimiter=',')\n","        run.log_artifact(join(output_dir,'W_est.csv'))\n","        if Wbi is not None:\n","            np.savetxt(join(output_dir,'W_bi_est.csv'), Wbi, delimiter=',')\n","            run.log_artifact(join(output_dir,'W_bi_est.csv'))\n","        for i, A_est_i in enumerate(A_est):\n","            np.savetxt(join(output_dir,f'A_est_{i}_no_t.csv'), W_est, delimiter=',')\n","            run.log_artifact(join(output_dir,f'A_est_{i}_no_t.csv'))\n","\n","\n","\n","        best_W, best_Wbi, best_A = calculate_metrics(X, Y, W_true, B_true, A_true, W_est, A_est, W_bi_true, Wbi, run, cfg)\n","\n","        if cfg.plot:\n","            make_plots(run, W_true, W_est, best_W, W_bi_true, Wbi, best_Wbi, intra_nodes, A_true, A_est, best_A, inter_nodes, output_dir, cfg.plot_dpi)\n","\n","if __name__ == \"__main__\":\n","    start_experiment()\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"DMFjNsw7WNPz"},"source":["# Test Nutrition CoDiet"]},{"cell_type":"markdown","source":["## Data Loader"],"metadata":{"id":"7AFrLhFZZYBA"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":436},"executionInfo":{"elapsed":757,"status":"error","timestamp":1750170050714,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"},"user_tz":-120},"id":"X3X4SBtaD5Pk","outputId":"bfcb13e2-8f43-46f6-a417-4a75473a8e1c"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '../datasets/DBN_test_data.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-493474240>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../datasets/DBN_test_data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'User ID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'visit'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Meal ID'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Food ID'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Nutrient table code'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Food group code'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Serving size (g/ml)'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Leftovers (g/ml)'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Portion size (g/ml)'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Reasonable amount'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../datasets/DBN_test_data.csv'"]}],"source":["import pandas as pd\n","data = pd.read_csv('./datasets/DBN_test_data.csv', sep=';')\n","test_data = data.drop(columns=['User ID', 'visit','Meal ID','Food ID','Nutrient table code', 'Food group code','Serving size (g/ml)','Leftovers (g/ml)','Portion size (g/ml)','Reasonable amount'])\n","test_data"]},{"cell_type":"code","source":["test_data=test_data.iloc[:3]\n","n_patients = test_data['patient'].unique()\n","\n","for patient_id in n_patients:\n","    patient_data = test_data[test_data['patient']==patient_id]\n","    patient_data = patient_data.drop(columns='patient')\n","    stds = np.std(patient_data, axis=0)\n","    X_clean = patient_data.loc[:, stds != 0]\n","X_clean\n","# time*features*patients"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":245},"id":"NRhwYVcHnWf9","executionInfo":{"status":"ok","timestamp":1748518305034,"user_tz":-60,"elapsed":8,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"}},"outputId":"13e25c6b-b43c-4e0c-f259-cc59da53b12c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Ready meal       Water  Total nitrogen  Nitrogen conversion factor  \\\n","0    0.042857  102.656000        0.829000                    8.373000   \n","1    0.000000  231.611774        0.996935                   16.928871   \n","2    0.047619  358.191429        1.680714                   25.690952   \n","\n","    Protein       Fat  Carbohydrate  Energy (kcal)  Energy (kJ)   Alcohol  \\\n","0  5.116143  6.101714     15.307286     143.255286   600.649571  1.497714   \n","1  5.831290  8.712258     14.135968     197.995968   825.781290  6.142419   \n","2  9.915952  6.922381     20.247619     237.025238   990.075952  8.342619   \n","\n","   ...     tsrd  vfa-(visceral-fat-area)  vfl-(visceral-fat-level)  vlf(ln)  \\\n","0  ...   92.732                    256.4                      25.0    3.166   \n","1  ...  114.645                    258.6                      25.0    3.530   \n","2  ...  107.710                    261.0                      26.0    3.915   \n","\n","   wc(waist-circumference)   weight-control  weight  whr-(waist-hip-ratio)  \\\n","0                     125.7           -35.8    98.0                   1.10   \n","1                     126.2           -36.4    98.2                   1.10   \n","2                     127.7           -36.4    97.5                   1.12   \n","\n","   whtr(waist-height-ratio)  xc/ht  \n","0                      0.81   28.7  \n","1                      0.81   30.4  \n","2                      0.82   31.5  \n","\n","[3 rows x 200 columns]"],"text/html":["\n","  <div id=\"df-e32eaab7-2818-4236-8c58-81e8a507f903\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Ready meal</th>\n","      <th>Water</th>\n","      <th>Total nitrogen</th>\n","      <th>Nitrogen conversion factor</th>\n","      <th>Protein</th>\n","      <th>Fat</th>\n","      <th>Carbohydrate</th>\n","      <th>Energy (kcal)</th>\n","      <th>Energy (kJ)</th>\n","      <th>Alcohol</th>\n","      <th>...</th>\n","      <th>tsrd</th>\n","      <th>vfa-(visceral-fat-area)</th>\n","      <th>vfl-(visceral-fat-level)</th>\n","      <th>vlf(ln)</th>\n","      <th>wc(waist-circumference)</th>\n","      <th>weight-control</th>\n","      <th>weight</th>\n","      <th>whr-(waist-hip-ratio)</th>\n","      <th>whtr(waist-height-ratio)</th>\n","      <th>xc/ht</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.042857</td>\n","      <td>102.656000</td>\n","      <td>0.829000</td>\n","      <td>8.373000</td>\n","      <td>5.116143</td>\n","      <td>6.101714</td>\n","      <td>15.307286</td>\n","      <td>143.255286</td>\n","      <td>600.649571</td>\n","      <td>1.497714</td>\n","      <td>...</td>\n","      <td>92.732</td>\n","      <td>256.4</td>\n","      <td>25.0</td>\n","      <td>3.166</td>\n","      <td>125.7</td>\n","      <td>-35.8</td>\n","      <td>98.0</td>\n","      <td>1.10</td>\n","      <td>0.81</td>\n","      <td>28.7</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.000000</td>\n","      <td>231.611774</td>\n","      <td>0.996935</td>\n","      <td>16.928871</td>\n","      <td>5.831290</td>\n","      <td>8.712258</td>\n","      <td>14.135968</td>\n","      <td>197.995968</td>\n","      <td>825.781290</td>\n","      <td>6.142419</td>\n","      <td>...</td>\n","      <td>114.645</td>\n","      <td>258.6</td>\n","      <td>25.0</td>\n","      <td>3.530</td>\n","      <td>126.2</td>\n","      <td>-36.4</td>\n","      <td>98.2</td>\n","      <td>1.10</td>\n","      <td>0.81</td>\n","      <td>30.4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.047619</td>\n","      <td>358.191429</td>\n","      <td>1.680714</td>\n","      <td>25.690952</td>\n","      <td>9.915952</td>\n","      <td>6.922381</td>\n","      <td>20.247619</td>\n","      <td>237.025238</td>\n","      <td>990.075952</td>\n","      <td>8.342619</td>\n","      <td>...</td>\n","      <td>107.710</td>\n","      <td>261.0</td>\n","      <td>26.0</td>\n","      <td>3.915</td>\n","      <td>127.7</td>\n","      <td>-36.4</td>\n","      <td>97.5</td>\n","      <td>1.12</td>\n","      <td>0.82</td>\n","      <td>31.5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3 rows × 200 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e32eaab7-2818-4236-8c58-81e8a507f903')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e32eaab7-2818-4236-8c58-81e8a507f903 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e32eaab7-2818-4236-8c58-81e8a507f903');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-1d466881-92eb-465c-a93e-6829346b020a\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1d466881-92eb-465c-a93e-6829346b020a')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-1d466881-92eb-465c-a93e-6829346b020a button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_28e92e41-54f6-40ba-95d5-d25838b64366\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X_clean')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_28e92e41-54f6-40ba-95d5-d25838b64366 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('X_clean');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"X_clean"}},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"4vvZyiDLvCPX"},"source":["## Test Dynotear\n","\n","For more info, see repo [Nutrition Data Analysis.](https://colab.research.google.com/drive/1gv0SC2TzPHBh5JNhUOlJtiwSkv2cwR3U#scrollTo=MMj_erhzzhLK)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2318,"status":"ok","timestamp":1747054933094,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"},"user_tz":-120},"id":"cWpiqUme_4y8","outputId":"55a4a12b-fe78-437d-95c8-2e3e00465e36"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pgmpy in /usr/local/lib/python3.11/dist-packages (0.1.25)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pgmpy) (3.4.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pgmpy) (1.23.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pgmpy) (1.11.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from pgmpy) (1.6.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from pgmpy) (2.2.2)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from pgmpy) (3.2.3)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from pgmpy) (2.6.0+cu124)\n","Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from pgmpy) (0.14.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from pgmpy) (4.67.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from pgmpy) (1.4.2)\n","Requirement already satisfied: opt-einsum in /usr/local/lib/python3.11/dist-packages (from pgmpy) (3.4.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->pgmpy) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->pgmpy) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->pgmpy) (2025.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pgmpy) (3.6.0)\n","Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->pgmpy) (1.0.1)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels->pgmpy) (24.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (4.13.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->pgmpy) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->pgmpy) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->pgmpy) (3.0.2)\n"]}],"source":["!pip install pgmpy"]},{"cell_type":"code","source":["sm, w_est, a_est = from_pandas_dynamic(X_clean, p=1)\n","output = []\n","for u, v, d in sm.edges(data=True):\n","    print(f\"\\nEdges of patient_{patient_id}:{u} -> {v}, weight={d.get('weight')}\")\n","    output.append([patient_id, u, v, d.get('weight')])\n","edges_df = pd.DataFrame(output, columns=[\"patient\",\"source\", \"target\", \"weight\"])\n","edges_df.to_csv(f\"./Codiet-{patient_id}-Result/ExDBN.csv\", index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"WxTKDDdlrAgQ","executionInfo":{"status":"error","timestamp":1747056646990,"user_tz":-120,"elapsed":292406,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"}},"outputId":"e5508807-800b-4ea9-b479-87662f28f081"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-58-8c30854ba272>\", line 1, in <cell line: 0>\n","    sm, w_est, a_est = from_pandas_dynamic(X_clean, p=1)\n","                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-34-fb8cfb461104>\", line 112, in from_pandas_dynamic\n","    g, w_est, a_est = from_numpy_dynamic(\n","                      ^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-34-fb8cfb461104>\", line 245, in from_numpy_dynamic\n","    w_est, a_est = _learn_dynamic_structure(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-34-fb8cfb461104>\", line 474, in _learn_dynamic_structure\n","    wa_new = sopt.minimize(\n","             ^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n","    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/scipy/optimize/_lbfgsb_py.py\", line 365, in _minimize_lbfgsb\n","    f, g = func_and_grad(x)\n","           ^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/scipy/optimize/_differentiable_functions.py\", line 286, in fun_and_grad\n","    self._update_grad()\n","  File \"/usr/local/lib/python3.11/dist-packages/scipy/optimize/_differentiable_functions.py\", line 256, in _update_grad\n","    self._update_grad_impl()\n","  File \"/usr/local/lib/python3.11/dist-packages/scipy/optimize/_differentiable_functions.py\", line 167, in update_grad\n","    self.g = grad_wrapped(self.x)\n","             ^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/scipy/optimize/_differentiable_functions.py\", line 164, in grad_wrapped\n","    return np.atleast_1d(grad(np.copy(x), *args))\n","                         ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-34-fb8cfb461104>\", line 460, in _grad\n","    ).flatten() + lambda_w * np.ones(2 * d_vars**2)\n","      ^^^^^^^^^\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","          ^^^^^^^^^^^^^^^^^^^^^^^^\n","AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n","    traceback_info = getframeinfo(tb, context)\n","                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/inspect.py\", line 1688, in getframeinfo\n","    lines, lnum = findsource(frame)\n","                  ^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 170, in findsource\n","    file = getsourcefile(object) or getfile(object)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/inspect.py\", line 948, in getsourcefile\n","    module = getmodule(object, filename)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/inspect.py\", line 988, in getmodule\n","    if ismodule(module) and hasattr(module, '__file__'):\n","                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","KeyboardInterrupt\n"]},{"output_type":"error","ename":"TypeError","evalue":"object of type 'NoneType' has no len()","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m<ipython-input-58-8c30854ba272>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_est\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_est\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_pandas_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_clean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-34-fb8cfb461104>\u001b[0m in \u001b[0;36mfrom_pandas_dynamic\u001b[0;34m(time_series, p, lambda_w, lambda_a, max_iter, h_tol, w_threshold, tabu_edges, tabu_parent_nodes, tabu_child_nodes)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     g, w_est, a_est = from_numpy_dynamic(\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-34-fb8cfb461104>\u001b[0m in \u001b[0;36mfrom_numpy_dynamic\u001b[0;34m(X, Xlags, lambda_w, lambda_a, max_iter, h_tol, w_threshold, tabu_edges, tabu_parent_nodes, tabu_child_nodes)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0mbnds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbnds_w\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbnds_a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m     w_est, a_est = _learn_dynamic_structure(\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXlags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbnds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_tol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-34-fb8cfb461104>\u001b[0m in \u001b[0;36m_learn_dynamic_structure\u001b[0;34m(X, Xlags, bnds, lambda_w, lambda_a, max_iter, h_tol)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrho\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e20\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh_new\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.25\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh_value\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mh_new\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m             wa_new = sopt.minimize(\n\u001b[0m\u001b[1;32m    475\u001b[0m                 \u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwa_est\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L-BFGS-B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbnds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    709\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m         res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    711\u001b[0m                                callback=callback, **options)\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_lbfgsb_py.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_grad\u001b[0;34m()\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mupdate_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mgrad_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-34-fb8cfb461104>\u001b[0m in \u001b[0;36m_grad\u001b[0;34m(wa_vec)\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0mobj_grad_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mobj_grad_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         ).flatten() + lambda_w * np.ones(2 * d_vars**2)\n\u001b[0m\u001b[1;32m    461\u001b[0m         \u001b[0mgrad_vec_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_grad_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_orders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_vars\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"]}]},{"cell_type":"code","source":["n_patients = test_data['patient'].unique()\n","\n","for patient_id in n_patients:\n","    patient_data = test_data[test_data['patient']==patient_id]\n","    patient_data = patient_data.drop(columns='patient')\n","    stds = np.std(patient_data, axis=0)\n","    X_clean = patient_data.loc[:, stds != 0]\n","X_clean\n","\n","import pandas as pd\n","import networkx as nx\n","\n","n_patients = test_data['patient'].unique()\n","# print(n_patients)\n","edges_data = []\n","sm1 = nx.DiGraph()\n","\n","for patient_id in n_patients:\n","    patient_data = test_data[test_data['patient']==patient_id]\n","    patient_data = patient_data.drop(columns='patient')\n","    stds = np.std(patient_data, axis=0)\n","    patient_X = patient_data.loc[:, stds != 0]\n","    # Check if patient_data is empty and has enough rows for analysis\n","    if patient_X.empty or len(patient_X) < 3: # At least 2 rows are needed for lagged data\n","        print(f\"Skipping patient_{patient_id} due to empty or insufficient data.\")\n","        continue  # Skip to the next patient\n","    else:\n","        print(f\"\\nEdges of patient_{patient_id}:\")\n","        sm, w_est, a_est = from_pandas_dynamic(patient_X, p=1)\n","        sm1.add_nodes_from(sm.nodes)\n","        print(f\"\\nEdges of patient_{patient_id}:\")\n","        for u, v, d in sm.edges(data=True):\n","            if sm1.has_edge(u, v):\n","                sm1[u][v][\"weight\"] += d.get('weight', 0.0)  # 权重累加\n","            else:\n","                # Change here: Add only the 'weight' value as the edge weight\n","                sm1.add_edge(u, v, weight=d.get('weight', 0.0))\n","\n","            print(f\"{u} -> {v}, weight={d.get('weight')}\")\n","            edge_data = {\n","                'source': u,\n","                'target': v,\n","                'weight': d.get('weight', 0)  # 获取权重，如果没有则默认为0\n","            }\n","            edges_data.append(edge_data)\n","\n","edges_df = pd.DataFrame(edges_data)\n","sm1\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"zLPFJ44_e0g4","executionInfo":{"status":"error","timestamp":1747055275283,"user_tz":-120,"elapsed":132304,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"}},"outputId":"2aabc71f-0302-4f45-8860-9b3da5718066"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Edges of patient_CD-003:\n"]},{"output_type":"stream","name":"stderr","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-46-d4aa982c66ad>\", line 29, in <cell line: 0>\n","    sm, w_est, a_est = from_pandas_dynamic(patient_X, p=1)\n","                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-34-fb8cfb461104>\", line 112, in from_pandas_dynamic\n","    g, w_est, a_est = from_numpy_dynamic(\n","                      ^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-34-fb8cfb461104>\", line 245, in from_numpy_dynamic\n","    w_est, a_est = _learn_dynamic_structure(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-34-fb8cfb461104>\", line 474, in _learn_dynamic_structure\n","    wa_new = sopt.minimize(\n","             ^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n","    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/scipy/optimize/_lbfgsb_py.py\", line 356, in _minimize_lbfgsb\n","    _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr,\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","          ^^^^^^^^^^^^^^^^^^^^^^^^\n","AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n","    traceback_info = getframeinfo(tb, context)\n","                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/inspect.py\", line 1688, in getframeinfo\n","    lines, lnum = findsource(frame)\n","                  ^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 170, in findsource\n","    file = getsourcefile(object) or getfile(object)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/inspect.py\", line 948, in getsourcefile\n","    module = getmodule(object, filename)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/inspect.py\", line 988, in getmodule\n","    if ismodule(module) and hasattr(module, '__file__'):\n","                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","KeyboardInterrupt\n"]},{"output_type":"error","ename":"TypeError","evalue":"object of type 'NoneType' has no len()","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m<ipython-input-46-d4aa982c66ad>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nEdges of patient_{patient_id}:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0msm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_est\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_est\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_pandas_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0msm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_nodes_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-34-fb8cfb461104>\u001b[0m in \u001b[0;36mfrom_pandas_dynamic\u001b[0;34m(time_series, p, lambda_w, lambda_a, max_iter, h_tol, w_threshold, tabu_edges, tabu_parent_nodes, tabu_child_nodes)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     g, w_est, a_est = from_numpy_dynamic(\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-34-fb8cfb461104>\u001b[0m in \u001b[0;36mfrom_numpy_dynamic\u001b[0;34m(X, Xlags, lambda_w, lambda_a, max_iter, h_tol, w_threshold, tabu_edges, tabu_parent_nodes, tabu_child_nodes)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0mbnds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbnds_w\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbnds_a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m     w_est, a_est = _learn_dynamic_structure(\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXlags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbnds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_tol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-34-fb8cfb461104>\u001b[0m in \u001b[0;36m_learn_dynamic_structure\u001b[0;34m(X, Xlags, bnds, lambda_w, lambda_a, max_iter, h_tol)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrho\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e20\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh_new\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.25\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh_value\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mh_new\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m             wa_new = sopt.minimize(\n\u001b[0m\u001b[1;32m    475\u001b[0m                 \u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwa_est\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L-BFGS-B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbnds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    709\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m         res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    711\u001b[0m                                callback=callback, **options)\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_lbfgsb_py.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;31m# x, f, g, wa, iwa, task, csave, lsave, isave, dsave = \\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr,\n\u001b[0m\u001b[1;32m    357\u001b[0m                        \u001b[0mpgtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miwa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsave\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsave\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"_vCsbFMvDpVf","executionInfo":{"status":"error","timestamp":1747055863570,"user_tz":-120,"elapsed":458191,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"}},"outputId":"452f899b-e973-43e2-9f21-840bdee69fb8"},"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-53-bff71bce500b>\", line 17, in <cell line: 0>\n","    sm, w_est, a_est = from_pandas_dynamic(patient_X, p=1)\n","                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-34-fb8cfb461104>\", line 112, in from_pandas_dynamic\n","    g, w_est, a_est = from_numpy_dynamic(\n","                      ^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-34-fb8cfb461104>\", line 245, in from_numpy_dynamic\n","    w_est, a_est = _learn_dynamic_structure(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-34-fb8cfb461104>\", line 474, in _learn_dynamic_structure\n","    wa_new = sopt.minimize(\n","             ^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n","    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/scipy/optimize/_lbfgsb_py.py\", line 365, in _minimize_lbfgsb\n","    f, g = func_and_grad(x)\n","           ^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n","    self._update_fun()\n","  File \"/usr/local/lib/python3.11/dist-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n","    self._update_fun_impl()\n","  File \"/usr/local/lib/python3.11/dist-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n","    self.f = fun_wrapped(self.x)\n","             ^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n","    fx = fun(np.copy(x), *args)\n","         ^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-34-fb8cfb461104>\", line 424, in _func\n","    _h_value = _h(wa_vec)\n","               ^^^^^^^^^^\n","  File \"<ipython-input-34-fb8cfb461104>\", line 401, in _h\n","    return np.trace(slin.expm(_w_mat * _w_mat)) - d_vars\n","                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/scipy/linalg/_matfuncs.py\", line 350, in expm\n","    pade_UV_calc(Am, n, m)\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","          ^^^^^^^^^^^^^^^^^^^^^^^^\n","AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n","    traceback_info = getframeinfo(tb, context)\n","                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/inspect.py\", line 1688, in getframeinfo\n","    lines, lnum = findsource(frame)\n","                  ^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 170, in findsource\n","    file = getsourcefile(object) or getfile(object)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/inspect.py\", line 948, in getsourcefile\n","    module = getmodule(object, filename)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/inspect.py\", line 992, in getmodule\n","    continue\n","KeyboardInterrupt\n"]},{"output_type":"error","ename":"TypeError","evalue":"object of type 'NoneType' has no len()","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m<ipython-input-53-bff71bce500b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0msm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_est\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_est\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_pandas_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nEdges of patient_{patient_id}:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-34-fb8cfb461104>\u001b[0m in \u001b[0;36mfrom_pandas_dynamic\u001b[0;34m(time_series, p, lambda_w, lambda_a, max_iter, h_tol, w_threshold, tabu_edges, tabu_parent_nodes, tabu_child_nodes)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     g, w_est, a_est = from_numpy_dynamic(\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-34-fb8cfb461104>\u001b[0m in \u001b[0;36mfrom_numpy_dynamic\u001b[0;34m(X, Xlags, lambda_w, lambda_a, max_iter, h_tol, w_threshold, tabu_edges, tabu_parent_nodes, tabu_child_nodes)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0mbnds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbnds_w\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbnds_a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m     w_est, a_est = _learn_dynamic_structure(\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXlags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbnds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_tol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-34-fb8cfb461104>\u001b[0m in \u001b[0;36m_learn_dynamic_structure\u001b[0;34m(X, Xlags, bnds, lambda_w, lambda_a, max_iter, h_tol)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrho\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e20\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh_new\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.25\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh_value\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mh_new\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m             wa_new = sopt.minimize(\n\u001b[0m\u001b[1;32m    475\u001b[0m                 \u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwa_est\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L-BFGS-B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbnds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    709\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m         res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    711\u001b[0m                                callback=callback, **options)\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_lbfgsb_py.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mfx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0;31m# Make sure the function returns a true scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-34-fb8cfb461104>\u001b[0m in \u001b[0;36m_func\u001b[0;34m(wa_vec)\u001b[0m\n\u001b[1;32m    423\u001b[0m         )\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0m_h_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_h\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwa_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         l1_penalty = lambda_w * (wa_vec[: 2 * d_vars**2].sum()) + lambda_a * (\n","\u001b[0;32m<ipython-input-34-fb8cfb461104>\u001b[0m in \u001b[0;36m_h\u001b[0;34m(wa_vec)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0m_w_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reshape_wa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwa_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_orders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_w_mat\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0m_w_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0md_vars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/linalg/_matfuncs.py\u001b[0m in \u001b[0;36mexpm\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mpade_UV_calc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0meAw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"]}],"source":["import pandas as pd\n","\n","n_patients = test_data['patient'].unique()\n","# print(n_patients)\n","output = []\n","for patient_id in n_patients:\n","    if int(patient_id.split('-')[1]) >= 0:\n","        patient_data = test_data[test_data['patient']==patient_id]\n","        patient_data = patient_data.drop(columns='patient')\n","        stds = np.std(patient_data, axis=0)\n","        patient_X = patient_data.loc[:, stds != 0]\n","        # Check if patient_X is empty and has enough rows for analysis\n","        if patient_X.empty or len(patient_X) < 2: # At least 2 rows are needed for lagged data\n","            print(f\"Skipping patient_{patient_id} due to empty or insufficient data.\")\n","            continue  # Skip to the next patient\n","        else:\n","            sm, w_est, a_est = from_pandas_dynamic(patient_X, p=1)\n","            print(f\"\\nEdges of patient_{patient_id}:\")\n","            for u, v, d in sm.edges(data=True):\n","                print(f\"\\nEdges of patient_{patient_id}:{u} -> {v}, weight={d.get('weight')}\")\n","                output.append([patient_id, u, v, d.get('weight')])\n","            edges_df = pd.DataFrame(output, columns=[\"patient\",\"source\", \"target\", \"weight\"])\n","            edges_df.to_csv(f\"./ExDBN-Codiet-Result/{patient_id}.csv\", index=False)\n","\n","output"]},{"cell_type":"markdown","source":["## Test lingam"],"metadata":{"id":"k0wqw8X-m8zX"}},{"cell_type":"code","source":["import numpy as np\n","from lingam import VARLiNGAM\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import StandardScaler\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n","\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X_clean)\n","\n","def solve_lingam(X, Y, p):\n","    import lingam\n","    model = lingam.VARLiNGAM(lags=p, criterion=None)\n","    model.fit(X)\n","\n","    W_est = model._adjacency_matrices[0]  # 当前时刻结构\n","    print(f'NUMBER OF ADJ MATRICES: {len(model._adjacency_matrices)}. DATA RECURSION: {p}')\n","\n","    A_est = []\n","    for i in range(p):\n","        A_est.append(model._adjacency_matrices[i + 1])  # 第1~p时刻的结构（滞后）\n","    return W_est, A_est\n","\n","W_est, A_est = solve_lingam(X_clean, Y=None, p=1)\n","\n","print(\"W_est (instantaneous):\")\n","print(W_est)\n","print(\"\\nA_est (lagged):\")\n","for i, A in enumerate(A_est):\n","    print(f\"Lag {i+1}:\")\n","    print(A)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"62zzPAGQm88v","executionInfo":{"status":"error","timestamp":1747061470962,"user_tz":-120,"elapsed":6104,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"}},"outputId":"04c9e9b0-bec7-4523-b555-f5ca389c5ca6"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-92-bf44a6e99801>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mW_est\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_est\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mW_est\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_est\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolve_lingam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_clean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W_est (instantaneous):\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-92-bf44a6e99801>\u001b[0m in \u001b[0;36msolve_lingam\u001b[0;34m(X, Y, p)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mlingam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlingam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVARLiNGAM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mW_est\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adjacency_matrices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# 当前时刻结构\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lingam/var_lingam.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlingam_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresiduals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mB_taus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calc_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjacency_matrix_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM_taus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lingam/direct_lingam.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_search_causal_order_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                 \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_search_causal_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lingam/direct_lingam.py\u001b[0m in \u001b[0;36m_search_causal_order\u001b[0;34m(self, X, U)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                     \u001b[0mxi_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                     \u001b[0mxj_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                     ri_j = (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3503\u001b[0m     \u001b[0mNotes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3504\u001b[0;31m     \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3505\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0mstandard\u001b[0m \u001b[0mdeviation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msquare\u001b[0m \u001b[0mroot\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0maverage\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3506\u001b[0m     \u001b[0mdeviations\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_clip_dep_is_byte_swapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["## Test IP-ADMG"],"metadata":{"id":"gAZblUcP0Gjl"}},{"cell_type":"code","source":[],"metadata":{"id":"Q0jtet2i0F3B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Save results"],"metadata":{"id":"6CBxp4zycfQ6"}},{"cell_type":"code","source":["import glob\n","import os\n","import pandas as pd\n","\n","folder_path = \"./cliquewidth/ExDAG-ExDBN-ExMAG/Pavel-GitLab//ExDBN-Codiet-Result/\"\n","csv_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n","print(f'{len(csv_files)} files found')\n","dfs = []\n","for file in csv_files:\n","    df = pd.read_csv(file)\n","    dfs.append(df)\n","edges = pd.concat(dfs, ignore_index=True)\n","edges.to_csv('./data/Nutrition-Results/ExDBN_edges.csv', sep=';', index=False)\n"],"metadata":{"id":"H143fu5wb5gQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Nutritional_Target\tRisk_Factor User_Count\n","edges['source'] = edges['source'].apply(lambda x: x.split('_')[0])  # 提取'_'前的部分\n","edges['target'] = edges['target'].apply(lambda x: x.split('_')[0])\n","# 示例边结构：edge = {'source': 'A', 'target': 'B', 'weight': -0.3}\n","nutritional_mapping = {\n","    'Cholesterol Fat': ['Cholesterol'],\n","    'Fat': ['Fat', 'Satd FA', 'Cis-Mon FA', 'Cis-n3 FA', 'Cis-n6 FA', 'Trans FA'],\n","    'FV': ['Tomatoes', 'Tomato puree', 'Brassicaceae', 'Yellow Red Green', 'Beans', 'Other Vegetables', 'Vegetable Puree', 'FS Vegetable Puree', 'Fruit', 'Vegetables'],\n","    'Sugar/SSBs': ['Total sugars', 'Non-milk extrinsic sugars', 'Intrinsic and milk sugars', 'Glucose',\n","                'Fructose', 'Maltose', 'Lactose', 'Sucrose', 'Other sugars (UK)', 'FS Table sugar',\n","                'FS Other Added Sugar', 'FS Honey', 'FS Fruit Juice', 'Fruit Juice', 'FS Dried Fruit',\n","                'FS Fruit Puree', 'FS Stewed Fruit'],\n","    'Red/processed meat': ['Processed Red Meat', 'Beef', 'Lamb', 'Pork', 'Other Red Meat', 'Burgers',\n","                  'Sausages', 'Offal', 'Processed Poultry', 'Ham'],\n","    'Salt/sodium': ['Sodium', 'Chloride'],\n","    'Vitamins': ['Vitamin A', 'Retinol', 'Total carotene', 'Alpha-carotene', 'Beta-carotene',\n","                'Beta cryptoxanthin', 'Vitamin C', 'Vitamin D', 'Vitamin E', 'Thiamin',\n","                'Riboflavin', 'Niacin', 'Vitamin B6', 'Vitamin B12', 'Folate',\n","                'Pantothenic acid', 'Biotin', 'Niacin equivalent'],\n","    'Minerals': ['Potassium', 'Magnesium', 'Phosphorus', 'Calcium', 'Iron',\n","                'Haem iron', 'Non-haem iron', 'Zinc', 'Copper', 'Iodine',\n","                'Selenium', 'Manganese', 'Chloride'],\n","    'Amino Acids / Protein Quality': ['Protein', 'Total nitrogen', 'Nitrogen conversion factor', 'Tryptophan/60'],\n","    'Energy & Macronutrients': ['Energy (kcal)', 'Energy (kJ)', 'Fat', 'Protein', 'Carbohydrate', 'Alcohol'],\n","    'Fibre': ['Englyst fibre', 'AOAC'],\n","}\n","\n","# Map to intermediate risk factors\n","risk_mapping = {\n","    'Body Composition': ['age-value', 'height', 'age', 'weight', 'lower-limit-(weight-normal-range)', 'upper-limit-(weight-normal-range)', 'icw-(intracellular-water)', 'lower-limit-(icw-normal-range)', 'upper-limit-(icw-normal-range)', 'slm-(soft-lean-mass)', 'lower-limit-(slm-normal-range)', 'upper-limit-(slm-normal-range)', 'ffm-(fat-free-mass)', 'lower-limit-(ffm-normal-range)', 'upper-limit-(ffm-normal-range)', 'smm-(skeletal-muscle-mass)', 'lower-limit-(smm-normal-range)', 'upper-limit-(smm-normal-range)', 'bmi-(body-mass-index)', 'lower-limit-(bmi-normal-range)', 'upper-limit-(bmi-normal-range)', 'lean-mass-of-right-arm', 'lower-limit-(lean-mass-of-right-arm-normal-range)', 'upper-limit-(lean-mass-of-right-arm-normal-range)', 'lean-mass(%)-of-right-arm', 'lean-mass-of-left-arm', 'lower-limit-(lean-mass-of-left-arm-normal-range)', 'upper-limit-(lean-mass-of-left-arm-normal-range)', 'lean-mass(%)-of-left-arm', 'lean-mass-of-trunk', 'lower-limit-(lean-mass-of-trunk-normal-range)', 'upper-limit-(lean-mass-of-trunk-normal-range)', 'lean-mass(%)-of-trunk', 'lean-mass-of-right-leg', 'lower-limit-(lean-mass-of-right-leg-normal-range)', 'upper-limit-(lean-mass-of-right-leg-normal-range)', 'lean-mass(%)-of-right-leg', 'lean-mass-of-left-leg', 'lower-limit-(lean-mass-of-left-leg-normal-range)', 'upper-limit-(lean-mass-of-left-leg-normal-range)', 'lean-mass(%)-of-left-leg', 'icw-of-right-arm', 'lower-limit-(icw-of-right-arm-normal-range)', 'upper-limit-(icw-of-right-arm-normal-range)', 'icw-of-left-arm', 'lower-limit-(icw-of-left-arm-normal-range)', 'upper-limit-(icw-of-left-arm-normal-range)', 'icw-of-trunk', 'lower-limit-(icw-of-trunk-normal-range)', 'upper-limit-(icw-of-trunk-normal-range)', 'icw-of-right-leg', 'lower-limit-(icw-of-right-leg-normal-range)', 'upper-limit-(icw-of-right-leg-normal-range)', 'icw-of-left-leg', 'lower-limit-(icw-of-left-leg-normal-range)', 'upper-limit-(icw-of-left-leg-normal-range)', 'ecw/tbw', 'ecw/tbw-of-right-arm', 'ecw/tbw-of-left-arm', 'ecw/tbw-of-trunk', 'ecw/tbw-of-right-leg', 'ecw/tbw-of-left-leg', 'inbody-score', 'target-weight', 'weight-control', 'ffm-control', 'bcm-(body-cell-mass)', 'lower-limit-(bcm-normal-range)', 'upper-limit-(bcm-normal-range)', 'bmc-(bone-mineral-content)', 'lower-limit-(bmc-normal-range)', 'upper-limit-(bmc-normal-range)', 'tbw/ffm', 'ffmi-(fat-free-mass-index)', 'inbody-type', 'whole-body-ecw/tbw-t-score', 'whole-body-ecw/tbw-z-score', 'bmi-t-score', 'bmi-z-score', 'whtr(waist-height-ratio)', 'smm/wt', 'ecm/bcm', 'tbw/wt', 'bcm-t-score', 'bcm-z-score', 'ffmi-t-score', 'ffmi-z-score', 'weight-t-score', 'weight-z-score', 'tbw/wt-t-score', 'tbw/wt-z-score', 'smm/wt-t-score', 'smm/wt-z-score', 'ecm/bcm-t-score', 'ecm/bcm-z-score'],\n","    'Obesity': ['wave-type', 'pe', 'pe-status', 'fatigue-index', 'fatigue-index-status', 'apen', 'upper-limit-(weight-normal-range)', 'upper-limit-(tbw-normal-range)', 'upper-limit-(icw-normal-range)', 'upper-limit-(ecw-normal-range)', 'upper-limit-(protein-normal-range)', 'upper-limit-(minerals-normal-range)', 'bfm-(body-fat-mass)', 'lower-limit-(bfm-normal-range)', 'upper-limit-(bfm-normal-range)', 'upper-limit-(slm-normal-range)', 'ffm-(fat-free-mass)', 'upper-limit-(ffm-normal-range)', 'upper-limit-(smm-normal-range)', 'upper-limit-(bmi-normal-range)', 'pbf-(percent-body-fat)', 'upper-limit-(pbf-normal-range)', 'upper-limit-(lean-mass-of-right-arm-normal-range)', 'upper-limit-(lean-mass-of-left-arm-normal-range)', 'upper-limit-(lean-mass-of-trunk-normal-range)', 'upper-limit-(lean-mass-of-right-leg-normal-range)', 'upper-limit-(lean-mass-of-left-leg-normal-range)', 'upper-limit-(tbw-of-right-arm-normal-range)', 'upper-limit-(tbw-of-left-arm-normal-range)', 'upper-limit-(tbw-of-trunk-normal-range)', 'upper-limit-(tbw-of-right-leg-normal-range)', 'upper-limit-(tbw-of-left-leg-normal-range)', 'upper-limit-(icw-of-right-arm-normal-range)', 'upper-limit-(icw-of-left-arm-normal-range)', 'upper-limit-(icw-of-trunk-normal-range)', 'upper-limit-(icw-of-right-leg-normal-range)', 'upper-limit-(icw-of-left-leg-normal-range)', 'upper-limit-(ecw-of-right-arm-normal-range)', 'upper-limit-(ecw-of-left-arm-normal-range)', 'upper-limit-(ecw-of-trunk-normal-range)', 'upper-limit-(ecw-of-right-leg-normal-range)', 'upper-limit-(ecw-of-left-leg-normal-range)', 'bfm-of-right-arm', 'bfm%-of-right-arm', 'bfm-of-left-arm', 'bfm%-of-left-arm', 'bfm-of-trunk', 'bfm%-of-trunk', 'bfm-of-right-leg', 'bfm%-of-right-leg', 'bfm-of-left-leg', 'bfm%-of-left-leg', 'bfm-control', 'upper-limit-(whr-normal-range)', 'vfl-(visceral-fat-level)', 'vfa-(visceral-fat-area)', 'obesity-degree', 'lower-limit-(obesity-degree-normal-range)', 'upper-limit-(obesity-degree-normal-range)', 'upper-limit-(bcm-normal-range)', 'upper-limit-(bmc-normal-range)', 'ffmi-(fat-free-mass-index)', 'fmi-(fat-mass-index)', 'inbody-type', 'upper-limit-(bmr-normal-range)', 'vfa-t-score', 'vfa-z-score', 'arms/legs-fat', 'sfa-ll(subcutaneous-fat-of-abdomen-llimit)', 'sfa-ul(subcutaneous-fat-of-abdomen-ulimit)', 'lower-limit-(visceral-fat-of-abdomen-normal-range)', 'upper-limit-(visceral-fat-of-abdomen-normal-range)', 'lower-limit-(bfm-of-arm-&-leg-normal-range)', 'upper-limit-(bfm-of-arm-&-leg-normal-range)', 'lower-limit-(bfm-of-trunk-normal-range)', 'upper-limit-(bfm-of-trunk-normal-range)', 'bai(body-adiposity-index)', 'absi(a-body-shaped-index)', 'svr(skeletal-muscle-mass-visceral-fat-area-ratio)', 'upper-limit-(whtr-normal-range)', 'upper-limit-(bai-normal-range)', 'upper-limit-(absi-normal-range)', 'upper-limit-(conicity-index-normal-range)', 'upper-limit-(svr-normal-range)', 'af-ll(abdominal-fat-llimit)', 'af-ul(abdominal-fat-ulimit)', 'bfm%-of-whole-body', 'bfm-of-arm-&-leg'],\n","    'Health and Risk Factors': ['ai', 'ai-status', 'apgcomment', 'hf', 'hfnorm', 'lf/hf', 'hf(ln)', 'ddrcomment', 'protein', 'lower-limit-(protein-normal-range)', 'upper-limit-(protein-normal-range)', 'minerals', 'lower-limit-(minerals-normal-range)', 'upper-limit-(minerals-normal-range)', 'whr-(waist-hip-ratio)', 'local-id', 'whtr(waist-height-ratio)', 'bai(body-adiposity-index)', 'upper-limit-(bai-normal-range)', 'wc(waist-circumference)\\xa0'],\n","    'Metabolism and Energy': ['ae', 'ae-status', 'weight', 'lower-limit-(weight-normal-range)', 'upper-limit-(weight-normal-range)', 'protein', 'lower-limit-(protein-normal-range)', 'upper-limit-(protein-normal-range)', 'target-weight', 'weight-control', 'bmr-(basal-metabolic-rate)', 'recommended-calorie-intake', 'lower-limit-(bmr-normal-range)', 'upper-limit-(bmr-normal-range)', 'weight-t-score', 'weight-z-score'],\n","    'Heart': ['hr', 'hr-status', 'mean-hrt', 'mean-hrt-status', 'electro-cardiac-stability', 'electro-cardiac-stability-status', 'ectopic-beat', 'sdnn', 'psi', 'tp', 'vlf', 'lf', 'lfnorm', 'lf/hf', 'rmssd', 'apen', 'tp(ln)', 'vlf(ln)', 'lf(ln)', 'whr-(waist-hip-ratio)', 'lower-limit-(whr-normal-range)', 'upper-limit-(whr-normal-range)', 'khz-ra-5-phase-angle', 'khz-la-5-phase-angle', 'khz-tr-5-phase-angle', 'khz-rl-5-phase-angle', 'khz-ll-5-phase-angle', 'khz-ra-50-phase-angle', 'khz-la-50-phase-angle', 'khz-tr-50-phase-angle', 'khz-rl-50-phase-angle', 'khz-ll-50-phase-angle', 'khz-ra-250-phase-angle', 'khz-la-250-phase-angle', 'khz-tr-250-phase-angle', 'khz-rl-250-phase-angle', 'khz-ll-250-phase-angle', 'khz-50-whole-body-phase-angle', 'whr-t-score', 'whr-z-score', 'khz-whole-body-phase-angle-t-score', 'khz-whole-body-phase-angle-z-score'],\n","    'Body Measurement': ['ans-activity', 'ans-activity-status', 'electro-cardiac-stability', 'electro-cardiac-stability-status', 'icw-(intracellular-water)', 'ecw-(extracellular-water)', 'whr-(waist-hip-ratio)', 'lower-limit-(whr-normal-range)', 'upper-limit-(whr-normal-range)', 'ac-(arm-circumference)', 'amc-(arm-muscle-circumference)', 'measured-circumference-of-neck', 'measured-circumference-of-chest', 'measured-circumference-of-abdomen', 'measured-circumference-of-hip', 'measured-circumference-of-right-arm', 'measured-circumference-of-left-arm', 'measured-circumference-of-right-thigh', 'measured-circumference-of-left-thigh', 'whtr(waist-height-ratio)', 'absi(a-body-shaped-index)', 'upper-limit-(whtr-normal-range)', 'upper-limit-(absi-normal-range)', 'whr-t-score', 'whr-z-score', 'r/ht', 'xc/ht'],\n","    'Mental Health': ['ans-activity', 'ans-activity-status', 'ans-balance', 'ans-balance-status', 'stress-resilience', 'stress-resilience-status', 'stress-index', 'stress-index-status', 'fatigue-index', 'fatigue-index-status', 'mean-hrt', 'mean-hrt-status', 'sdnn', 'lf/hf', 'rmssd', 'srd', 'tsrd', 'bmr-(basal-metabolic-rate)', 'lower-limit-(bmr-normal-range)', 'upper-limit-(bmr-normal-range)'],\n","    'Stomach': ['stress-resilience', 'stress-resilience-status', 'stress-index', 'stress-index-status', 'fatigue-index', 'fatigue-index-status', 'recommended-calorie-intake'],\n","    'Water and Hydration': ['tbw-(total-body-water)', 'lower-limit-(tbw-normal-range)', 'upper-limit-(tbw-normal-range)', 'icw-(intracellular-water)', 'lower-limit-(icw-normal-range)', 'upper-limit-(icw-normal-range)', 'ecw-(extracellular-water)', 'lower-limit-(ecw-normal-range)', 'upper-limit-(ecw-normal-range)', 'tbw-of-right-arm', 'lower-limit-(tbw-of-right-arm-normal-range)', 'upper-limit-(tbw-of-right-arm-normal-range)', 'tbw-of-left-arm', 'lower-limit-(tbw-of-left-arm-normal-range)', 'upper-limit-(tbw-of-left-arm-normal-range)', 'tbw-of-trunk', 'lower-limit-(tbw-of-trunk-normal-range)', 'upper-limit-(tbw-of-trunk-normal-range)', 'tbw-of-right-leg', 'lower-limit-(tbw-of-right-leg-normal-range)', 'upper-limit-(tbw-of-right-leg-normal-range)', 'tbw-of-left-leg', 'lower-limit-(tbw-of-left-leg-normal-range)', 'upper-limit-(tbw-of-left-leg-normal-range)', 'icw-of-right-arm', 'lower-limit-(icw-of-right-arm-normal-range)', 'upper-limit-(icw-of-right-arm-normal-range)', 'icw-of-left-arm', 'lower-limit-(icw-of-left-arm-normal-range)', 'upper-limit-(icw-of-left-arm-normal-range)', 'icw-of-trunk', 'lower-limit-(icw-of-trunk-normal-range)', 'upper-limit-(icw-of-trunk-normal-range)', 'icw-of-right-leg', 'lower-limit-(icw-of-right-leg-normal-range)', 'upper-limit-(icw-of-right-leg-normal-range)', 'icw-of-left-leg', 'lower-limit-(icw-of-left-leg-normal-range)', 'upper-limit-(icw-of-left-leg-normal-range)', 'ecw-of-right-arm', 'lower-limit-(ecw-of-right-arm-normal-range)', 'upper-limit-(ecw-of-right-arm-normal-range)', 'ecw-of-left-arm', 'lower-limit-(ecw-of-left-arm-normal-range)', 'upper-limit-(ecw-of-left-arm-normal-range)', 'ecw-of-trunk', 'lower-limit-(ecw-of-trunk-normal-range)', 'upper-limit-(ecw-of-trunk-normal-range)', 'ecw-of-right-leg', 'lower-limit-(ecw-of-right-leg-normal-range)', 'upper-limit-(ecw-of-right-leg-normal-range)', 'ecw-of-left-leg', 'lower-limit-(ecw-of-left-leg-normal-range)', 'upper-limit-(ecw-of-left-leg-normal-range)', 'ecw/tbw', 'ecw/tbw-of-right-arm', 'ecw/tbw-of-left-arm', 'ecw/tbw-of-trunk', 'ecw/tbw-of-right-leg', 'ecw/tbw-of-left-leg', 'tbw/ffm', 'whole-body-ecw/tbw-t-score', 'whole-body-ecw/tbw-z-score', 'tbw/wt', 'tbw/wt-t-score', 'tbw/wt-z-score'],\n","    'Fat Mass': ['bfm-(body-fat-mass)', 'lower-limit-(bfm-normal-range)', 'upper-limit-(bfm-normal-range)', 'pbf-(percent-body-fat)', 'lower-limit-(pbf-normal-range)', 'upper-limit-(pbf-normal-range)', 'bfm-of-right-arm', 'bfm%-of-right-arm', 'bfm-of-left-arm', 'bfm%-of-left-arm', 'bfm-of-trunk', 'bfm%-of-trunk', 'bfm-of-right-leg', 'bfm%-of-right-leg', 'bfm-of-left-leg', 'bfm%-of-left-leg', 'bfm-control', 'whr-(waist-hip-ratio)', 'lower-limit-(whr-normal-range)', 'upper-limit-(whr-normal-range)', 'vfl-(visceral-fat-level)', 'ffmi-(fat-free-mass-index)', 'fmi-(fat-mass-index)', 'arms/legs-fat', 'sfa-ll(subcutaneous-fat-of-abdomen-llimit)', 'sfa-ul(subcutaneous-fat-of-abdomen-ulimit)', 'lower-limit-(bfm-of-arm-&-leg-normal-range)', 'upper-limit-(bfm-of-arm-&-leg-normal-range)', 'lower-limit-(bfm-of-trunk-normal-range)', 'upper-limit-(bfm-of-trunk-normal-range)', 'conicity-index', 'upper-limit-(conicity-index-normal-range)', 'bfm%-of-whole-body', 'ffmi-t-score', 'ffmi-z-score', 'fmi-t-score', 'fmi-z-score', 'pbf-t-score', 'pbf-z-score', 'whr-t-score', 'whr-z-score', 'bfm-of-arm-&-leg'],\n","    'Muscle Mass': ['smm-(skeletal-muscle-mass)', 'lower-limit-(smm-normal-range)', 'upper-limit-(smm-normal-range)', 'smi-(skeletal-muscle-index)', 'smi(asm/ht²)-t-score', 'smi(asm/ht²)-z-score', 'smm/wt', 'smm/wt-t-score', 'smm/wt-z-score']\n","}\n","\n","def normalize_edges(edges):\n","    for edge in edges:\n","        if edge['weight'] < 0:\n","            edge['source'], edge['target'] = edge['target'], edge['source']\n","            edge['weight'] = abs(edge['weight'])\n","    return edges\n","\n","def build_reverse_mapping(mapping):\n","    reverse = {}\n","    for category, items in mapping.items():\n","        for item in items:\n","            reverse[item] = category\n","    return reverse\n","\n","nutrient_reverse_map = build_reverse_mapping(nutritional_mapping)\n","risk_reverse_map = build_reverse_mapping(risk_mapping)\n","\n","# 分类变量名\n","def classify_variable(var_name):\n","    if var_name in nutrient_reverse_map:\n","        return 'Nutrient', nutrient_reverse_map[var_name]\n","    elif var_name in risk_reverse_map:\n","        return 'Risk', risk_reverse_map[var_name]\n","    return 'Other', None\n","\n","def process_edges(edges):\n","    processed = []\n","    for edge in edges:\n","        # 处理权重为负数\n","        if edge['weight'] < 0:\n","            edge['source'], edge['target'] = edge['target'], edge['source']\n","            edge['weight'] = abs(edge['weight'])\n","\n","        # 分类源和目标\n","        source_type, source_cat = classify_variable(edge['source'])\n","        target_type, target_cat = classify_variable(edge['target'])\n","\n","        edge['source_type'] = source_type\n","        edge['Nutritional_Target'] = source_cat\n","        edge['target_type'] = target_type\n","        edge['Risk_Factor'] = target_cat\n","        processed.append(edge)\n","    return processed\n","\n","result = process_edges(edges.to_dict('records'))\n","df = pd.DataFrame(result)\n","\n","# According weight\n","df = df[df['weight'] >= 1e-8]\n","summary_df = df.groupby(['Nutritional_Target', 'Risk_Factor'], as_index=False)['weight'].sum()\n","summary_df.rename(columns={'weight': 'User_Count'}, inplace=True)\n","summary_df = summary_df[~summary_df['Nutritional_Target'].isin(risk_mapping.keys())]\n","summary_df = summary_df[~summary_df['Risk_Factor'].isin(nutritional_mapping.keys())]\n","summary_df=pd.DataFrame(summary_df.reset_index(drop=True))\n","summary_df.to_csv('plot_data_user_weight.csv', index=False)\n","\n","# According user num\n","df = df[df['weight'] >= 1e-8]\n","df['weight'] = 1\n","summary_df = df.groupby(['Nutritional_Target', 'Risk_Factor'], as_index=False)['weight'].sum()\n","summary_df.rename(columns={'weight': 'User_Count'}, inplace=True)\n","summary_df = summary_df[~summary_df['Nutritional_Target'].isin(risk_mapping.keys())]\n","summary_df = summary_df[~summary_df['Risk_Factor'].isin(nutritional_mapping.keys())]\n","summary_df=pd.DataFrame(summary_df.reset_index(drop=True))\n","summary_df.to_csv('plot_data_user.csv', index=False)\n","summary_df"],"metadata":{"id":"-mOeAQ-QgDtL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Test Synthetic Data"],"metadata":{"id":"MsUzGSMrXsG_"}},{"cell_type":"markdown","source":["## Data Generator-VAR"],"metadata":{"id":"8HkeXUxmbSg4"}},{"cell_type":"code","source":["# 构造模拟 VAR 数据\n","def simulate_var_data(n_samples=500, p=1):\n","    d = 3  # 变量数\n","    W0 = np.array([[0.0, 0.8, 0.0],\n","                   [0.0, 0.0, -0.5],\n","                   [0.0, 0.0, 0.0]])  # 当前结构\n","\n","    A1 = np.array([[0.0, 0.0, 0.0],\n","                   [0.2, 0.0, 0.0],\n","                   [0.0, 0.3, 0.0]])  # lag 1 结构\n","\n","    X = np.random.randn(n_samples + p, d)\n","    for t in range(p, n_samples + p):\n","        X[t] += X[t - 1] @ A1 + np.random.randn(d) * 0.1\n","\n","    return X[p:], [A1]\n","\n","\n","X, true_As = simulate_var_data(n_samples=1000, p=1)\n","X  = pd.DataFrame({'X1': X[:,0], 'X2': X[:,1], 'X3': X[:,2]})\n","X"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"7AckuCHznuA5","executionInfo":{"status":"ok","timestamp":1747058665956,"user_tz":-120,"elapsed":74,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"}},"outputId":"17fe3695-6d3f-420a-e3ce-c842d883e6e2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["           X1        X2        X3\n","0    0.601674  1.838178 -1.092736\n","1    1.187931 -0.831406 -0.222651\n","2    0.654974 -0.213252 -0.510355\n","3   -0.545596 -2.171410  0.627491\n","4   -1.498067  1.907375 -0.411292\n","..        ...       ...       ...\n","995  1.569635 -0.529204  2.732846\n","996 -1.040436  0.278159 -0.835316\n","997 -0.551378  0.745380  0.557673\n","998  0.879897  1.386265  1.126183\n","999 -0.631711 -0.004389  0.003243\n","\n","[1000 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-fb56ad9b-aed4-4975-bfb0-f1f7768b62f5\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>X1</th>\n","      <th>X2</th>\n","      <th>X3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.601674</td>\n","      <td>1.838178</td>\n","      <td>-1.092736</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.187931</td>\n","      <td>-0.831406</td>\n","      <td>-0.222651</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.654974</td>\n","      <td>-0.213252</td>\n","      <td>-0.510355</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.545596</td>\n","      <td>-2.171410</td>\n","      <td>0.627491</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-1.498067</td>\n","      <td>1.907375</td>\n","      <td>-0.411292</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>1.569635</td>\n","      <td>-0.529204</td>\n","      <td>2.732846</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>-1.040436</td>\n","      <td>0.278159</td>\n","      <td>-0.835316</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>-0.551378</td>\n","      <td>0.745380</td>\n","      <td>0.557673</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>0.879897</td>\n","      <td>1.386265</td>\n","      <td>1.126183</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>-0.631711</td>\n","      <td>-0.004389</td>\n","      <td>0.003243</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows × 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb56ad9b-aed4-4975-bfb0-f1f7768b62f5')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-fb56ad9b-aed4-4975-bfb0-f1f7768b62f5 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-fb56ad9b-aed4-4975-bfb0-f1f7768b62f5');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-1e95bbd7-9b2a-4b7a-ab95-925d7390c742\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1e95bbd7-9b2a-4b7a-ab95-925d7390c742')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-1e95bbd7-9b2a-4b7a-ab95-925d7390c742 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_63cbcb8a-5816-4798-a64e-aaf1f368589f\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_63cbcb8a-5816-4798-a64e-aaf1f368589f button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('X');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"X","summary":"{\n  \"name\": \"X\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"X1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0495191620819626,\n        \"min\": -3.4922361628803267,\n        \"max\": 3.4007921808696033,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          -0.01000922465863241,\n          -0.38096370960092335,\n          0.33969641695627306\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"X2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0876821693056185,\n        \"min\": -3.9110278124032765,\n        \"max\": 3.916444077475545,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          1.1018871048356063,\n          -0.13356904118177942,\n          -3.9110278124032765\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"X3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0023993325963636,\n        \"min\": -3.0862151255131045,\n        \"max\": 2.7969465154791715,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          -0.49869564618009726,\n          1.193417979458317,\n          -0.8243738048717916\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":68}]},{"cell_type":"markdown","source":["## Test Dynotear"],"metadata":{"id":"JPh5xuZObHFb"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1747058699898,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"},"user_tz":-120},"id":"jUo3zL96HlI6","outputId":"06f8b039-27e5-4fff-eb0b-6bd6652254a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.         0.         0.        ]\n"," [0.11551321 0.         0.        ]\n"," [0.         0.13273093 0.        ]]\n","\n","Edges:\n","X2_lag1 -> X1_lag0, weight=0.11551320874050695\n","X3_lag1 -> X2_lag0, weight=0.1327309289856114\n"]}],"source":["sm, w_est, a_est = from_pandas_dynamic(X, p=1)\n","print(w_est, a_est)\n","'''\n","print(\"\\nEdges:\")\n","for u, v, d in sm.edges(data=True):\n","    print(f\"{u} -> {v}, weight={d.get('weight')}\")\n","'''"]},{"cell_type":"markdown","metadata":{"id":"xXfi7jlTrakJ"},"source":["## Test lingam"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":120,"status":"ok","timestamp":1747058949826,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"},"user_tz":-120},"id":"vCu3NkMf2RUl","outputId":"cfc9e1c9-491e-4a49-f245-62d663029ada"},"outputs":[{"output_type":"stream","name":"stdout","text":["NUMBER OF ADJ MATRICES: 2. DATA RECURSION: 1\n","W_est (instantaneous):\n","[[0. 0. 0.]\n"," [0. 0. 0.]\n"," [0. 0. 0.]]\n","\n","A_est (lagged):\n","Lag 1:\n","[[0.         0.19974618 0.        ]\n"," [0.         0.         0.23351226]\n"," [0.         0.         0.        ]]\n"]}],"source":["import numpy as np\n","from lingam import VARLiNGAM\n","import matplotlib.pyplot as plt\n","\n","def solve_lingam(X, Y, p):\n","    import lingam\n","    model = lingam.VARLiNGAM(lags=p, criterion=None)\n","    model.fit(X)\n","\n","    W_est = model._adjacency_matrices[0]\n","    print(f'NUMBER OF ADJ MATRICES: {len(model._adjacency_matrices)}. DATA RECURSION: {p}')\n","\n","    A_est = []\n","    for i in range(p):\n","        A_est.append(model._adjacency_matrices[i + 1])\n","    return W_est, A_est\n","\n","W_est, A_est = solve_lingam(X, Y=None, p=1)\n","#W_est, A_est = solve_lingam(X, Y, p)\n","\n","print(\"W_est (instantaneous):\")\n","print(W_est)\n","print(\"\\nA_est (lagged):\")\n","for i, A in enumerate(A_est):\n","    print(f\"Lag {i+1}:\")\n","    print(A)\n","print(W_est, A_est)"]},{"cell_type":"markdown","metadata":{"id":"_yDnAaNws28E"},"source":["## *Test gobnilp"]},{"cell_type":"code","source":["!pip install --upgrade pygobnilp\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xs5oSqhQ5mmX","executionInfo":{"status":"ok","timestamp":1747060164401,"user_tz":-120,"elapsed":4712,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"}},"outputId":"f8a43837-ecd0-4b6f-d381-de6db1ec191a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pygobnilp in /usr/local/lib/python3.11/dist-packages (1.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pygobnilp) (1.11.4)\n","Requirement already satisfied: pygraphviz in /usr/local/lib/python3.11/dist-packages (from pygobnilp) (1.14)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from pygobnilp) (3.10.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pygobnilp) (3.4.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from pygobnilp) (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pygobnilp) (1.23.5)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from pygobnilp) (1.6.1)\n","Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from pygobnilp) (0.60.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygobnilp) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygobnilp) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygobnilp) (4.57.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygobnilp) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygobnilp) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygobnilp) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygobnilp) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygobnilp) (2.9.0.post0)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->pygobnilp) (0.43.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->pygobnilp) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->pygobnilp) (2025.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pygobnilp) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pygobnilp) (3.6.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->pygobnilp) (1.17.0)\n"]}]},{"cell_type":"code","source":["from pygobnilp.gobnilp import Gobnilp\n","m = Gobnilp()\n","m.params.TimeLimit = cfg.time_limit # Access the 'time_limit' attribute of the 'cfg' instance\n","# The issue was here: addConstr() was being called with an implicit 'self' argument\n","# Pass the linear expression, sense, and rhs as keyword arguments to fix the problem\n","# m.learn(X,data_type=cfg.data_type,score=cfg.score,  palim=cfg.palim, gurobi_output=True, verbose=5, plot=False) # BGe, GaussianL0, GaussianBIC, GaussianAIC,\n","m.learn(X, data_type='continuous', score='GaussianBIC')  # Pass an empty dictionary for params\n","bn = m.learned_bn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"P6sOYzZL_bjU","executionInfo":{"status":"error","timestamp":1747160636798,"user_tz":-120,"elapsed":567,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"}},"outputId":"ccbad390-90ab-4fc4-837d-14dc1384efcb"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"module 'numpy.linalg._umath_linalg' has no attribute '_ilp64'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-0b57774cb022>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpygobnilp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgobnilp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGobnilp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGobnilp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeLimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_limit\u001b[0m \u001b[0;31m# Access the 'time_limit' attribute of the 'cfg' instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# The issue was here: addConstr() was being called with an implicit 'self' argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Pass the linear expression, sense, and rhs as keyword arguments to fix the problem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pygobnilp/gobnilp.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     from .scoring import (\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mDiscreteData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mContinuousData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mBDeu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBGe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pygobnilp/scoring.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdigamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgammaln\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0m_distributor_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m )\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInconsistentVersionWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HTMLDocumentationLinkMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata_requests\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_MetadataRequester\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_routing_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalidate_parameter_constraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_joblib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata_routing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_bunch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBunch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_chunking\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_chunking.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInterval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_is_arraylike_not_scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_get_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataConversionWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPositiveSpectrumWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_array_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_is_numpy_namespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_deprecate_force_all_finite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_preserve_dia_indices_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparse_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0m_NUMPY_NAMESPACE_NAMES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"array_api_compat.numpy\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/stats/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    606\u001b[0m from ._warnings_errors import (ConstantInputWarning, NearConstantInputWarning,\n\u001b[1;32m    607\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[0;32m--> 608\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_stats_py\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_variation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvariation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/stats/_stats_py.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNumpyVersion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msuppress_warnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/testing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_private\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_private\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_private\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_assert_valid_refcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_gen_alignment_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_private\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextbuild\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mIS_PYSTON\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pyston_version_info\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mHAS_REFCOUNT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'getrefcount'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mIS_PYSTON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mHAS_LAPACK64\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ilp64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0m_OLD_PROMOTION\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_promotion_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'legacy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'numpy.linalg._umath_linalg' has no attribute '_ilp64'"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":703},"executionInfo":{"elapsed":130,"status":"error","timestamp":1747061474688,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"},"user_tz":-120},"id":"lQrBHZays3FD","outputId":"7c75a674-3028-41d6-91f8-816495dfe95a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Set parameter PreCrush to value 1\n","Set parameter CutPasses to value 100000\n","Set parameter GomoryPasses to value 100000\n","Set parameter MIPFocus to value 2\n","Set parameter ZeroHalfCuts to value 2\n","Set parameter MIPGap to value 0\n","Set parameter MIPGapAbs to value 0\n","Set parameter TimeLimit to value 3600\n","Set parameter OutputFlag to value 1\n","1 local scores stored for child variable X1\n","1 local scores stored for child variable X2\n","1 local scores stored for child variable X3\n","Search nodes expanded = 3, scores computed = 3, scores kept = 3\n","Set parameter PoolSolutions to value 1\n","Set parameter PoolSearchMode to value 1\n"]},{"output_type":"stream","name":"stderr","text":["3 family variables declared\n","6 arrow variables declared\n","3 adj variables declared\n"]},{"output_type":"error","ename":"TypeError","evalue":"addConstr() takes at most 3 positional arguments (4 given)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-93-b8c871766157>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m#X = np.loadtxt('X.csv', delimiter=',')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mW_est\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Pass the 'cfg' instance instead of the 'DictConfig' class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mnotears_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_est\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-93-b8c871766157>\u001b[0m in \u001b[0;36msolve\u001b[0;34m(X, cfg)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Pass the linear expression, sense, and rhs as keyword arguments to fix the problem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# m.learn(X,data_type=cfg.data_type,score=cfg.score,  palim=cfg.palim, gurobi_output=True, verbose=5, plot=False) # BGe, GaussianL0, GaussianBIC, GaussianAIC,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpalim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgurobi_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Pass an empty dictionary for params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mbn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearned_bn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pygobnilp/gobnilp.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, data_source, varnames, header, comments, delimiter, start, end, data_type, score, local_score_fun, k, ls, standardise, arities, palim, alpha, nu, alpha_mu, alpha_omega, starts, local_scores_source, nsols, kbest, mec, consfile, settingsfile, pruning, edge_penalty, plot, abbrev, output_scores, output_stem, output_dag, output_cpdag, output_ext, verbose, gurobi_output, **params)\u001b[0m\n\u001b[1;32m   3501\u001b[0m             \u001b[0;31m# no MIP model yet, (or we wish to throw away the existing one) so make one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3502\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_basic_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3503\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_basic_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnsols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkbest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkbest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3504\u001b[0m             \u001b[0;31m# call 'mipconss' if it is defined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconsfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pygobnilp/gobnilp.py\u001b[0m in \u001b[0;36mmake_basic_model\u001b[0;34m(self, nsols, kbest, mec)\u001b[0m\n\u001b[1;32m   3289\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3290\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPoolSearchMode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m   \u001b[0;31m# find k best solutions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3291\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_basic_constraints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3292\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3293\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_constraints_one_dag_per_MEC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pygobnilp/gobnilp.py\u001b[0m in \u001b[0;36madd_basic_constraints\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2547\u001b[0m         \u001b[0;34m*\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mpy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0madd_constraints_clusters\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mpygobnilp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgobnilp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGobnilp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_constraints_clusters\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2548\u001b[0m         '''\n\u001b[0;32m-> 2549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_constraints_oneparentset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2550\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_constraints_setpacking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2551\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_constraints_arrow_family\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pygobnilp/gobnilp.py\u001b[0m in \u001b[0;36madd_constraints_oneparentset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2242\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparentset_dict\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfamily\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2244\u001b[0;31m             self.addConstr(LinExpr([1.0] * len(parentset_dict),list(parentset_dict.values())),\n\u001b[0m\u001b[1;32m   2245\u001b[0m                            \u001b[0mGRB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEQUAL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2246\u001b[0m                            1)\n","\u001b[0;32msrc/gurobipy/_model.pyx\u001b[0m in \u001b[0;36mgurobipy._model.Model.addConstr\u001b[0;34m()\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: addConstr() takes at most 3 positional arguments (4 given)"]}],"source":["import numpy as np\n","import networkx as nx\n","from omegaconf import DictConfig\n","#from notears import utils\n","# import notears.utils as notears_utils\n","\n","cfg = DictConfig({\n","    'time_limit': 3600,  # Example time limit in seconds\n","    'data_type': 'continuous',  # Example data type\n","    'score': 'BGe',  # Example score function\n","    'palim': 0, # Example palim value\n","})\n","\n","def solve(X, cfg: DictConfig):\n","    from pygobnilp.gobnilp import Gobnilp\n","    m = Gobnilp()\n","    m.params.TimeLimit = cfg.time_limit # Access the 'time_limit' attribute of the 'cfg' instance\n","    # The issue was here: addConstr() was being called with an implicit 'self' argument\n","    # Pass the linear expression, sense, and rhs as keyword arguments to fix the problem\n","    # m.learn(X,data_type=cfg.data_type,score=cfg.score,  palim=cfg.palim, gurobi_output=True, verbose=5, plot=False) # BGe, GaussianL0, GaussianBIC, GaussianAIC,\n","    m.learn(X, data_type=cfg.data_type, score=cfg.score,palim=cfg.palim, gurobi_output=True, verbose=5, plot=False)  # Pass an empty dictionary for params\n","    bn = m.learned_bn\n","\n","    am = nx.adjacency_matrix(bn, sorted(bn.nodes()))\n","\n","    W_est = am.todense()\n","    return W_est\n","\n","\n","if __name__ == '__main__':\n","    notears_utils.set_random_seed(1)\n","\n","    #n, d, s0, graph_type, sem_type = 100, 23, 20, 'ER', 'gauss' #20\n","    n, d, s0, graph_type, sem_type = 3000, 3, 20, 'PATHPERM', 'gauss' #20\n","    B_true = notears_utils.simulate_dag(d, s0, graph_type)\n","    W_true = notears_utils.simulate_parameter(B_true)\n","    np.savetxt('W_true.csv', W_true, delimiter=',')\n","\n","    X = notears_utils.simulate_linear_sem(W_true, n, sem_type, noise_scale=50)\n","    np.savetxt('X.csv', X, delimiter=',')\n","    #X = np.loadtxt('X.csv', delimiter=',')\n","\n","    W_est = solve(X,cfg) # Pass the 'cfg' instance instead of the 'DictConfig' class\n","\n","    assert notears_utils.is_dag(W_est)\n","    np.savetxt('W_est_gobnilp.csv', W_est, delimiter=',')\n","    # acc = notears_utils.count_accuracy(B_true, W_est != 0)\n","    # print(acc)"]},{"cell_type":"markdown","metadata":{"id":"WOgkGrc2rbBl"},"source":["## Test milp-DAG"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5VagyXTjrbNt"},"outputs":[],"source":["if __name__ == '__main__':\n","    # import notears.utils as notears_utils\n","    import omegaconf as OmegaConf\n","\n","    notears_utils.set_random_seed(1)\n","    n, d, s0, graph_type, sem_type = 2000, 10, 30, 'ER', 'gauss'\n","    #n, d, s0, graph_type, sem_type = 100, 3, 20, 'PATHPERM', 'gauss'  # 7 funguje, 25 GOBNILP COUNTER EXAMPL\n","    #n, d, s0, graph_type, sem_type = 10, 2, 20, 'PATH', 'gauss' # 7 funguje, 25\n","    B_true = notears_utils.simulate_dag(d, s0, graph_type)\n","    W_true = notears_utils.simulate_parameter(B_true)\n","    np.savetxt('W_true.csv', W_true, delimiter=',')\n","    #W_true = np.loadtxt('W_true.csv', delimiter=',')\n","\n","    X = notears_utils.simulate_linear_sem(W_true, n, sem_type, noise_scale=1)\n","    Y = [] # TODO: add historical data\n","    xcol = X[:,1] / X[:,0]\n","    x1avg = X[:,0].sum()/n\n","    x2avg = X[:,1].sum()/n\n","    print('debug')\n","    print(x2avg/x1avg)\n","\n","    xrat = (X[:,1]/X[:,0]).sum()/n\n","    print(xrat)\n","\n","    np.savetxt('X.csv', X, delimiter=',')\n","    #X = np.loadtxt('X.csv', delimiter=',')\n","    cfg = OmegaConf.DictConfig({})\n","    cfg.time_limit = 1800\n","    cfg.constraints_mode = 'weights'\n","    cfg.callback_mode = 'all_cycles'\n","    cfg.lambda1=1\n","    cfg.lambda2=1\n","    cfg.loss_type='l2'\n","    cfg.reg_type='l1'\n","    cfg.a_reg_type='l1'\n","    cfg.robust = False\n","    cfg.weights_bound = 100\n","    cfg.target_mip_gap = 0.001\n","    cfg.tabu_edges = False\n","\n","    W_est, A_est, _, _, stats = solve(X, cfg, 0, Y=Y, B_ref=B_true) # lambda1=0.0009\n","    assert notears_utils.is_dag(W_est)\n","    np.savetxt('W_est_milp.csv', W_est, delimiter=',')\n","    acc = notears_utils.count_accuracy(B_true, W_est != 0)\n","    print(stats)\n","    print(acc)"]},{"cell_type":"markdown","metadata":{"id":"cp0ASsycllon"},"source":["## Test sortnregress"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iT6oDjO6lly3"},"outputs":[],"source":["if __name__ == \"__main__\":\n","    W = np.array([[0, 1, 0], [0, 0, 2], [0, 0, 0]])\n","    X = np.random.randn(1000, 3).dot(np.linalg.inv(np.eye(3) - W))\n","    W_hat = sortnregress(X)\n","    print(W)\n","    print(W_hat)"]},{"cell_type":"markdown","metadata":{"id":"6MeD-h7_o4ra"},"source":["## Test BOSS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mj8UDiQto45n"},"outputs":[],"source":["from os.path import join, isfile\n","from os import listdir\n","import subprocess\n","import numpy as np\n","import json\n","\n","def write_data(file_name, X, variable_names):\n","    header = '\\t'.join(variable_names)\n","    np.savetxt(file_name, X, delimiter='\\t', header=header, comments='')\n","\n","def read_data(file_name, variable_names):\n","    d = len(variable_names)\n","    d_idx = {name: i for i, name in enumerate(variable_names)}\n","    with open(file_name) as f:\n","        W_est_json = json.load(f)\n","    edges = W_est_json['edgesSet']\n","    W_est = np.zeros((d,d))\n","    for edge in edges:\n","        from_idx = d_idx[edge['node1']['name']] # row index\n","        to_idx = d_idx[edge['node2']['name']] # column index\n","        if edge['endpoint1'] == 'TAIL' and edge['endpoint2'] == 'ARROW':\n","            W_est[from_idx, to_idx] = 1\n","        elif edge['endpoint1'] == 'TAIL' and edge['endpoint2'] == 'TAIL':\n","            W_est[from_idx, to_idx] = 1\n","            #W_est[to_idx, from_idx] = 1\n","        else:\n","            assert False\n","\n","    return W_est\n","\n","\n","def solve_boss(X, work_dir, boss_cmd):\n","    _, d = X.shape\n","    variable_names = [f'v{rnd_var_index}' for rnd_var_index in range(d)]\n","    write_data(join(work_dir, 'dataset.txt'), X, variable_names)\n","    ret = subprocess.run(boss_cmd.split(' '), cwd=work_dir)\n","    assert ret.returncode == 0\n","\n","    output_files = [f for f in listdir(work_dir) if isfile(join(work_dir, f)) and f.startswith('boss_') and f.endswith('_graph.json')]\n","    assert len(output_files) == 1\n","    W_est = read_data(join(work_dir, output_files[0]), variable_names)\n","\n","    return W_est\n","\n"]},{"cell_type":"markdown","metadata":{"id":"71hET7s2pOcC"},"source":["## Test POP"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AN-drSZ8pOlg"},"outputs":[],"source":["import gurobipy as gp\n","import numpy as np\n","from gurobipy import GRB\n","\n","\n","\n","def solve_pop(X, lambda1, loss_type):\n","    n, d = X.shape\n","    m = gp.Model()\n","    V = {}  # v constraints\n","    W = {} # Je v cost funkci\n","    for v1 in range(d):\n","        for v2 in range(d):\n","            for power in range(1, d + 1):\n","                V[power, v1, v2] = m.addVar(vtype=GRB.CONTINUOUS, name=f'w2{v1}->{v2}_power_{d}')\n","                if power == 1:\n","                    W[v1, v2] = m.addVar(lb=float('-inf'),vtype=GRB.CONTINUOUS, name=f'weight{v1}->{v2}')\n","                    m.addConstr(W[v1, v2] ** 2 == V[1, v1, v2])\n","\n","    for v1 in range(d):\n","        for v2 in range(d):\n","            for power in range(1, d + 1):\n","                if (power % 2) == 0:\n","                    m.addConstr(V[power, v1, v2] == gp.quicksum(V[power//2, v1, k] * V[power//2, k, v2] for k in range(d)))\n","                else:\n","                    if power > 1:\n","                        m.addConstr(V[power, v1, v2] == gp.quicksum(V[((power-1)//2)+1, v1, k] * V[(power-1)//2, k, v2] for k in range(d)))\n","\n","    #for v in range(d):\n","    for power in range(1, d + 1):\n","        m.addConstr(gp.quicksum(V[power,k,k] for k in range(d)) == 0)\n","\n","    if loss_type == 'l2':\n","\n","        reg2 = gp.quicksum(V.values())\n","        m.setObjective(gp.quicksum((X[i,j] - gp.quicksum(X[i, k] * W[k, j] for k in range(d) if k != j))**2 for i in range(n) for j in range(d)) + lambda1 * reg2, GRB.MINIMIZE)\n","        print(m.getObjective().getValue())\n","    elif loss_type == 'l1':\n","        pass\n","\n","    m._W = W\n","    m.optimize()\n","\n","\n","    W_vals = m.getAttr('x', W)\n","\n","    W_est = np.zeros((d,d))\n","    for v1 in range(d):\n","        for v2 in range(d):\n","            W_est[v1, v2] = W_vals[v1, v2]\n","\n","\n","    assert utils.is_dag(W_est)\n","    m.dispose()\n","    gp.disposeDefaultEnv()\n","    return W_est\n","\n","\n","if __name__ == '__main__':\n","    from notears import utils\n","    utils.set_random_seed(1)\n","\n","    n, d, s0, graph_type, sem_type = 30, 7, 20, 'ER', 'gauss' # 7 funguje, 25\n","    #n, d, s0, graph_type, sem_type = 10, 2, 20, 'PATH', 'gauss' # 7 funguje, 25\n","    B_true = utils.simulate_dag(d, s0, graph_type)\n","    W_true = utils.simulate_parameter(B_true)\n","    np.savetxt('W_true.csv', W_true, delimiter=',')\n","    #W_true = np.loadtxt('W_true.csv', delimiter=',')\n","\n","    X = utils.simulate_linear_sem(W_true, n, sem_type, noise_scale=1)\n","    xcol = X[:,1] / X[:,0]\n","    x1avg = X[:,0].sum()/n\n","    x2avg = X[:,1].sum()/n\n","    print('debug')\n","    print(x2avg/x1avg)\n","\n","    xrat = (X[:,1]/X[:,0]).sum()/n\n","    print(xrat)\n","\n","    np.savetxt('X.csv', X, delimiter=',')\n","    #X = np.loadtxt('X.csv', delimiter=',')\n","\n","    W_est = solve_pop(X, lambda1=0, loss_type='l2') # lambda1=0.0009\n","    assert utils.is_dag(W_est)\n","    np.savetxt('W_est_milp.csv', W_est, delimiter=',')\n","    acc = utils.count_accuracy(B_true, W_est != 0)\n","    print(acc)"]},{"cell_type":"markdown","source":["## Matrices → DiGraph"],"metadata":{"id":"LAxuZTJ80aww"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"DGrlQxgkgtjK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747058782619,"user_tz":-120,"elapsed":13,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"}},"outputId":"6ad29249-b817-47e8-b3ba-01fac823a642"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Edges:\n","X1_lag1 -> X2_lag0, weight=0.116\n","X2_lag1 -> X3_lag0, weight=0.133\n"]}],"source":["import networkx as nx\n","import matplotlib.pyplot as plt\n","import numpy as np  # Import numpy for using np.round\n","import numpy as np\n","import networkx as nx\n","import matplotlib.pyplot as plt\n","\n","G = nx.DiGraph()\n","\n","nodes = list(sm.nodes)\n","# Separate the nodes into two lists based on 'lag0' and 'lag1'\n","nodes_t0 = sorted([node for node in nodes if 'lag0' in node], key=lambda x: x[1])\n","nodes_t1 = sorted([node for node in nodes if 'lag1' in node], key=lambda x: x[1])\n","G.add_nodes_from(nodes_t0 + nodes_t1)\n","\n","# 添加 Intra-slice 边（t -> t）\n","intra_edges_dashed = []\n","for i in range(3):\n","    for j in range(3):\n","        if abs(w_est[i, j]) > 1e-4:  # 忽略太小的边\n","            if w_est[i, j] > 0:\n","                intra_edges_dashed.append((nodes_t0[j], nodes_t0[i], {'weight': abs(round(w_est[i, j], 3))}))\n","            else:\n","                intra_edges_dashed.append((nodes_t0[i], nodes_t0[j], {'weight': abs(round(w_est[i, j], 3))}))\n","\n","# 添加 Inter-slice 边（t-1 -> t）\n","inter_edges =[]\n","for i in range(3):\n","    for j in range(3):\n","        if abs(a_est[i, j]) > 1e-4:\n","            if a_est[i, j] > 0:\n","                inter_edges.append((nodes_t1[j], nodes_t0[i], {'weight': abs(round(a_est[i, j], 3))}))\n","            else:\n","                inter_edges.append((nodes_t0[i], nodes_t1[j], {'weight': abs(round(a_est[i, j], 3))}))\n","\n","# 添加边\n","G.add_edges_from(inter_edges)\n","G.add_edges_from(intra_edges_dashed)\n","\n","print(\"\\nEdges:\")\n","for u, v, d in G.edges(data=True):\n","    print(f\"{u} -> {v}, weight={d.get('weight')}\")"]},{"cell_type":"markdown","source":["## Plot"],"metadata":{"id":"ZmxxbxHf4zAT"}},{"cell_type":"markdown","metadata":{"id":"8SjLMWbpRSS_"},"source":["### plot Large-scale data\n","\n","* 可自动布局, 但表现不一定\n","* sm和G都可画图"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hr0SLLhpUCT-"},"outputs":[],"source":["pos = nx.spring_layout(sm, seed=24)\n","\n","labels = nx.get_edge_attributes(sm, 'weight')\n","\n","# Round the edge labels individually using a dictionary comprehension\n","rounded_labels = {edge: abs(np.round(weight, 3)) for edge, weight in labels.items()}\n","\n","nx.draw(sm, pos, with_labels=True, node_size=1800, font_size=8, node_color='lightblue')\n","nx.draw_networkx_edge_labels(sm, pos, edge_labels=rounded_labels, font_color='red')  # Use rounded_labels here\n","plt.title(\"Learned Dynamic Bayesian Network\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mJ6yY-TRVQA2"},"outputs":[],"source":["# 画图\n","pos = nx.spring_layout(G, seed=42)  # 布局\n","edge_labels = nx.get_edge_attributes(G, 'weight')\n","\n","plt.figure(figsize=(10, 6))\n","nx.draw(G, pos, with_labels=True, node_size=2000, node_color='lightblue', font_size=10, arrows=True)\n","nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_color='red')\n","plt.title('DBN Causal Graph (Intra + Inter Slice)')\n","plt.axis('off')\n","#plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"SKUK7fhdhpGB"},"source":["**no-weight labels**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bLt_rNuvEO6N"},"outputs":[],"source":["plt.figure(figsize=(6, 4))\n","nx.draw(G, with_labels=True, node_size=2000, node_color=\"lightblue\", font_size=9, font_weight=\"bold\", arrows=True)\n","plt.title(\"Learned Dynamic Bayesian Network Without Labels\")\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"cobEADayhcV1"},"source":["### plot Small-scale data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fVOgZjv6Jzu8"},"outputs":[],"source":["# 手动布局，保持图形结构清晰\n","pos = {\n","    'X1_lag0': (-2, 2),\n","    'X2_lag0': (-2, 1),\n","    'X3_lag0': (-2, 0),\n","    'X1_lag1': (0, 2),\n","    'X2_lag1': (0, 1),\n","    'X3_lag1': (0, 0),\n","}\n","\n","# 绘图设置\n","plt.figure(figsize=(4, 4))\n","nx.draw_networkx_nodes(G, pos, node_size=1800, node_color='white', edgecolors='black', linewidths=1.5)\n","nx.draw_networkx_labels(G, pos, font_size=9)\n","\n","nx.draw_networkx_edges(G, pos, edgelist=inter_edges, edge_color='black', arrows=True,\n","    arrowstyle='-|>', min_target_margin=20, connectionstyle='arc3,rad=0.0', width=1)\n","nx.draw_networkx_edges(G, pos, edgelist=intra_edges_dashed, edge_color='black', arrows=True, style='dashed',\n","    arrowstyle='-|>', min_target_margin=20, connectionstyle='arc3,rad=0.0', width=2)\n","\n","plt.axis('off')\n","plt.title(\"Demonstration of Causality Predicted from DBN\", fontsize=12)\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"kUFU_zQnRX4l"},"source":["### plot junction tree"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1LHWJpC1EsVB"},"outputs":[],"source":["import numpy as np\n","import textwrap\n","import networkx as nx\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","from pgmpy.models import MarkovNetwork\n","from pgmpy.factors.discrete import DiscreteFactor\n","\n","# Calculate Pearson correlation matrix\n","# Convert \"yes\" / \"no\" to 1 / 0\n","corr_matrix = df.corr()\n","threshold = 0.1\n","edges = [(var1, var2) for var1 in corr_matrix.columns for var2 in corr_matrix.columns\n","         if var1 != var2 and abs(corr_matrix[var1][var2]) > threshold]\n","\n","# Step 1: Define the Markov Network (Undirected Graph)\n","# ————————————————————————————————————————————————————————————————\n","G_Undirected = MarkovNetwork()\n","G_Undirected.add_nodes_from([var1 for var1 in corr_matrix.columns])\n","\n","G_Undirected.add_edges_from(edges)\n","# print(\"Edges in the Undirected Graph:\", list(G_Undirected.edges()))\n","\n","# Convert to NetworkX Graph for visualization\n","G = nx.Graph()\n","G.add_edges_from(list(G_Undirected.edges()))\n","\n","# Step 2: Add random factors\n","# -------------------------------------------------------------------------------------\n","phi = [DiscreteFactor(edge, [2, 2], np.random.rand(4)) for edge in G.edges()]\n","G_Undirected.add_factors(*phi)\n","\n","# Step 3: Triangulate the graph (Chordal Graph)\n","chordal = G_Undirected.triangulate()\n","G_chordal = nx.Graph()\n","G_chordal.add_edges_from(list(chordal.edges()))\n","# print(\"Edges in the chordal Graph:\", list(chordal.edges()))\n","\n","# Step 4: Convert to Junction Tree\n","junction_tree = G_Undirected.to_junction_tree()\n","# print(\"Edges in the Junction Tree:\", list(junction_tree.edges()))\n","\n","G_junction = nx.Graph()\n","G_junction.add_edges_from(list(junction_tree.edges()))\n","\n","# Nodes text change line\n","def wrap_labels(labels, width=6):\n","    return {node: '\\n'.join(textwrap.wrap(', '.join(node), width=width)) for node in labels}\n","\n","# Wrap the labels (convert tuple to string and wrap)\n","wrapped_labels = wrap_labels(G_junction.nodes(), width=10)\n","pos = nx.spring_layout(G_junction)\n","\n","# Plots\n","fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n","axes[0].set_title(\"Undirected Graph\", fontsize=20)\n","nx.draw(G, ax=axes[0], with_labels=True, node_color='skyblue', edge_color='skyblue', node_size=3500, font_size=12)\n","\n","axes[1].set_title(\"Chordal Graph\", fontsize=20)\n","nx.draw(G_chordal, ax=axes[1], with_labels=True, node_color='orange', edge_color='orange', node_size=3500, font_size=12)\n","\n","axes[2].set_title(\"Junction Tree\", fontsize=20)\n","nx.draw(G_junction, pos=pos, ax=axes[2], with_labels=False, node_color='lightgreen', edge_color='lightgreen', node_size=3500)\n","nx.draw_networkx_labels(G_junction, pos=pos, labels=wrapped_labels, font_size=10,  font_color='black')\n","\n","\n","for ax in axes.flat:\n","    rect = patches.Rectangle((0, 0), 1, 1, transform=ax.transAxes,\n","                              linewidth=2, edgecolor='black', facecolor='none')\n","    ax.add_patch(rect)\n","plt.tight_layout()\n","#plt.subplots_adjust(wspace=0.5, hspace=0.5)\n","plt.show()\n"]},{"cell_type":"markdown","source":["# Test BN_IP4AncADMG Synthetic Data"],"metadata":{"id":"cpydwVa1Pm5L"}},{"cell_type":"code","source":["# from test_latent_scores import generate_scores_bidirect,generate_scores_bidirect_m3hc\n","import numpy as np\n","\n","\n","\n","datasets = ['./datasets/example.txt']\n","\n","\n","for dataset in datasets:\n","\n","\twith open(dataset, 'rb') as f:\n","\t    data = np.loadtxt(f, skiprows=0)\n","\n","\t# visible\n","\tobserved_data = data\n","\n","\n","\tc_size = 2\n","\tsingle_parent_size = 3\n","\tother_c_parent_size = 1\n","\tfile_name = dataset[:-4]\n","\tprint(file_name)\n","\n","\n","\tgenerate_scores_bidirect(observed_data,\n","\t                         single_c_parent_size = single_parent_size,\n","\t                         other_c_parent_size = other_c_parent_size,\n","\t                         c_size = c_size,\n","\t                         file_name = file_name)"],"metadata":{"id":"48CiPCO44OFW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Read data"],"metadata":{"id":"TbVqpEmrPwSJ"}},{"cell_type":"markdown","source":["## Test BN"],"metadata":{"id":"wXqJa1gz4ohP"}},{"cell_type":"code","source":["import numpy as np\n","import pickle\n","\n","if __name__ == '__main__':\n","\tscoresets = ['./datasets/synth_5_test_score_1000.pkl']\n","\tfor instName in scoresets:\n","\t\tinst = BNSLlvInst(instName)\n","\t\tinst.readFromPkl()\n","\t\tinst.Initialize(prune=True,printsc=False)\n","\t\tinst.Solve_with_cb()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bsa3DZQmVRH0","executionInfo":{"status":"ok","timestamp":1748516705109,"user_tz":-60,"elapsed":383,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"}},"outputId":"5fa33784-a92f-471a-b03e-be291b52b460"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0.89067573  0.087962    1.02928186  1.66921171]\n"," [ 2.72098806 -0.77178239 -0.43049761  0.5408975 ]\n"," [-0.88811419  1.14917463  2.53760388  0.93742924]\n"," ...\n"," [ 0.21757335 -0.25374846 -0.20694337 -0.97884618]\n"," [ 0.86300478  0.97576313  0.98661576  0.34398597]\n"," [-0.57095935 -0.46304362 -0.48567583 -0.66283661]] {((0,), ()): {((),): np.float64(-1403.8645428682), ((1,),): np.float64(-1406.7992786619084), ((2,),): np.float64(-1407.0368206501032), ((3,),): np.float64(-1407.208985009694), ((1, 2),): np.float64(-1409.9180569984508), ((1, 3),): np.float64(-1410.1516260629903), ((2, 3),): np.float64(-1410.369429445646), ((1, 2, 3),): np.float64(-1413.2583552266578)}, ((1,), ()): {((),): np.float64(-1435.8233981051844), ((0,),): np.float64(-1438.758133898893), ((2,),): np.float64(-1437.1731578389652), ((3,),): np.float64(-1439.129498059495), ((0, 2),): np.float64(-1440.054394187312), ((0, 3),): np.float64(-1442.0721391127906), ((2, 3),): np.float64(-1440.512468058411), ((0, 2, 3),): np.float64(-1443.4013938394241)}, ((2,), ()): {((),): np.float64(-1452.8428115631575), ((0,),): np.float64(-1456.015089345061), ((1,),): np.float64(-1454.192571296938), ((3,),): np.float64(-1455.774425700198), ((0, 1),): np.float64(-1457.3113496334802), ((0, 3),): np.float64(-1458.9348701361494), ((1, 3),): np.float64(-1457.157395699115), ((0, 1, 3),): np.float64(-1460.264124862782)}, ((3,), ()): {((),): np.float64(-1424.9315377144794), ((0,),): np.float64(-1428.2759798559734), ((1,),): np.float64(-1428.2376376687898), ((2,),): np.float64(-1427.8631518515194), ((0, 1),): np.float64(-1431.5899850698715), ((0, 2),): np.float64(-1431.1957606470626), ((1, 2),): np.float64(-1431.2024620709653), ((0, 1, 2),): np.float64(-1434.5427602991733)}, ((0, 1), ((0, 1),)): {((), ()): np.float64(-2842.622676767093), ((), (0,)): np.float64(-2842.622676767093), ((), (2,)): np.float64(-2843.918937055512), ((), (3,)): np.float64(-2845.9366819809907), ((), (0, 2)): np.float64(-2843.9189370555114), ((), (0, 3)): np.float64(-2845.9366819809907), ((), (2, 3)): np.float64(-2847.265936707623), ((1,), ()): np.float64(-2842.622676767093), ((1,), (2,)): np.float64(-2843.9724365008733), ((1,), (3,)): np.float64(-2845.9287767214037), ((1,), (2, 3)): np.float64(-2847.311746720319), ((2,), ()): np.float64(-2845.7414551036354), ((2,), (0,)): np.float64(-2845.7949545489964), ((2,), (2,)): np.float64(-2847.091214840578), ((2,), (3,)): np.float64(-2849.0563354269707), ((2,), (0, 2)): np.float64(-2847.091214837416), ((2,), (0, 3)): np.float64(-2849.1089597628948), ((2,), (2, 3)): np.float64(-2850.4382144926058), ((3,), ()): np.float64(-2845.9750241681745), ((3,), (0,)): np.float64(-2845.9671189085875), ((3,), (2,)): np.float64(-2847.270670722074), ((3,), (3,)): np.float64(-2849.28127516628), ((3,), (0, 2)): np.float64(-2847.2633791970065), ((3,), (0, 3)): np.float64(-2849.2811241224854), ((3,), (2, 3)): np.float64(-2850.61037884931), ((1, 2), ()): np.float64(-2845.741455103635), ((1, 2), (2,)): np.float64(-2847.091214837416), ((1, 2), (3,)): np.float64(-2849.047555057946), ((1, 2), (2, 3)): np.float64(-2850.430525056862), ((1, 3), ()): np.float64(-2845.9750241681745), ((1, 3), (2,)): np.float64(-2847.324783901956), ((1, 3), (3,)): np.float64(-2849.2811241224854), ((1, 3), (2, 3)): np.float64(-2850.664094121402), ((2, 3), ()): np.float64(-2849.0817533318423), ((2, 3), (0,)): np.float64(-2849.127563344539), ((2, 3), (2,)): np.float64(-2850.4315130686623), ((2, 3), (3,)): np.float64(-2852.387853286368), ((2, 3), (0, 2)): np.float64(-2850.423823632958), ((2, 3), (0, 3)): np.float64(-2852.4415685584368), ((2, 3), (2, 3)): np.float64(-2853.7708232882715)}, ((0, 2), ((0, 2),)): {((), ()): np.float64(-2859.879632213261), ((), (0,)): np.float64(-2859.879632213261), ((), (1,)): np.float64(-2861.1758925016798), ((), (3,)): np.float64(-2862.799413004349), ((), (0, 1)): np.float64(-2861.1758925016798), ((), (0, 3)): np.float64(-2862.799413004349), ((), (1, 3)): np.float64(-2864.1286677309827), ((1,), ()): np.float64(-2862.760868561608), ((1,), (0,)): np.float64(-2862.8143680069697), ((1,), (1,)): np.float64(-2864.1106282960227), ((1,), (3,)): np.float64(-2865.680017776065), ((1,), (0, 1)): np.float64(-2864.110628295389), ((1,), (0, 3)): np.float64(-2865.734148798058), ((1,), (1, 3)): np.float64(-2867.063403525371), ((2,), ()): np.float64(-2859.879632213261), ((2,), (1,)): np.float64(-2861.2293919470408), ((2,), (3,)): np.float64(-2862.8112463503003), ((2,), (1, 3)): np.float64(-2864.194216349217), ((3,), ()): np.float64(-2863.212241008803), ((3,), (0,)): np.float64(-2863.2240743547545), ((3,), (1,)): np.float64(-2864.507832053163), ((3,), (3,)): np.float64(-2866.144161714818), ((3,), (0, 1)): np.float64(-2864.5203346431745), ((3,), (0, 3)): np.float64(-2866.1438551458436), ((3,), (1, 3)): np.float64(-2867.4731098726243), ((1, 2), ()): np.float64(-2862.760868561608), ((1, 2), (1,)): np.float64(-2864.110628295389), ((1, 2), (3,)): np.float64(-2865.6924826986483), ((1, 2), (1, 3)): np.float64(-2867.075452697564), ((1, 3), ()): np.float64(-2866.101166789815), ((1, 3), (0,)): np.float64(-2866.1667154080505), ((1, 3), (1,)): np.float64(-2867.4509265243023), ((1, 3), (3,)): np.float64(-2869.032780927033), ((1, 3), (0, 1)): np.float64(-2867.462975696471), ((1, 3), (0, 3)): np.float64(-2869.0864961991406), ((1, 3), (1, 3)): np.float64(-2870.415750926642), ((2, 3), ()): np.float64(-2863.212241008803), ((2, 3), (1,)): np.float64(-2864.5620007425846), ((2, 3), (3,)): np.float64(-2866.143855145844), ((2, 3), (1, 3)): np.float64(-2867.5268251447596)}, ((0, 3), ((0, 3),)): {((), ()): np.float64(-2832.1405227241735), ((), (0,)): np.float64(-2832.1405227241735), ((), (1,)): np.float64(-2835.4545279380714), ((), (2,)): np.float64(-2835.060303515262), ((), (0, 1)): np.float64(-2835.4545279380714), ((), (0, 2)): np.float64(-2835.060303515262), ((), (1, 2)): np.float64(-2838.4073031673734), ((1,), ()): np.float64(-2835.083163777469), ((1,), (0,)): np.float64(-2835.0752585178816), ((1,), (1,)): np.float64(-2838.389293740974), ((1,), (2,)): np.float64(-2838.0023461750534), ((1,), (0, 1)): np.float64(-2838.3892637317804), ((1,), (0, 2)): np.float64(-2837.995039308971), ((1,), (1, 2)): np.float64(-2841.3420389610837), ((2,), ()): np.float64(-2835.300967160125), ((2,), (0,)): np.float64(-2835.3128005060767), ((2,), (1,)): np.float64(-2838.6157898839283), ((2,), (2,)): np.float64(-2838.232708016541), ((2,), (0, 1)): np.float64(-2838.6268057199745), ((2,), (0, 2)): np.float64(-2838.232581297166), ((2,), (1, 2)): np.float64(-2841.579707668653), ((3,), ()): np.float64(-2832.1405227241735), ((3,), (1,)): np.float64(-2835.446622678485), ((3,), (2,)): np.float64(-2835.072136861214), ((3,), (1, 2)): np.float64(-2838.41144708066), ((1, 2), ()): np.float64(-2838.1898929411373), ((1, 2), (0,)): np.float64(-2838.194036854424), ((1, 2), (1,)): np.float64(-2841.4959928954495), ((1, 2), (2,)): np.float64(-2841.121507078184), ((1, 2), (0, 1)): np.float64(-2841.508042068321), ((1, 2), (0, 2)): np.float64(-2841.113817645513), ((1, 2), (1, 2)): np.float64(-2844.4608172976314), ((1, 3), ()): np.float64(-2835.083163777469), ((1, 3), (1,)): np.float64(-2838.38926373178), ((1, 3), (2,)): np.float64(-2838.0147779145095), ((1, 3), (1, 2)): np.float64(-2841.354088133957), ((2, 3), ()): np.float64(-2835.300967160125), ((2, 3), (1,)): np.float64(-2838.607067114435), ((2, 3), (2,)): np.float64(-2838.232581297166), ((2, 3), (1, 2)): np.float64(-2841.5718915166117)}, ((1, 2), ((1, 2),)): {((), ()): np.float64(-2890.0159694021227), ((), (0,)): np.float64(-2893.1347477386644), ((), (1,)): np.float64(-2890.0159694021227), ((), (3,)): np.float64(-2892.980793804299), ((), (0, 1)): np.float64(-2893.1347477386644), ((), (0, 3)): np.float64(-2896.0875229679673), ((), (1, 3)): np.float64(-2892.9807938042995), ((0,), ()): np.float64(-2892.8972057504693), ((0,), (0,)): np.float64(-2896.069483554861), ((0,), (1,)): np.float64(-2892.9507051958303), ((0,), (3,)): np.float64(-2895.8614239631497), ((0,), (0, 1)): np.float64(-2896.0694835323734), ((0,), (0, 3)): np.float64(-2899.0222587834946), ((0,), (1, 3)): np.float64(-2895.9155295980077), ((2,), ()): np.float64(-2890.0159694021227), ((2,), (0,)): np.float64(-2893.1882471840254), ((2,), (3,)): np.float64(-2892.947583539163), ((2,), (0, 3)): np.float64(-2896.1080279751145), ((3,), ()): np.float64(-2893.355279621568), ((3,), (0,)): np.float64(-2896.4748479226555), ((3,), (1,)): np.float64(-2893.3220693564335), ((3,), (3,)): np.float64(-2896.286893795506), ((3,), (0, 1)): np.float64(-2896.4408476929752), ((3,), (0, 3)): np.float64(-2899.393622961189), ((3,), (1, 3)): np.float64(-2896.286893758609), ((0, 2), ()): np.float64(-2892.8972057504693), ((0, 2), (0,)): np.float64(-2896.0694835323734), ((0, 2), (3,)): np.float64(-2895.8288198875102), ((0, 2), (0, 3)): np.float64(-2898.9892643234634), ((0, 3), ()): np.float64(-2896.244205402581), ((0, 3), (0,)): np.float64(-2899.416483206028), ((0, 3), (1,)): np.float64(-2896.264710409729), ((0, 3), (3,)): np.float64(-2899.1758195795283), ((0, 3), (0, 1)): np.float64(-2899.3834887462717), ((0, 3), (0, 3)): np.float64(-2902.336264037811), ((0, 3), (1, 3)): np.float64(-2899.229534811906), ((2, 3), ()): np.float64(-2893.3552796215686), ((2, 3), (0,)): np.float64(-2896.527557403472), ((2, 3), (3,)): np.float64(-2896.286893758609), ((2, 3), (0, 3)): np.float64(-2899.447338194561)}, ((1, 3), ((1, 3),)): {((), ()): np.float64(-2864.0610357739747), ((), (0,)): np.float64(-2867.4133831750555), ((), (1,)): np.float64(-2864.0610357739747), ((), (2,)): np.float64(-2867.0258601761493), ((), (0, 1)): np.float64(-2867.413383175056), ((), (0, 2)): np.float64(-2870.366158404358), ((), (1, 2)): np.float64(-2867.0258601761493), ((0,), ()): np.float64(-2867.0036768272694), ((0,), (0,)): np.float64(-2870.348149581849), ((0,), (1,)): np.float64(-2866.995771567683), ((0,), (2,)): np.float64(-2869.9679301587576), ((0,), (0, 1)): np.float64(-2870.3481189687645), ((0,), (0, 2)): np.float64(-2873.3008941980684), ((0,), (1, 2)): np.float64(-2869.9605959698592), ((2,), ()): np.float64(-2865.4440057728893), ((2,), (0,)): np.float64(-2868.7957530967), ((2,), (1,)): np.float64(-2865.410795507755), ((2,), (2,)): np.float64(-2868.375619909937), ((2,), (0, 1)): np.float64(-2868.763142908837), ((2,), (0, 2)): np.float64(-2871.715918138145), ((2,), (1, 2)): np.float64(-2868.3756199099307), ((3,), ()): np.float64(-2864.0610357739747), ((3,), (0,)): np.float64(-2867.405477915469), ((3,), (2,)): np.float64(-2866.9926499110143), ((3,), (0, 2)): np.float64(-2870.325258706557), ((0, 2), ()): np.float64(-2868.332931553903), ((0, 2), (0,)): np.float64(-2871.6773736953974), ((0, 2), (1,)): np.float64(-2868.2920318561023), ((0, 2), (2,)): np.float64(-2871.2645456909486), ((0, 2), (0, 1)): np.float64(-2871.6443792571836), ((0, 2), (0, 2)): np.float64(-2874.597154486493), ((0, 2), (1, 2)): np.float64(-2871.2568562582783), ((0, 3), ()): np.float64(-2867.0036768272694), ((0, 3), (0,)): np.float64(-2870.3481189687645), ((0, 3), (2,)): np.float64(-2869.9352909643103), ((0, 3), (0, 2)): np.float64(-2873.267899759854), ((2, 3), ()): np.float64(-2865.44400577289), ((2, 3), (0,)): np.float64(-2868.7884479143845), ((2, 3), (2,)): np.float64(-2868.375619909931), ((2, 3), (0, 2)): np.float64(-2871.7082287054736)}, ((2, 3), ((2, 3),)): {((), ()): np.float64(-2880.705963414677), ((), (0,)): np.float64(-2884.03857221022), ((), (1,)): np.float64(-2884.0452736341226), ((), (2,)): np.float64(-2880.705963414677), ((), (0, 1)): np.float64(-2887.3855718623304), ((), (0, 2)): np.float64(-2884.03857221022), ((), (1, 2)): np.float64(-2884.045273634122), ((0,), ()): np.float64(-2883.8664078506285), ((0,), (0,)): np.float64(-2887.2108499922556), ((0,), (1,)): np.float64(-2887.206459173482), ((0,), (2,)): np.float64(-2883.878241196581), ((0,), (0, 1)): np.float64(-2890.5578496443522), ((0,), (0, 2)): np.float64(-2887.210849992123), ((0,), (1, 2)): np.float64(-2887.2175514160263), ((1,), ()): np.float64(-2882.0889334135936), ((1,), (0,)): np.float64(-2885.4208851144667), ((1,), (1,)): np.float64(-2885.3950333680427), ((1,), (2,)): np.float64(-2882.0557231484586), ((1,), (0, 1)): np.float64(-2888.735331596257), ((1,), (0, 2)): np.float64(-2885.3883319440015), ((1,), (1, 2)): np.float64(-2885.3950333679036), ((3,), ()): np.float64(-2880.705963414677), ((3,), (0,)): np.float64(-2884.050405556171), ((3,), (1,)): np.float64(-2884.012063368987), ((3,), (0, 1)): np.float64(-2887.36441077007), ((0, 1), ()): np.float64(-2885.195662577262), ((0, 1), (0,)): np.float64(-2888.540104718865), ((0, 1), (1,)): np.float64(-2888.501762531721), ((0, 1), (2,)): np.float64(-2885.1745014849994), ((0, 1), (0, 1)): np.float64(-2891.854109932904), ((0, 1), (0, 2)): np.float64(-2888.5071102805423), ((0, 1), (1, 2)): np.float64(-2888.5138117044453), ((0, 3), ()): np.float64(-2883.8664078506285), ((0, 3), (0,)): np.float64(-2887.210849992123), ((0, 3), (1,)): np.float64(-2887.1725078049394), ((0, 3), (0, 1)): np.float64(-2890.524855206022), ((1, 3), ()): np.float64(-2882.088933413594), ((1, 3), (0,)): np.float64(-2885.4333755550874), ((1, 3), (1,)): np.float64(-2885.3950333679036), ((1, 3), (0, 1)): np.float64(-2888.747380768986)}, ((0, 1, 2), ((0, 1), (0, 2))): {((), (), ()): np.float64(-4298.584266666792), ((), (), (1,)): np.float64(-4299.934026053182), ((), (), (3,)): np.float64(-4301.503415479612), ((), (), (1, 3)): np.float64(-4302.886801269934), ((), (2,), ()): np.float64(-4299.934026137251), ((), (2,), (3,)): np.float64(-4302.854198376931), ((), (3,), ()): np.float64(-4301.899146610008), ((), (3,), (1,)): np.float64(-4303.248468637315), ((), (3,), (3,)): np.float64(-4304.817823555224), ((), (3,), (1, 3)): np.float64(-4306.200806133898), ((), (2, 3), ()): np.float64(-4303.281025792843), ((), (2, 3), (3,)): np.float64(-4306.200806225923), ((3,), (), ()): np.float64(-4301.924564895), ((3,), (), (1,)): np.float64(-4303.2743242742845), ((3,), (), (3,)): np.float64(-4304.856178636838), ((3,), (), (1, 3)): np.float64(-4306.239148676656), ((3,), (2,), ()): np.float64(-4303.274324356484), ((3,), (2,), (3,)): np.float64(-4306.205938162526), ((3,), (3,), ()): np.float64(-4305.230664454193), ((3,), (3,), (1,)): np.float64(-4306.580423874185), ((3,), (3,), (3,)): np.float64(-4308.162278195715), ((3,), (3,), (1, 3)): np.float64(-4309.545248275821), ((3,), (2, 3), ()): np.float64(-4306.613634575748), ((3,), (2, 3), (3,)): np.float64(-4309.545248380851)}, ((0, 1, 2), ((0, 1), (1, 2))): {((), (), ()): np.float64(-4296.761748618669), ((), (), (0,)): np.float64(-4299.934024227497), ((), (), (3,)): np.float64(-4299.725964392937), ((), (), (0, 3)): np.float64(-4302.8867994900875), ((), (3,), ()): np.float64(-4300.108748270781), ((), (3,), (0,)): np.float64(-4303.281023938342), ((), (3,), (3,)): np.float64(-4303.040360044629), ((), (3,), (0, 3)): np.float64(-4306.200804776705), ((2,), (), ()): np.float64(-4299.934024011581), ((2,), (), (3,)): np.float64(-4302.897821579393), ((2,), (3,), ()): np.float64(-4303.28102372854), ((2,), (3,), (3,)): np.float64(-4306.212635564924), ((3,), (), ()): np.float64(-4300.113479856816), ((3,), (), (0,)): np.float64(-4303.285418949365), ((3,), (), (3,)): np.float64(-4303.078684167837), ((3,), (), (0, 3)): np.float64(-4306.239144753507), ((3,), (3,), ()): np.float64(-4303.453188021429), ((3,), (3,), (0,)): np.float64(-4306.625463903672), ((3,), (3,), (3,)): np.float64(-4306.384802334807), ((3,), (3,), (0, 3)): np.float64(-4309.545247053757), ((2, 3), (), ()): np.float64(-4303.274322271082), ((2, 3), (), (3,)): np.float64(-4306.239144367424), ((2, 3), (3,), ()): np.float64(-4306.613632525905), ((2, 3), (3,), (3,)): np.float64(-4309.545246830465)}, ((0, 1, 2), ((0, 2), (1, 2))): {((), (), ()): np.float64(-4296.9992906068655), ((), (), (3,)): np.float64(-4299.952065836168), ((), (0,), ()): np.float64(-4299.9340251898075), ((), (0,), (3,)): np.float64(-4302.886800388572), ((), (3,), ()): np.float64(-4300.3393893780385), ((), (3,), (3,)): np.float64(-4303.258164364812), ((), (0, 3), ()): np.float64(-4303.281024859106), ((), (0, 3), (3,)): np.float64(-4306.200805642114), ((1,), (), ()): np.float64(-4299.934024986493), ((1,), (), (3,)): np.float64(-4302.886800188039), ((1,), (3,), ()): np.float64(-4303.273713665789), ((1,), (3,), (3,)): np.float64(-4306.19289875355), ((3,), (), ()): np.float64(-4300.3312286604105), ((3,), (), (3,)): np.float64(-4303.296506505978), ((3,), (0,), ()): np.float64(-4303.266995395911), ((3,), (0,), (3,)): np.float64(-4306.231241284356), ((3,), (3,), ()): np.float64(-4303.670933620035), ((3,), (3,), (3,)): np.float64(-4306.602605047428), ((3,), (0, 3), ()): np.float64(-4306.613632353832), ((3,), (0, 3), (3,)): np.float64(-4309.545246547724), ((1, 3), (), ()): np.float64(-4303.2743231626355), ((1, 3), (), (3,)): np.float64(-4306.2391475891145), ((1, 3), (3,), ()): np.float64(-4306.61363197341), ((1, 3), (3,), (3,)): np.float64(-4309.545246166838)}, ((0, 1, 2), ((0, 1), (0, 2), (1, 2))): {((), (), ()): np.float64(-4299.9340263937065), ((), (), (3,)): np.float64(-4302.886801622903), ((), (3,), ()): np.float64(-4303.281026045969), ((), (3,), (3,)): np.float64(-4306.200806877709), ((3,), (), ()): np.float64(-4303.274324622017), ((3,), (), (3,)): np.float64(-4306.239149024329), ((3,), (3,), ()): np.float64(-4306.613634841654), ((3,), (3,), (3,)): np.float64(-4309.545251251069)}, ((0, 1, 3), ((0, 1), (0, 3))): {((), (), ()): np.float64(-4270.906561882655), ((), (), (1,)): np.float64(-4274.2126617315835), ((), (), (2,)): np.float64(-4273.825744014834), ((), (), (1, 2)): np.float64(-4277.165436948298), ((), (2,), ()): np.float64(-4272.2022083209), ((), (2,), (1,)): np.float64(-4275.507917756722), ((), (2,), (2,)): np.float64(-4275.122391194793), ((), (2,), (1, 2)): np.float64(-4278.461697094224), ((), (3,), ()): np.float64(-4274.212661716632), ((), (3,), (2,)): np.float64(-4277.131378982916), ((), (2, 3), ()): np.float64(-4275.541916430528), ((), (2, 3), (2,)): np.float64(-4278.461697056518), ((2,), (), ()): np.float64(-4274.013291046322), ((2,), (), (1,)): np.float64(-4277.31939086969), ((2,), (), (2,)): np.float64(-4276.94490505451), ((2,), (), (1, 2)): np.float64(-4280.284215272236), ((2,), (2,), ()): np.float64(-4275.363050653373), ((2,), (2,), (1,)): np.float64(-4278.669150475437), ((2,), (2,), (2,)): np.float64(-4278.294664665106), ((2,), (2,), (1, 2)): np.float64(-4281.633974881171), ((2,), (3,), ()): np.float64(-4277.31939085121), ((2,), (3,), (2,)): np.float64(-4280.2510048495105), ((2,), (2, 3), ()): np.float64(-4278.702360855011), ((2,), (2, 3), (2,)): np.float64(-4281.633974858188)}, ((0, 1, 3), ((0, 1), (1, 3))): {((), (), ()): np.float64(-4270.86821969547), ((), (), (0,)): np.float64(-4274.21266168357), ((), (), (2,)): np.float64(-4273.832472730344), ((), (), (0, 2)): np.float64(-4277.165436946648), ((), (2,), ()): np.float64(-4272.197474422103), ((), (2,), (0,)): np.float64(-4275.5419164328005), ((), (2,), (2,)): np.float64(-4275.129088438756), ((), (2,), (0, 2)): np.float64(-4278.461697223941), ((2,), (), ()): np.float64(-4273.9878729842885), ((2,), (), (0,)): np.float64(-4277.331903869599), ((2,), (), (2,)): np.float64(-4276.951638611482), ((2,), (), (0, 2)): np.float64(-4280.284215146118), ((2,), (2,), ()): np.float64(-4275.36975208637), ((2,), (2,), (0,)): np.float64(-4278.714194095241), ((2,), (2,), (2,)): np.float64(-4278.3013662681615), ((2,), (2,), (0, 2)): np.float64(-4281.633975054022), ((3,), (), ()): np.float64(-4274.212661686455), ((3,), (), (2,)): np.float64(-4277.177885262624), ((3,), (2,), ()): np.float64(-4275.541916435), ((3,), (2,), (2,)): np.float64(-4278.473530444039), ((2, 3), (), ()): np.float64(-4277.319390833709), ((2, 3), (), (2,)): np.float64(-4280.284215142136), ((2, 3), (2,), ()): np.float64(-4278.702360873562), ((2, 3), (2,), (2,)): np.float64(-4281.633975056515)}, ((0, 1, 3), ((0, 3), (1, 3))): {((), (), ()): np.float64(-4271.277926043255), ((), (), (2,)): np.float64(-4274.230701272558), ((), (0,), ()): np.float64(-4274.21266180636), ((), (0,), (2,)): np.float64(-4277.165437040301), ((), (2,), ()): np.float64(-4272.660295942927), ((), (2,), (2,)): np.float64(-4275.580460982007), ((), (0, 2), ()): np.float64(-4275.541916540185), ((), (0, 2), (2,)): np.float64(-4278.46169732876), ((1,), (), ()): np.float64(-4274.212691846159), ((1,), (), (2,)): np.float64(-4277.165437040211), ((1,), (2,), ()): np.float64(-4275.59599678693), ((1,), (2,), (2,)): np.float64(-4278.515196748156), ((2,), (), ()): np.float64(-4274.439187989112), ((2,), (), (2,)): np.float64(-4277.402979030041), ((2,), (0,), ()): np.float64(-4277.373516475633), ((2,), (0,), (2,)): np.float64(-4280.33771479627), ((2,), (2,), ()): np.float64(-4275.821132399729), ((2,), (2,), (2,)): np.float64(-4278.752738739626), ((2,), (0, 2), ()): np.float64(-4278.70236094761), ((2,), (0, 2), (2,)): np.float64(-4281.633975084789), ((1, 2), (), ()): np.float64(-4277.319390967039), ((1, 2), (), (2,)): np.float64(-4280.284215376686), ((1, 2), (2,), ()): np.float64(-4278.702360947404), ((1, 2), (2,), (2,)): np.float64(-4281.6339750845855)}, ((0, 1, 3), ((0, 1), (0, 3), (1, 3))): {((), (), ()): np.float64(-4274.212661836587), ((), (), (2,)): np.float64(-4277.165437065881), ((), (2,), ()): np.float64(-4275.541916563218), ((), (2,), (2,)): np.float64(-4278.461697354304), ((2,), (), ()): np.float64(-4277.319391000166), ((2,), (), (2,)): np.float64(-4280.284215402349), ((2,), (2,), ()): np.float64(-4278.702361002129), ((2,), (2,), (2,)): np.float64(-4281.633975328886)}, ((0, 2, 3), ((2, 3), (0, 2))): {((), (), ()): np.float64(-4287.730950718828), ((), (), (0,)): np.float64(-4291.0753925659155), ((), (), (1,)): np.float64(-4291.071001747969), ((), (), (0, 1)): np.float64(-4294.422392235417), ((), (1,), ()): np.float64(-4289.060205445461), ((), (1,), (0,)): np.float64(-4292.4046472591945), ((), (1,), (1,)): np.float64(-4292.366305051893), ((), (1,), (0, 1)): np.float64(-4295.718652472884), ((1,), (), ()): np.float64(-4290.611555117876), ((1,), (), (0,)): np.float64(-4293.957048030114), ((1,), (), (1,)): np.float64(-4293.951230690351), ((1,), (), (0, 1)): np.float64(-4297.303628191767), ((1,), (1,), ()): np.float64(-4291.994940892351), ((1,), (1,), (0,)): np.float64(-4295.339382719188), ((1,), (1,), (1,)): np.float64(-4295.3010406182475), ((1,), (1,), (0, 1)): np.float64(-4298.653388047001), ((3,), (), ()): np.float64(-4291.075392554632), ((3,), (), (1,)): np.float64(-4294.415088209922), ((3,), (1,), ()): np.float64(-4292.40464724827), ((3,), (1,), (1,)): np.float64(-4295.710746863983), ((1, 3), (), ()): np.float64(-4293.964318278357), ((1, 3), (), (1,)): np.float64(-4297.3036281768), ((1, 3), (1,), ()): np.float64(-4295.347288302342), ((1, 3), (1,), (1,)): np.float64(-4298.653388034011)}, ((0, 2, 3), ((2, 3), (0, 3))): {((), (), ()): np.float64(-4287.90311507842), ((), (), (1,)): np.float64(-4291.25011473053), ((), (0,), ()): np.float64(-4291.0753927435135), ((), (0,), (1,)): np.float64(-4294.422392409242), ((), (1,), ()): np.float64(-4289.285427860382), ((), (1,), (1,)): np.float64(-4292.599874350549), ((), (0, 1), ()): np.float64(-4292.404647477328), ((), (0, 1), (1,)): np.float64(-4295.718652699197), ((1,), (), ()): np.float64(-4290.845157467598), ((1,), (), (1,)): np.float64(-4294.184850409882), ((1,), (0,), ()): np.float64(-4294.017060764009), ((1,), (0,), (1,)): np.float64(-4297.3571280999), ((1,), (1,), ()): np.float64(-4292.228506426112), ((1,), (1,), (1,)): np.float64(-4295.5346100305815), ((1,), (0, 1), ()): np.float64(-4295.347288436686), ((1,), (0, 1), (1,)): np.float64(-4298.653388391332), ((2,), (), ()): np.float64(-4291.075392733557), ((2,), (), (1,)): np.float64(-4294.422392400416), ((2,), (1,), ()): np.float64(-4292.457307902875), ((2,), (1,), (1,)): np.float64(-4295.772152023513), ((1, 2), (), ()): np.float64(-4293.964318522573), ((1, 2), (), (1,)): np.float64(-4297.303628749131), ((1, 2), (1,), ()): np.float64(-4295.3472884180155), ((1, 2), (1,), (1,)): np.float64(-4298.653388372669)}, ((0, 2, 3), ((0, 2), (0, 3))): {((), (), ()): np.float64(-4288.143778723282), ((), (), (1,)): np.float64(-4291.458601380849), ((), (), (2,)): np.float64(-4291.07539279203), ((), (), (1, 2)): np.float64(-4294.4223924483995), ((), (1,), ()): np.float64(-4289.439369682604), ((), (1,), (1,)): np.float64(-4292.753815336827), ((), (1,), (2,)): np.float64(-4292.372039833357), ((), (1,), (1, 2)): np.float64(-4295.718652648269), ((), (3,), ()): np.float64(-4291.075392802842), ((), (3,), (1,)): np.float64(-4294.389773461316), ((), (1, 3), ()): np.float64(-4292.40464751887), ((), (1, 3), (1,)): np.float64(-4295.718652672522), ((1,), (), ()): np.float64(-4291.032704504295), ((1,), (), (1,)): np.float64(-4294.338804379288), ((1,), (), (2,)): np.float64(-4293.964318564975), ((1,), (), (1, 2)): np.float64(-4297.303628784351), ((1,), (1,), ()): np.float64(-4292.382464160041), ((1,), (1,), (1,)): np.float64(-4295.688564035525), ((1,), (1,), (2,)): np.float64(-4295.314078223932), ((1,), (1,), (1, 2)): np.float64(-4298.65338844342), ((1,), (3,), ()): np.float64(-4293.9643185792065), ((1,), (3,), (1,)): np.float64(-4297.270418463014), ((1,), (1, 3), ()): np.float64(-4295.3472885788005), ((1,), (1, 3), (1,)): np.float64(-4298.653388462728)}, ((0, 2, 3), ((2, 3), (0, 2), (0, 3))): {((), (), ()): np.float64(-4291.075392859852), ((), (), (1,)): np.float64(-4294.42239251197), ((), (1,), ()): np.float64(-4292.404647586387), ((), (1,), (1,)): np.float64(-4295.718652800435), ((1,), (), ()): np.float64(-4293.964318640704), ((1,), (), (1,)): np.float64(-4297.30362886015), ((1,), (1,), ()): np.float64(-4295.347288640336), ((1,), (1,), (1,)): np.float64(-4298.653388712505)}, ((1, 2, 3), ((2, 3), (1, 2))): {((), (), ()): np.float64(-4317.912331518778), ((), (), (0,)): np.float64(-4321.244281144335), ((), (), (1,)): np.float64(-4321.218429275868), ((), (), (0, 1)): np.float64(-4324.558727452133), ((), (0,), ()): np.float64(-4321.019060682447), ((), (0,), (0,)): np.float64(-4324.363500695146), ((), (0,), (1,)): np.float64(-4324.325158324421), ((), (0,), (0, 1)): np.float64(-4327.677505726987), ((0,), (), ()): np.float64(-4320.792959612713), ((0,), (), (0,)): np.float64(-4324.125975971891), ((0,), (), (1,)): np.float64(-4324.098617748997), ((0,), (), (0, 1)): np.float64(-4327.439961598099), ((0,), (0,), ()): np.float64(-4323.953794386074), ((0,), (0,), (0,)): np.float64(-4327.298234667529), ((0,), (0,), (1,)): np.float64(-4327.259891990307), ((0,), (0,), (0, 1)): np.float64(-4330.612239671496), ((3,), (), ()): np.float64(-4321.218429374817), ((3,), (), (0,)): np.float64(-4324.549931264757), ((3,), (0,), ()): np.float64(-4324.325158428914), ((3,), (0,), (0,)): np.float64(-4327.669598292975), ((0, 3), (), ()): np.float64(-4324.1073551028985), ((0, 3), (), (0,)): np.float64(-4327.439961576197), ((0, 3), (0,), ()): np.float64(-4327.267799512477), ((0, 3), (0,), (0,)): np.float64(-4330.612239669724)}, ((1, 2, 3), ((2, 3), (1, 3))): {((), (), ()): np.float64(-4319.8686717393075), ((), (), (0,)): np.float64(-4323.208969967515), ((), (0,), ()): np.float64(-4323.029857163997), ((), (0,), (0,)): np.float64(-4326.381247641553), ((), (1,), ()): np.float64(-4321.21843132866), ((), (1,), (0,)): np.float64(-4324.558729561428), ((), (0, 1), ()): np.float64(-4324.325160488742), ((), (0, 1), (0,)): np.float64(-4327.677507897715), ((0,), (), ()): np.float64(-4322.810741430323), ((0,), (), (0,)): np.float64(-4326.143705653227), ((0,), (0,), ()): np.float64(-4325.971547856517), ((0,), (0,), (0,)): np.float64(-4329.315983327503), ((0,), (1,), ()): np.float64(-4324.161512524075), ((0,), (1,), (0,)): np.float64(-4327.493465215479), ((0,), (0, 1), ()): np.float64(-4327.267801409685), ((0,), (0, 1), (0,)): np.float64(-4330.612243551485), ((2,), (), ()): np.float64(-4321.218431353323), ((2,), (), (0,)): np.float64(-4324.55872958691), ((2,), (0,), ()): np.float64(-4324.379277819871), ((2,), (0,), (0,)): np.float64(-4327.731007254964), ((0, 2), (), ()): np.float64(-4324.10735714234), ((0, 2), (), (0,)): np.float64(-4327.439965935312), ((0, 2), (0,), ()): np.float64(-4327.267801461699), ((0, 2), (0,), (0,)): np.float64(-4330.612243603487)}, ((1, 2, 3), ((1, 2), (1, 3))): {((), (), ()): np.float64(-4318.286817336048), ((), (), (0,)): np.float64(-4321.6385642150835), ((), (), (2,)): np.float64(-4321.21843099205), ((), (), (0, 2)): np.float64(-4324.558729252026), ((), (0,), ()): np.float64(-4321.406385151658), ((), (0,), (0,)): np.float64(-4324.757758608874), ((), (0,), (2,)): np.float64(-4324.3375963958615), ((), (0,), (0, 2)): np.float64(-4327.677507113667), ((), (3,), ()): np.float64(-4321.218430711477), ((), (3,), (0,)): np.float64(-4324.571181706941), ((), (0, 3), ()): np.float64(-4324.325159854549), ((), (0, 3), (0,)): np.float64(-4327.677506728218), ((0,), (), ()): np.float64(-4321.175743117061), ((0,), (), (0,)): np.float64(-4324.520184804303), ((0,), (), (2,)): np.float64(-4324.107356793668), ((0,), (), (0, 2)): np.float64(-4327.4399655892485), ((0,), (0,), ()): np.float64(-4324.348020466028), ((0,), (0,), (0,)): np.float64(-4327.692462154105), ((0,), (0,), (2,)): np.float64(-4327.2796341371695), ((0,), (0,), (0, 2)): np.float64(-4330.612242933171), ((0,), (3,), ()): np.float64(-4324.107356509892), ((0,), (3,), (0,)): np.float64(-4327.4517980575365), ((0,), (0, 3), ()): np.float64(-4327.267800966796), ((0,), (0, 3), (0,)): np.float64(-4330.612242513076)}, ((1, 2, 3), ((2, 3), (1, 2), (1, 3))): {((), (), ()): np.float64(-4321.218431453986), ((), (), (0,)): np.float64(-4324.5587296822605), ((), (0,), ()): np.float64(-4324.32516061667), ((), (0,), (0,)): np.float64(-4327.677508017916), ((0,), (), ()): np.float64(-4324.107357234091), ((0,), (), (0,)): np.float64(-4327.43996602963), ((0,), (0,), ()): np.float64(-4327.2678016922055), ((0,), (0,), (0,)): np.float64(-4330.6122441162415)}, ((0, 1, 2, 3), ((0, 1), (1, 2), (0, 3))): {((), (), (), ()): np.float64(-5725.045019999709), ((), (), (), (1,)): np.float64(-5728.350729437648), ((), (), (), (2,)): np.float64(-5727.965202886506), ((), (), (), (1, 2)): np.float64(-5731.304508787663), ((), (), (0,), ()): np.float64(-5728.2169588732195), ((), (), (0,), (1,)): np.float64(-5731.523051364601), ((), (), (0,), (2,)): np.float64(-5731.137122625535), ((), (), (0,), (1, 2)): np.float64(-5734.47678440359), ((), (), (3,), ()): np.float64(-5728.010224272381), ((), (), (3,), (1,)): np.float64(-5731.315938091435), ((), (), (0, 3), ()): np.float64(-5731.170684639385), ((), (), (0, 3), (1,)): np.float64(-5734.476784450568), ((), (3,), (), ()): np.float64(-5728.384727994207), ((), (3,), (), (2,)): np.float64(-5731.304508620257), ((), (3,), (0,), ()): np.float64(-5731.557003684504), ((), (3,), (0,), (2,)): np.float64(-5734.47678432695), ((), (3,), (3,), ()): np.float64(-5731.316338761435), ((), (3,), (0, 3), ()): np.float64(-5734.476783550694), ((2,), (), (), ()): np.float64(-5728.2058599848615), ((2,), (), (), (1,)): np.float64(-5731.511959772615), ((2,), (), (), (2,)): np.float64(-5731.137473996458), ((2,), (), (), (1, 2)): np.float64(-5734.4767841822695), ((2,), (), (3,), ()): np.float64(-5731.170682082306), ((2,), (), (3,), (1,)): np.float64(-5734.476781836191), ((2,), (3,), (), ()): np.float64(-5731.545170093825), ((2,), (3,), (), (2,)): np.float64(-5734.476784096998), ((2,), (3,), (3,), ()): np.float64(-5734.476780884611)}, ((0, 1, 2, 3), ((0, 1), (1, 2), (2, 3))): {((), (), (), ()): np.float64(-5724.657504545076), ((), (), (), (0,)): np.float64(-5727.990520953733), ((), (), (), (1,)): np.float64(-5727.96316275593), ((), (), (), (0, 1)): np.float64(-5731.304506652211), ((), (), (0,), ()): np.float64(-5727.818337206787), ((), (), (0,), (0,)): np.float64(-5731.16277749286), ((), (), (0,), (1,)): np.float64(-5731.124434844741), ((), (), (0,), (0, 1)): np.float64(-5734.476782529495), ((), (3,), (), ()): np.float64(-5727.971897969915), ((), (3,), (), (0,)): np.float64(-5731.304504444342), ((), (3,), (0,), ()): np.float64(-5731.132340253874), ((), (3,), (0,), (0,)): np.float64(-5734.476780416295), ((2,), (), (), ()): np.float64(-5727.829361672318), ((2,), (), (), (0,)): np.float64(-5731.162372895032), ((2,), (), (), (1,)): np.float64(-5731.135451156689), ((2,), (), (), (0, 1)): np.float64(-5734.476782334388), ((2,), (3,), (), ()): np.float64(-5731.144173483121), ((2,), (3,), (), (0,)): np.float64(-5734.47678001802), ((3,), (), (), ()): np.float64(-5728.010224285214), ((3,), (), (), (1,)): np.float64(-5731.315885734477), ((3,), (), (0,), ()): np.float64(-5731.170682470171), ((3,), (), (0,), (1,)): np.float64(-5734.476780111951), ((3,), (3,), (), ()): np.float64(-5731.31634025957), ((3,), (3,), (0,), ()): np.float64(-5734.476782530901), ((2, 3), (), (), ()): np.float64(-5731.170684423874), ((2, 3), (), (), (1,)): np.float64(-5734.476782421877), ((2, 3), (3,), (), ()): np.float64(-5734.476784747956)}, ((0, 1, 2, 3), ((0, 1), (1, 2), (1, 3))): {((), (), (), ()): np.float64(-5725.04028598526), ((), (), (), (0,)): np.float64(-5728.384727542851), ((), (), (), (2,)): np.float64(-5727.971899542623), ((), (), (), (0, 2)): np.float64(-5731.304508327861), ((), (), (0,), ()): np.float64(-5728.21256120172), ((), (), (0,), (0,)): np.float64(-5731.557002743008), ((), (), (0,), (2,)): np.float64(-5731.14417473417), ((), (), (0,), (0, 2)): np.float64(-5734.4767834897175), ((), (), (3,), ()): np.float64(-5727.97189694567), ((), (), (3,), (0,)): np.float64(-5731.316338289048), ((), (), (0, 3), ()): np.float64(-5731.132341678947), ((), (), (0, 3), (0,)): np.float64(-5734.476783038202), ((2,), (), (), ()): np.float64(-5728.212561323855), ((2,), (), (), (0,)): np.float64(-5731.557002860816), ((2,), (), (), (2,)): np.float64(-5731.1441750573895), ((2,), (), (), (0, 2)): np.float64(-5734.476783811973), ((2,), (), (3,), ()): np.float64(-5731.144172332596), ((2,), (), (3,), (0,)): np.float64(-5734.477270901343), ((3,), (), (), ()): np.float64(-5728.384725608818), ((3,), (), (), (2,)): np.float64(-5731.316339128251), ((3,), (), (0,), ()): np.float64(-5731.557001021996), ((3,), (), (0,), (2,)): np.float64(-5734.477273731114), ((3,), (), (3,), ()): np.float64(-5731.316336493429), ((3,), (), (0, 3), ()): np.float64(-5734.47678146198), ((2, 3), (), (), ()): np.float64(-5731.545170112856), ((2, 3), (), (), (2,)): np.float64(-5734.476783814898), ((2, 3), (), (3,), ()): np.float64(-5734.476781080473)}, ((0, 1, 2, 3), ((0, 1), (0, 3), (2, 3))): {((), (), (), ()): np.float64(-5726.66855569472), ((), (), (), (1,)): np.float64(-5730.00824851133), ((), (), (0,), ()): np.float64(-5729.8404589789225), ((), (), (0,), (1,)): np.float64(-5733.180526201654), ((), (), (1,), ()): np.float64(-5728.051904645241), ((), (), (1,), (1,)): np.float64(-5731.358008131553), ((), (), (0, 1), ()): np.float64(-5731.1706866436925), ((), (), (0, 1), (1,)): np.float64(-5734.476786492688), ((), (2,), (), ()): np.float64(-5727.965202886407), ((), (2,), (), (1,)): np.float64(-5731.304508657253), ((), (2,), (0,), ()): np.float64(-5731.137086020815), ((), (2,), (0,), (1,)): np.float64(-5734.47678636163), ((), (3,), (), ()): np.float64(-5729.974190671584), ((), (3,), (0,), ()): np.float64(-5733.14652129096), ((), (3,), (1,), ()): np.float64(-5731.357553637098), ((), (3,), (0, 1), ()): np.float64(-5734.4767864696), ((), (2, 3), (), ()): np.float64(-5731.304508756951), ((), (2, 3), (0,), ()): np.float64(-5734.476786449391), ((2,), (), (), ()): np.float64(-5729.7877166278895), ((2,), (), (), (1,)): np.float64(-5733.127026723738), ((2,), (), (1,), ()): np.float64(-5731.170686523325), ((2,), (), (1,), (1,)): np.float64(-5734.476786347274), ((2,), (2,), (), ()): np.float64(-5731.13747623708), ((2,), (2,), (), (1,)): np.float64(-5734.476786331899), ((2,), (3,), (), ()): np.float64(-5733.09381642368), ((2,), (3,), (1,), ()): np.float64(-5734.4767863113075), ((2,), (2, 3), (), ()): np.float64(-5734.476786430816)}, ((0, 1, 2, 3), ((0, 1), (0, 3), (0, 2))): {((), (), (), ()): np.float64(-5726.8561026094785), ((), (), (), (1,)): np.float64(-5730.162202353729), ((), (), (), (2,)): np.float64(-5729.787716541492), ((), (), (), (1, 2)): np.float64(-5733.12702675915), ((), (), (1,), ()): np.float64(-5728.205861910229), ((), (), (1,), (1,)): np.float64(-5731.511961662023), ((), (), (1,), (2,)): np.float64(-5731.137475870236), ((), (), (1,), (1, 2)): np.float64(-5734.476786082809), ((), (), (3,), ()): np.float64(-5729.7877162892255), ((), (), (3,), (1,)): np.float64(-5733.093816051028), ((), (), (1, 3), ()): np.float64(-5731.170686329009), ((), (), (1, 3), (1,)): np.float64(-5734.476786102103), ((), (2,), (), ()): np.float64(-5728.205861942625), ((), (2,), (), (1,)): np.float64(-5731.511961693858), ((), (2,), (), (2,)): np.float64(-5731.137475899566), ((), (2,), (), (1, 2)): np.float64(-5734.476786111658), ((), (2,), (3,), ()): np.float64(-5731.137475707166), ((), (2,), (3,), (1,)): np.float64(-5734.479569812833), ((), (3,), (), ()): np.float64(-5730.162202019331), ((), (3,), (), (2,)): np.float64(-5733.093815950561), ((), (3,), (1,), ()): np.float64(-5731.51196136974), ((), (3,), (1,), (2,)): np.float64(-5734.479569665042), ((), (3,), (3,), ()): np.float64(-5733.093815702855), ((), (3,), (1, 3), ()): np.float64(-5734.476785795929), ((), (2, 3), (), ()): np.float64(-5731.545172144013), ((), (2, 3), (), (2,)): np.float64(-5734.476786088206), ((), (2, 3), (3,), ()): np.float64(-5734.476785900024)}, ((0, 1, 2, 3), ((0, 1), (2, 3), (0, 2))): {((), (), (), ()): np.float64(-5726.434953595728), ((), (), (), (0,)): np.float64(-5729.780446493722), ((), (), (), (1,)): np.float64(-5729.7746291459525), ((), (), (), (0, 1)): np.float64(-5733.127026635359), ((), (), (1,), ()): np.float64(-5727.818338984773), ((), (), (1,), (0,)): np.float64(-5731.162780812), ((), (), (1,), (1,)): np.float64(-5731.124438710248), ((), (), (1,), (0, 1)): np.float64(-5734.4767861394075), ((), (2,), (), ()): np.float64(-5727.785736427042), ((), (2,), (), (0,)): np.float64(-5731.130170479146), ((), (2,), (), (1,)): np.float64(-5731.125383669243), ((), (2,), (), (0, 1)): np.float64(-5734.476786158534), ((), (3,), (), ()): np.float64(-5729.749361665163), ((), (3,), (), (0,)): np.float64(-5733.094847786097), ((), (3,), (1,), ()): np.float64(-5731.132343848734), ((), (3,), (1,), (0,)): np.float64(-5734.476785687963), ((), (2, 3), (), ()): np.float64(-5731.132344272273), ((), (2, 3), (), (0,)): np.float64(-5734.476786144126), ((3,), (), (), ()): np.float64(-5729.787716383992), ((3,), (), (), (1,)): np.float64(-5733.127026282412), ((3,), (), (1,), ()): np.float64(-5731.170686053025), ((3,), (), (1,), (1,)): np.float64(-5734.476785784075), ((3,), (2,), (), ()): np.float64(-5731.137475902878), ((3,), (2,), (), (1,)): np.float64(-5734.476785852005), ((3,), (3,), (), ()): np.float64(-5733.093815942413), ((3,), (3,), (1,), ()): np.float64(-5734.47678565186), ((3,), (2, 3), (), ()): np.float64(-5734.476786120931)}, ((0, 1, 2, 3), ((0, 1), (2, 3), (1, 3))): {((), (), (), ()): np.float64(-5726.675284403736), ((), (), (), (0,)): np.float64(-5730.008248509697), ((), (), (0,), ()): np.float64(-5729.836090831688), ((), (), (0,), (0,)): np.float64(-5733.180526183914), ((), (), (1,), ()): np.float64(-5728.026055528992), ((), (), (1,), (0,)): np.float64(-5731.35800807027), ((), (), (0, 1), ()): np.float64(-5731.132344418119), ((), (), (0, 1), (0,)): np.float64(-5734.476786406171), ((), (2,), (), ()): np.float64(-5727.971900010964), ((), (2,), (), (0,)): np.float64(-5731.304508672632), ((), (2,), (0,), ()): np.float64(-5731.13234432989), ((), (2,), (0,), (0,)): np.float64(-5734.476786340807), ((2,), (), (), ()): np.float64(-5729.794450296364), ((2,), (), (), (0,)): np.float64(-5733.127026709152), ((2,), (), (1,), ()): np.float64(-5731.145277421666), ((2,), (), (1,), (0,)): np.float64(-5734.476786228971), ((2,), (2,), (), ()): np.float64(-5731.144177840302), ((2,), (2,), (), (0,)): np.float64(-5734.476786502713), ((3,), (), (), ()): np.float64(-5730.020696943019), ((3,), (), (0,), ()): np.float64(-5733.18151546823), ((3,), (), (1,), ()): np.float64(-5731.370509965565), ((3,), (), (0, 1), ()): np.float64(-5734.476786400916), ((3,), (2,), (), ()): np.float64(-5731.316342016852), ((3,), (2,), (0,), ()): np.float64(-5734.476786327622), ((2, 3), (), (), ()): np.float64(-5733.127026835944), ((2, 3), (), (1,), ()): np.float64(-5734.476786388055), ((2, 3), (2,), (), ()): np.float64(-5734.476786629286)}, ((0, 1, 2, 3), ((0, 1), (0, 2), (1, 3))): {((), (), (), ()): np.float64(-5726.830684704608), ((), (), (), (0,)): np.float64(-5730.1747155926705), ((), (), (), (2,)): np.float64(-5729.794450296196), ((), (), (), (0, 2)): np.float64(-5733.127026832506), ((), (), (1,), ()): np.float64(-5728.180006694012), ((), (), (1,), (0,)): np.float64(-5731.524452051664), ((), (), (1,), (2,)): np.float64(-5731.1438265181), ((), (), (1,), (0, 2)): np.float64(-5734.476786231857), ((), (), (3,), ()): np.float64(-5729.749361664134), ((), (), (3,), (0,)): np.float64(-5733.093383793432), ((), (), (1, 3), ()): np.float64(-5731.13234420326), ((), (), (1, 3), (0,)): np.float64(-5734.476786185583), ((), (2,), (), ()): np.float64(-5728.212563507248), ((), (2,), (), (0,)): np.float64(-5731.55700551018), ((), (2,), (), (2,)): np.float64(-5731.144177900566), ((), (2,), (), (0, 2)): np.float64(-5734.4767866843695), ((), (2,), (3,), ()): np.float64(-5731.132343940026), ((), (2,), (3,), (0,)): np.float64(-5734.476785937755), ((3,), (), (), ()): np.float64(-5730.162202397558), ((3,), (), (), (2,)): np.float64(-5733.127026705414), ((3,), (), (1,), ()): np.float64(-5731.511961793416), ((3,), (), (1,), (2,)): np.float64(-5734.4767861101645), ((3,), (), (3,), ()): np.float64(-5733.093816137461), ((3,), (), (1, 3), ()): np.float64(-5734.476786193771), ((3,), (2,), (), ()): np.float64(-5731.545172160949), ((3,), (2,), (), (2,)): np.float64(-5734.47678656695), ((3,), (2,), (3,), ()): np.float64(-5734.476785965209)}, ((0, 1, 2, 3), ((1, 2), (0, 3), (2, 3))): {((), (), (), ()): np.float64(-5725.108826087722), ((), (), (), (1,)): np.float64(-5728.423270322101), ((), (), (0,), ()): np.float64(-5728.228045582048), ((), (), (0,), (1,)): np.float64(-5731.542048496678), ((), (0,), (), ()): np.float64(-5727.990520963061), ((), (0,), (), (1,)): np.float64(-5731.304504463973), ((), (0,), (0,), ()): np.float64(-5731.162779286141), ((), (0,), (0,), (1,)): np.float64(-5734.476782170726), ((), (3,), (), ()): np.float64(-5728.414476357075), ((), (3,), (0,), ()): np.float64(-5731.53414332109), ((), (0, 3), (), ()): np.float64(-5731.3045067169305), ((), (0, 3), (0,), ()): np.float64(-5734.4767844048765), ((1,), (), (), ()): np.float64(-5728.051904645247), ((1,), (), (), (1,)): np.float64(-5731.3580059981205), ((1,), (), (0,), ()): np.float64(-5731.170686541441), ((1,), (), (0,), (1,)): np.float64(-5734.476784184721), ((1,), (3,), (), ()): np.float64(-5731.357570020527), ((1,), (3,), (0,), ()): np.float64(-5734.476784275583), ((2,), (), (), ()): np.float64(-5728.2807061287895), ((2,), (), (), (1,)): np.float64(-5731.595548042617), ((2,), (0,), (), ()): np.float64(-5731.162396784927), ((2,), (0,), (), (1,)): np.float64(-5734.476782235192), ((2,), (3,), (), ()): np.float64(-5731.586766616291), ((2,), (0, 3), (), ()): np.float64(-5734.476784431142), ((1, 2), (), (), ()): np.float64(-5731.1706866351105), ((1, 2), (), (), (1,)): np.float64(-5734.476784391502), ((1, 2), (3,), (), ()): np.float64(-5734.476784491021)}, ((0, 1, 2, 3), ((1, 2), (0, 3), (0, 2))): {((), (), (), ()): np.float64(-5725.2627678728195), ((), (), (), (1,)): np.float64(-5728.577213519416), ((), (), (), (2,)): np.float64(-5728.1954380238585), ((), (), (), (1, 2)): np.float64(-5731.542050832251), ((), (), (3,), ()): np.float64(-5728.2280456235985), ((), (), (3,), (1,)): np.float64(-5731.542050775452), ((), (0,), (), ()): np.float64(-5728.198534376144), ((), (0,), (), (1,)): np.float64(-5731.512945225483), ((), (0,), (), (2,)): np.float64(-5731.130140974986), ((), (0,), (), (1, 2)): np.float64(-5734.476785422392), ((), (0,), (3,), ()): np.float64(-5731.162780186561), ((), (0,), (3,), (1,)): np.float64(-5734.4767853475705), ((), (3,), (), ()): np.float64(-5728.602472809203), ((), (3,), (), (2,)): np.float64(-5731.535137595732), ((), (3,), (3,), ()): np.float64(-5731.534144164627), ((), (0, 3), (), ()): np.float64(-5731.54517131778), ((), (0, 3), (), (2,)): np.float64(-5734.47678543689), ((), (0, 3), (3,), ()): np.float64(-5734.476785450954), ((1,), (), (), ()): np.float64(-5728.205860877787), ((1,), (), (), (1,)): np.float64(-5731.51196075325), ((1,), (), (), (2,)): np.float64(-5731.137474991697), ((1,), (), (), (1, 2)): np.float64(-5734.476785209656), ((1,), (), (3,), ()): np.float64(-5731.170685241216), ((1,), (), (3,), (1,)): np.float64(-5734.476785125144), ((1,), (3,), (), ()): np.float64(-5731.545169688326), ((1,), (3,), (), (2,)): np.float64(-5734.476783853574), ((1,), (3,), (3,), ()): np.float64(-5734.47678381894)}, ((0, 1, 2, 3), ((1, 2), (0, 3), (1, 3))): {((), (), (), ()): np.float64(-5725.503107528055), ((), (), (), (2,)): np.float64(-5728.423272120122), ((), (), (0,), ()): np.float64(-5728.622301931764), ((), (), (0,), (2,)): np.float64(-5731.542049981891), ((), (), (3,), ()): np.float64(-5728.43572512019), ((), (), (0, 3), ()): np.float64(-5731.542050158142), ((), (0,), (), ()): np.float64(-5728.3847281034405), ((), (0,), (), (2,)): np.float64(-5731.304508431519), ((), (0,), (0,), ()): np.float64(-5731.557005453234), ((), (0,), (0,), (2,)): np.float64(-5734.476785775685), ((), (0,), (3,), ()): np.float64(-5731.316341489283), ((), (0,), (0, 3), ()): np.float64(-5734.476785946371), ((1,), (), (), ()): np.float64(-5728.438808373211), ((1,), (), (), (2,)): np.float64(-5731.358007857608), ((1,), (), (0,), ()): np.float64(-5731.558017930483), ((1,), (), (0,), (2,)): np.float64(-5734.476785687204), ((1,), (), (3,), ()): np.float64(-5731.370471913218), ((1,), (), (0, 3), ()): np.float64(-5734.476785885338), ((2,), (), (), ()): np.float64(-5728.663943987257), ((2,), (), (), (2,)): np.float64(-5731.59554987773), ((2,), (), (3,), ()): np.float64(-5731.59661777058), ((2,), (0,), (), ()): np.float64(-5731.545172510876), ((2,), (0,), (), (2,)): np.float64(-5734.476786187551), ((2,), (0,), (3,), ()): np.float64(-5734.476785887792), ((1, 2), (), (), ()): np.float64(-5731.545172536635), ((1, 2), (), (), (2,)): np.float64(-5734.476786192501), ((1, 2), (), (3,), ()): np.float64(-5734.476785904067)}, ((0, 1, 2, 3), ((1, 2), (2, 3), (0, 2))): {((), (), (), ()): np.float64(-5724.883603550646), ((), (), (), (0,)): np.float64(-5728.228043296006), ((), (), (), (1,)): np.float64(-5728.189700851217), ((), (), (), (0, 1)): np.float64(-5731.542048328531), ((), (0,), (), ()): np.float64(-5727.8183359988625), ((), (0,), (), (0,)): np.float64(-5731.162775839188), ((), (0,), (), (1,)): np.float64(-5731.1244333027935), ((), (0,), (), (0, 1)): np.float64(-5734.476780820769), ((), (3,), (), ()): np.float64(-5728.189699842659), ((), (3,), (), (0,)): np.float64(-5731.534139467029), ((), (0, 3), (), ()): np.float64(-5731.13234112497), ((), (0, 3), (), (0,)): np.float64(-5734.476780800959), ((1,), (), (), ()): np.float64(-5727.818337558863), ((1,), (), (), (0,)): np.float64(-5731.162777415489), ((1,), (), (), (1,)): np.float64(-5731.1244350374145), ((1,), (), (), (0, 1)): np.float64(-5734.4767825643385), ((1,), (3,), (), ()): np.float64(-5731.124433925029), ((1,), (3,), (), (0,)): np.float64(-5734.477062163252), ((3,), (), (), ()): np.float64(-5728.228043885474), ((3,), (), (), (1,)): np.float64(-5731.534141252235), ((3,), (0,), (), ()): np.float64(-5731.162776659883), ((3,), (0,), (), (1,)): np.float64(-5734.4770666289205), ((3,), (3,), (), ()): np.float64(-5731.534140224399), ((3,), (0, 3), (), ()): np.float64(-5734.476781779177), ((1, 3), (), (), ()): np.float64(-5731.170684968564), ((1, 3), (), (), (1,)): np.float64(-5734.476782504096), ((1, 3), (3,), (), ()): np.float64(-5734.476781399056)}, ((0, 1, 2, 3), ((1, 2), (0, 2), (1, 3))): {((), (), (), ()): np.float64(-5725.270928505339), ((), (), (), (0,)): np.float64(-5728.6223019323415), ((), (), (), (2,)): np.float64(-5728.2021397791395), ((), (), (), (0, 2)): np.float64(-5731.542050464313), ((), (), (3,), ()): np.float64(-5728.189702719098), ((), (), (3,), (0,)): np.float64(-5731.542049590632), ((), (0,), (), ()): np.float64(-5728.212562573763), ((), (0,), (), (0,)): np.float64(-5731.5570042587115), ((), (0,), (), (2,)): np.float64(-5731.144176250696), ((), (0,), (), (0, 2)): np.float64(-5734.476785043658), ((), (0,), (3,), ()): np.float64(-5731.132342569494), ((), (0,), (3,), (0,)): np.float64(-5734.476784112658), ((1,), (), (), ()): np.float64(-5728.2052527577935), ((1,), (), (), (0,)): np.float64(-5731.5566387686), ((1,), (), (), (2,)): np.float64(-5731.1368693943305), ((1,), (), (), (0, 2)): np.float64(-5734.47678497109), ((1,), (), (3,), ()): np.float64(-5731.124437092782), ((1,), (), (3,), (0,)): np.float64(-5734.476783976482), ((3,), (), (), ()): np.float64(-5728.602472803942), ((3,), (), (), (2,)): np.float64(-5731.533675848734), ((3,), (), (3,), ()): np.float64(-5731.5341433763715), ((3,), (0,), (), ()): np.float64(-5731.5451700685), ((3,), (0,), (), (2,)): np.float64(-5734.476783743763), ((3,), (0,), (3,), ()): np.float64(-5734.476783452025), ((1, 3), (), (), ()): np.float64(-5731.545171118215), ((1, 3), (), (), (2,)): np.float64(-5734.476784892218), ((1, 3), (), (3,), ()): np.float64(-5734.47678447956)}, ((0, 1, 2, 3), ((0, 3), (2, 3), (1, 3))): {((), (), (), ()): np.float64(-5727.073512835715), ((), (), (0,), ()): np.float64(-5730.245790406518), ((), (), (1,), ()): np.float64(-5728.423272315818), ((), (), (0, 1), ()): np.float64(-5731.54205066411), ((), (0,), (), ()): np.float64(-5730.008248495514), ((), (0,), (0,), ()): np.float64(-5733.180526062038), ((), (0,), (1,), ()): np.float64(-5731.35800792761), ((), (0,), (0, 1), ()): np.float64(-5734.476786279369), ((), (2,), (), ()): np.float64(-5728.423272430833), ((), (2,), (0,), ()): np.float64(-5731.595549992157), ((), (0, 2), (), ()): np.float64(-5731.304508777641), ((), (0, 2), (0,), ()): np.float64(-5734.476786331355), ((1,), (), (), ()): np.float64(-5730.008248489016), ((1,), (), (0,), ()): np.float64(-5733.180526066825), ((1,), (), (1,), ()): np.float64(-5731.358007953925), ((1,), (), (0, 1), ()): np.float64(-5734.476786318317), ((1,), (2,), (), ()): np.float64(-5731.358008067579), ((1,), (2,), (0,), ()): np.float64(-5734.480752439713), ((2,), (), (), ()): np.float64(-5730.24579048122), ((2,), (), (1,), ()): np.float64(-5731.5955499606835), ((2,), (0,), (), ()): np.float64(-5733.18052613502), ((2,), (0,), (1,), ()): np.float64(-5734.480751926228), ((2,), (2,), (), ()): np.float64(-5731.595550072193), ((2,), (0, 2), (), ()): np.float64(-5734.476786409581), ((1, 2), (), (), ()): np.float64(-5733.127026828193), ((1, 2), (), (1,), ()): np.float64(-5734.476786299657), ((1, 2), (2,), (), ()): np.float64(-5734.476786409323)}, ((0, 1, 2, 3), ((0, 3), (0, 2), (1, 3))): {((), (), (), ()): np.float64(-5727.281998962879), ((), (), (), (2,)): np.float64(-5730.245790553574), ((), (), (1,), ()): np.float64(-5728.577213521273), ((), (), (1,), (2,)): np.float64(-5731.542050753431), ((), (), (3,), ()): np.float64(-5730.213171625868), ((), (), (1, 3), ()): np.float64(-5731.54205084841), ((), (0,), (), ()): np.float64(-5730.2163280725235), ((), (0,), (), (2,)): np.float64(-5733.180526317261), ((), (0,), (1,), ()): np.float64(-5731.511505049995), ((), (0,), (1,), (2,)): np.float64(-5734.476786511376), ((), (0,), (3,), ()): np.float64(-5733.147921554883), ((), (0,), (1, 3), ()): np.float64(-5734.476786601005), ((), (2,), (), ()): np.float64(-5728.663943987255), ((), (2,), (), (2,)): np.float64(-5731.595550260593), ((), (2,), (3,), ()): np.float64(-5731.595170110767), ((), (0, 2), (), ()): np.float64(-5731.545172536736), ((), (0, 2), (), (2,)): np.float64(-5734.476786602998), ((), (0, 2), (3,), ()): np.float64(-5734.476786618824), ((1,), (), (), ()): np.float64(-5730.1622025303195), ((1,), (), (), (2,)): np.float64(-5733.1270268635035), ((1,), (), (1,), ()): np.float64(-5731.511962185908), ((1,), (), (1,), (2,)): np.float64(-5734.476786522227), ((1,), (), (3,), ()): np.float64(-5733.093816608913), ((1,), (), (1, 3), ()): np.float64(-5734.476786608257), ((1,), (2,), (), ()): np.float64(-5731.5451725105795), ((1,), (2,), (), (2,)): np.float64(-5734.476786568429), ((1,), (2,), (3,), ()): np.float64(-5734.476786591171)}, ((0, 1, 2, 3), ((2, 3), (0, 2), (1, 3))): {((), (), (), ()): np.float64(-5726.894400146808), ((), (), (), (0,)): np.float64(-5730.245790340044), ((), (), (1,), ()): np.float64(-5728.1897033568375), ((), (), (1,), (0,)): np.float64(-5731.542050437186), ((), (0,), (), ()): np.float64(-5729.83609083258), ((), (0,), (), (0,)): np.float64(-5733.180526026169), ((), (0,), (1,), ()): np.float64(-5731.1323442777875), ((), (0,), (1,), (0,)): np.float64(-5734.476786091339), ((), (2,), (), ()): np.float64(-5728.243820809758), ((), (2,), (), (0,)): np.float64(-5731.595549942496), ((), (0, 2), (), ()): np.float64(-5731.132344443932), ((), (0, 2), (), (0,)): np.float64(-5734.476786291038), ((1,), (), (), ()): np.float64(-5729.774629146278), ((1,), (), (), (0,)): np.float64(-5733.127026296605), ((1,), (), (1,), ()): np.float64(-5731.124438803885), ((1,), (), (1,), (0,)): np.float64(-5734.476785896393), ((1,), (2,), (), ()): np.float64(-5731.124019847116), ((1,), (2,), (), (0,)): np.float64(-5734.476785874802), ((3,), (), (), ()): np.float64(-5730.238486602793), ((3,), (), (1,), ()): np.float64(-5731.534145163558), ((3,), (0,), (), ()): np.float64(-5733.180187956981), ((3,), (0,), (1,), ()): np.float64(-5734.4767860874945), ((3,), (2,), (), ()): np.float64(-5731.588258251498), ((3,), (0, 2), (), ()): np.float64(-5734.476786282715), ((1, 3), (), (), ()): np.float64(-5733.127026624761), ((1, 3), (), (1,), ()): np.float64(-5734.476786217562), ((1, 3), (2,), (), ()): np.float64(-5734.476786217541)}, ((0, 1, 2, 3), ((0, 1), (1, 2), (0, 3), (2, 3))): {((), (), (), ()): np.float64(-5727.999239502615), ((), (), (), (1,)): np.float64(-5731.304505483408), ((), (), (0,), ()): np.float64(-5731.170683601416), ((), (), (0,), (1,)): np.float64(-5734.476780143153), ((), (3,), (), ()): np.float64(-5731.304504399886), ((), (3,), (0,), ()): np.float64(-5734.476779199879), ((2,), (), (), ()): np.float64(-5731.170683327135), ((2,), (), (), (1,)): np.float64(-5734.476780160015), ((2,), (3,), (), ()): np.float64(-5734.476778914566)}, ((0, 1, 2, 3), ((0, 1), (1, 2), (0, 3), (0, 2))): {((), (), (), ()): np.float64(-5728.205862336501), ((), (), (), (1,)): np.float64(-5731.51196209382), ((), (), (), (2,)): np.float64(-5731.1374762813775), ((), (), (), (1, 2)): np.float64(-5734.4767864990345), ((), (), (3,), ()): np.float64(-5731.170686675881), ((), (), (3,), (1,)): np.float64(-5734.476786454231), ((), (3,), (), ()): np.float64(-5731.545172410282), ((), (3,), (), (2,)): np.float64(-5734.476786342136), ((), (3,), (3,), ()): np.float64(-5734.476785586248)}, ((0, 1, 2, 3), ((0, 1), (1, 2), (0, 3), (1, 3))): {((), (), (), ()): np.float64(-5728.384728126375), ((), (), (), (2,)): np.float64(-5731.304508456958), ((), (), (0,), ()): np.float64(-5731.557003323103), ((), (), (0,), (2,)): np.float64(-5734.476783616711), ((), (), (3,), ()): np.float64(-5731.316339049787), ((), (), (0, 3), ()): np.float64(-5734.476783793554), ((2,), (), (), ()): np.float64(-5731.545170240328), ((2,), (), (), (2,)): np.float64(-5734.476784117727), ((2,), (), (3,), ()): np.float64(-5734.476781248879)}, ((0, 1, 2, 3), ((0, 1), (1, 2), (2, 3), (0, 2))): {((), (), (), ()): np.float64(-5727.818339337381), ((), (), (), (0,)): np.float64(-5731.1627791449455), ((), (), (), (1,)): np.float64(-5731.124437153447), ((), (), (), (0, 1)): np.float64(-5734.476784617932), ((), (3,), (), ()): np.float64(-5731.132342352371), ((), (3,), (), (0,)): np.float64(-5734.476781994711), ((3,), (), (), ()): np.float64(-5731.170686400377), ((3,), (), (), (1,)): np.float64(-5734.476784266548), ((3,), (3,), (), ()): np.float64(-5734.476786415248)}, ((0, 1, 2, 3), ((0, 1), (1, 2), (2, 3), (1, 3))): {((), (), (), ()): np.float64(-5727.971900072678), ((), (), (), (0,)): np.float64(-5731.304508736511), ((), (), (0,), ()): np.float64(-5731.132342407177), ((), (), (0,), (0,)): np.float64(-5734.476784683336), ((2,), (), (), ()): np.float64(-5731.144175392069), ((2,), (), (), (0,)): np.float64(-5734.476784022744), ((3,), (), (), ()): np.float64(-5731.316339665143), ((3,), (), (0,), ()): np.float64(-5734.476782232935), ((2, 3), (), (), ()): np.float64(-5734.47678417868)}, ((0, 1, 2, 3), ((0, 1), (1, 2), (0, 2), (1, 3))): {((), (), (), ()): np.float64(-5728.212563760361), ((), (), (), (0,)): np.float64(-5731.557005324963), ((), (), (), (2,)): np.float64(-5731.144177704117), ((), (), (), (0, 2)): np.float64(-5734.4767864922305), ((), (), (3,), ()): np.float64(-5731.132343770422), ((), (), (3,), (0,)): np.float64(-5734.476785156686), ((3,), (), (), ()): np.float64(-5731.545172427026), ((3,), (), (), (2,)): np.float64(-5734.476786350841), ((3,), (), (3,), ()): np.float64(-5734.47678570486)}, ((0, 1, 2, 3), ((0, 1), (0, 3), (2, 3), (0, 2))): {((), (), (), ()): np.float64(-5729.787716745888), ((), (), (), (1,)): np.float64(-5733.127026834623), ((), (), (1,), ()): np.float64(-5731.170686390716), ((), (), (1,), (1,)): np.float64(-5734.476786338909), ((), (2,), (), ()): np.float64(-5731.137476091343), ((), (2,), (), (1,)): np.float64(-5734.476786174968), ((), (3,), (), ()): np.float64(-5733.093816171293), ((), (3,), (1,), ()): np.float64(-5734.476785869193), ((), (2, 3), (), ()): np.float64(-5734.4767862934605)}, ((0, 1, 2, 3), ((0, 1), (0, 3), (2, 3), (1, 3))): {((), (), (), ()): np.float64(-5730.008248629034), ((), (), (0,), ()): np.float64(-5733.180526193067), ((), (), (1,), ()): np.float64(-5731.358008101015), ((), (), (0, 1), ()): np.float64(-5734.476786449764), ((), (2,), (), ()): np.float64(-5731.304508803119), ((), (2,), (0,), ()): np.float64(-5734.4767863543375), ((2,), (), (), ()): np.float64(-5733.127026853982), ((2,), (), (1,), ()): np.float64(-5734.4767863329025), ((2,), (2,), (), ()): np.float64(-5734.476786661085)}, ((0, 1, 2, 3), ((0, 1), (0, 3), (0, 2), (1, 3))): {((), (), (), ()): np.float64(-5730.162202563338), ((), (), (), (2,)): np.float64(-5733.127026889061), ((), (), (1,), ()): np.float64(-5731.511961870028), ((), (), (1,), (2,)): np.float64(-5734.476786212342), ((), (), (3,), ()): np.float64(-5733.09381623173), ((), (), (1, 3), ()): np.float64(-5734.47678628279), ((), (2,), (), ()): np.float64(-5731.545172290402), ((), (2,), (), (2,)): np.float64(-5734.4767867650535), ((), (2,), (3,), ()): np.float64(-5734.4767860330385)}, ((0, 1, 2, 3), ((0, 1), (2, 3), (0, 2), (1, 3))): {((), (), (), ()): np.float64(-5729.781931423471), ((), (), (), (0,)): np.float64(-5733.127026911301), ((), (), (1,), ()): np.float64(-5731.132344508787), ((), (), (1,), (0,)): np.float64(-5734.4767866142665), ((), (2,), (), ()): np.float64(-5731.132344936558), ((), (2,), (), (0,)): np.float64(-5734.476787043691), ((3,), (), (), ()): np.float64(-5733.127026915997), ((3,), (), (1,), ()): np.float64(-5734.476786616351), ((3,), (2,), (), ()): np.float64(-5734.47678706608)}, ((0, 1, 2, 3), ((1, 2), (0, 3), (2, 3), (0, 2))): {((), (), (), ()): np.float64(-5728.228045688804), ((), (), (), (1,)): np.float64(-5731.542048595522), ((), (0,), (), ()): np.float64(-5731.162778184669), ((), (0,), (), (1,)): np.float64(-5734.476781042314), ((), (3,), (), ()): np.float64(-5731.534142032647), ((), (0, 3), (), ()): np.float64(-5734.476783310752), ((1,), (), (), ()): np.float64(-5731.170685300265), ((1,), (), (), (1,)): np.float64(-5734.476783122241), ((1,), (3,), (), ()): np.float64(-5734.4767817351085)}, ((0, 1, 2, 3), ((1, 2), (0, 3), (2, 3), (1, 3))): {((), (), (), ()): np.float64(-5728.423272550035), ((), (), (0,), ()): np.float64(-5731.542050783556), ((), (0,), (), ()): np.float64(-5731.30450887157), ((), (0,), (0,), ()): np.float64(-5734.476786569794), ((1,), (), (), ()): np.float64(-5731.35800819597), ((1,), (), (0,), ()): np.float64(-5734.476786445292), ((2,), (), (), ()): np.float64(-5731.595550182045), ((2,), (0,), (), ()): np.float64(-5734.476786493787), ((1, 2), (), (), ()): np.float64(-5734.476786528726)}, ((0, 1, 2, 3), ((1, 2), (0, 3), (0, 2), (1, 3))): {((), (), (), ()): np.float64(-5728.609810571995), ((), (), (), (2,)): np.float64(-5731.542050765144), ((), (), (3,), ()): np.float64(-5731.542050524961), ((), (0,), (), ()): np.float64(-5731.545171650789), ((), (0,), (), (2,)): np.float64(-5734.476785656436), ((), (0,), (3,), ()): np.float64(-5734.476785434604), ((1,), (), (), ()): np.float64(-5731.545171480194), ((1,), (), (), (2,)): np.float64(-5734.476785601205), ((1,), (), (3,), ()): np.float64(-5734.476785262447)}, ((0, 1, 2, 3), ((1, 2), (2, 3), (0, 2), (1, 3))): {((), (), (), ()): np.float64(-5728.189703484758), ((), (), (), (0,)): np.float64(-5731.54205061179), ((), (0,), (), ()): np.float64(-5731.132343295833), ((), (0,), (), (0,)): np.float64(-5734.476785256024), ((1,), (), (), ()): np.float64(-5731.124437475456), ((1,), (), (), (0,)): np.float64(-5734.476784657967), ((3,), (), (), ()): np.float64(-5731.534143776435), ((3,), (0,), (), ()): np.float64(-5734.476783868048), ((1, 3), (), (), ()): np.float64(-5734.476784861936)}, ((0, 1, 2, 3), ((0, 3), (2, 3), (0, 2), (1, 3))): {((), (), (), ()): np.float64(-5730.245790616861), ((), (), (1,), ()): np.float64(-5731.542050764784), ((), (0,), (), ()): np.float64(-5733.180526279469), ((), (0,), (1,), ()): np.float64(-5734.476786388241), ((), (2,), (), ()): np.float64(-5731.595550214474), ((), (0, 2), (), ()): np.float64(-5734.476786561647), ((1,), (), (), ()): np.float64(-5733.127026939219), ((1,), (), (1,), ()): np.float64(-5734.476786518775), ((1,), (2,), (), ()): np.float64(-5734.476786527265)}, ((0, 1, 2, 3), ((0, 1), (1, 2), (0, 3), (2, 3), (0, 2))): {((), (), (), ()): np.float64(-5731.170686735013), ((), (), (), (1,)): np.float64(-5734.476783786334), ((), (3,), (), ()): np.float64(-5734.476782432545)}, ((0, 1, 2, 3), ((0, 1), (1, 2), (0, 3), (2, 3), (1, 3))): {((), (), (), ()): np.float64(-5731.304508866274), ((), (), (0,), ()): np.float64(-5734.4767834254035), ((2,), (), (), ()): np.float64(-5734.476783112519)}, ((0, 1, 2, 3), ((0, 1), (1, 2), (0, 3), (0, 2), (1, 3))): {((), (), (), ()): np.float64(-5731.545172554038), ((), (), (), (2,)): np.float64(-5734.47678690619), ((), (), (3,), ()): np.float64(-5734.47678628244)}, ((0, 1, 2, 3), ((0, 1), (1, 2), (2, 3), (0, 2), (1, 3))): {((), (), (), ()): np.float64(-5731.132344557364), ((), (), (), (0,)): np.float64(-5734.4767867152), ((3,), (), (), ()): np.float64(-5734.476786650817)}, ((0, 1, 2, 3), ((0, 1), (0, 3), (2, 3), (0, 2), (1, 3))): {((), (), (), ()): np.float64(-5733.127026965578), ((), (), (1,), ()): np.float64(-5734.476786666444), ((), (2,), (), ()): np.float64(-5734.476787097285)}, ((0, 1, 2, 3), ((1, 2), (0, 3), (2, 3), (0, 2), (1, 3))): {((), (), (), ()): np.float64(-5731.542050880695), ((), (0,), (), ()): np.float64(-5734.4767857935485), ((1,), (), (), ()): np.float64(-5734.476785628478)}, ((0, 1, 2, 3), ((0, 1), (1, 2), (0, 3), (2, 3), (0, 2), (1, 3))): {((), (), (), ()): np.float64(-5734.47678669226)}}\n","1178 vs 590, pruning time: 0.012529134750366211\n","Set parameter MIPGap to value 1e-06\n","LP iter 1, ObjVal: -5717.462290251022, time: 0.005338430404663086, frac. of nonzero variables: 4/590, frac. of nonzero bidirected edges: 0/6, # cluster: 0, # bi-cluster: 0\n","Set parameter Heuristics to value 0\n","Set parameter LazyConstraints to value 1\n","Set parameter LogFile to value \"./datasets/synth_5_test_score_1000.pkl.log\"\n","Gurobi Optimizer version 12.0.2 build v12.0.2rc0 (linux64 - \"Ubuntu 22.04.4 LTS\")\n","\n","CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz, instruction set [SSE2|AVX|AVX2]\n","Thread count: 1 physical cores, 2 logical processors, using up to 2 threads\n","\n","Non-default parameters:\n","MIPGap  1e-06\n","Heuristics  0\n","LazyConstraints  1\n","\n","Optimize a model with 38 rows, 624 columns and 6662 nonzeros\n","Model fingerprint: 0xefd35d2a\n","Variable types: 34 continuous, 590 integer (590 binary)\n","Coefficient statistics:\n","  Matrix range     [1e+00, 1e+00]\n","  Objective range  [1e+03, 6e+03]\n","  Bounds range     [1e+00, 1e+00]\n","  RHS range        [1e+00, 1e+00]\n","Presolve removed 15 rows and 15 columns\n","Presolve time: 0.03s\n","Presolved: 23 rows, 609 columns, 4314 nonzeros\n","Variable types: 0 continuous, 609 integer (590 binary)\n","\n","Root relaxation: objective -5.717462e+03, 4 iterations, 0.00 seconds (0.00 work units)\n","\n","    Nodes    |    Current Node    |     Objective Bounds      |     Work\n"," Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n","\n","*    0     0               0    -5717.462290 -5717.4623  0.00%     -    0s\n","\n","Explored 1 nodes (4 simplex iterations) in 0.05 seconds (0.01 work units)\n","Thread count was 2 (of 2 available processors)\n","\n","Solution count 1: -5717.46 \n","No other solutions better than -5717.46\n","\n","Optimal solution found (tolerance 1.00e-06)\n","Best objective -5.717462290251e+03, best bound -5.717462290251e+03, gap 0.0000%\n","\n","User-callback calls 173, time in user-callback 0.00 sec\n","Bidirected edges: \n","Parent sets: \n","0: ()\n","1: ()\n","2: ()\n","3: ()\n","z solution: \n","((0,), ()): ((),), score: -1403.8645428682\n","((1,), ()): ((),), score: -1435.8233981051844\n","((2,), ()): ((),), score: -1452.8428115631575\n","((3,), ()): ((),), score: -1424.9315377144794\n"]}]},{"cell_type":"code","source":["import pickle\n","\n","# 测试读取数据\n","filename = './datasets/synth_5_test_score_1000.pkl'\n","file = open(filename, 'rb')\n","[data, originalScores] = pickle.load(file)\n","file.close()\n","# print(len(data[0])) #18*1000\n","#data = data[:2]  # 提取前 10 个元素\n","print(data.shape,originalScores)\n","\n","originalScores_print = {k: v for i, (k, v) in enumerate(originalScores.items()) if i < 2}  # 取前 5 个键值对\n","originalScores_print\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":384},"id":"X0tpau0iPnBe","executionInfo":{"status":"error","timestamp":1747160472977,"user_tz":-120,"elapsed":54,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"}},"outputId":"cb58b5ff-6cc8-46e4-f3d7-ae71c1e71c7d"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'numpy._core.numeric'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-a1d7beff4a39>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./datasets/synth_5_test_score_1000.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginalScores\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# print(len(data[0])) #18*1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy._core.numeric'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["Initialize(data, originalScores, filename, prune=False,printsc=False)\n","Solve_with_cb()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":159},"id":"gGepeP5tPwo5","executionInfo":{"status":"error","timestamp":1747160475597,"user_tz":-120,"elapsed":4,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"}},"outputId":"707761ee-b97c-442d-97ec-588850585e06"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'Initialize' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-3b670c8465ad>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mInitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginalScores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprune\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprintsc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mSolve_with_cb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Initialize' is not defined"]}]},{"cell_type":"markdown","source":["# Test score example"],"metadata":{"id":"qMkOhl0CVVRz"}},{"cell_type":"markdown","source":["## Read data"],"metadata":{"id":"RoXu4Y-S4eeQ"}},{"cell_type":"markdown","source":["## Test BN"],"metadata":{"id":"_cKw7ZKV4uLc"}},{"cell_type":"code","source":["if __name__ == '__main__':\n","\tscoresets = ['./datasets/score_example']\n","\tfor instName in scoresets:\n","\t\tinst = BNSLlvInst(instName)\n","\n","\t\tinst.readFromPkl()\n","\t\tinst.Initialize(prune=True,printsc=False)\n","\t\tinst.Solve_with_cb()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1Xj5mIw2OmlTw0rQAKeER68lVsjIbg1oU"},"id":"XVZ5wcb7VIPB","executionInfo":{"status":"ok","timestamp":1747160892534,"user_tz":-120,"elapsed":70654,"user":{"displayName":"xiaoyu he","userId":"11845591592229205113"}},"outputId":"abdeebeb-2115-4e16-c679-f614916bb4d0"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["# Backup"],"metadata":{"id":"s0ad3XY24YPw"}},{"cell_type":"markdown","metadata":{"id":"zNx8GsO7ue9y"},"source":["## Mlflow Tests"]},{"cell_type":"markdown","metadata":{"id":"Ezk7XsJLWsUx"},"source":["## Test ExDAG"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"apaJGNvHWL2I"},"outputs":[],"source":["%%shell\n","export PYTHONPATH=$PYTHONPATH:../\n","export  KMP_DUPLICATE_LIB_OK=TRUE\n","# os.chdir(\"/content/drive/My Drive/Colab Notebooks/Causality/cliquewidth/ExDAG-ExDBN-ExMAG/Pavel-GitLab/\")\n","CMD=\"python3 run_experiments.py --multirun --config-name=config-cluster\"\n","\n","edge_ratios=\"2,3\"\n","vars=\"5, 10, 15, 20, 25\"\n","samples=\"20, 50, 100, 500, 1000\"\n","noise=\"gauss, exp, uniform\"\n","\n","${CMD} experiment=\"EXDAG\" problem=\"er, sf\" problem.sem_type=\"${noise}\" problem.edge_ratio=\"${edge_ratios}\" problem.number_of_variables=\"${vars}\" problem.number_of_samples=\"${samples}\" solver=\"milp\" solver.time_limit=\"7200\" solver.lambda1=\"3, 2, 1, 0.5, 0.01\" problem.seed='range(0,10)' 2>&1 | tee milp.log # Redirect stderr to stdout and save to milp.log\n","\n","${CMD} experiment=\"EXDAG\" problem=\"er, sf\" problem.sem_type=\"${noise}\" problem.edge_ratio=\"${edge_ratios}\" problem.number_of_variables=\"${vars}\" problem.number_of_samples=\"${samples}\" solver=\"notears\" solver.lambda1=\"0.03\" problem.seed='range(0,10)' 2>&1 | tee notears.log # Redirect stderr to stdout and save to notears.log\n","\n","${CMD} experiment=\"EXDAG\" problem=\"er, sf\" problem.sem_type=\"${noise}\" problem.edge_ratio=\"${edge_ratios}\" problem.number_of_variables=\"${vars}\" problem.number_of_samples=\"${samples}\" solver=\"dagma\" problem.seed='range(0,10)' 2>&1 | tee dagma.log # Redirect stderr to stdout and save to dagma.log\n","\n","${CMD} experiment=\"EXDAG\" problem=\"er, sf\" problem.sem_type=\"${noise}\" problem.edge_ratio=\"${edge_ratios}\" problem.number_of_variables=\"${vars}\" problem.number_of_samples=\"${samples}\" solver=\"boss\" problem.seed='range(0,10)' 2>&1 | tee boss.log # Redirect stderr to stdout and save to boss.log\n","\n","${CMD} experiment=\"EXDAG\" problem=\"er, sf\" problem.sem_type=\"${noise}\" problem.number_of_variables=\"10\" solver=\"gobnilp\" problem.number_of_samples=\"10,100,1000\" problem.seed='range(0,10)' 2>&1 | tee gobnilp.log # Redirect stderr to stdout and save to gobnilp.log"]},{"cell_type":"markdown","metadata":{"id":"VEJ78XHBNGMt"},"source":["## Test ExDBN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xddNblaeNGXn"},"outputs":[],"source":["%%shell\n","\n","export PYTHONPATH=$PYTHONPATH:../\n","export  KMP_DUPLICATE_LIB_OK=TRUE\n","\n","CMD=\"python3 run_experiments.py --multirun --config-name=config-cluster\"\n","\n","vars=\"7, 10, 15, 20, 25\"\n","\n","python3 run_experiments.py --multirun experiment=\"EXDBN\" problem=\"dynamic\" problem.variant=\"er\" problem.normalize=\"false\" problem.noise_scale=0.8 problem.noise_scale_variance=0.4 problem.generator=\"notears\" problem.w_min_inter=0.2 problem.w_max_inter=0.4 problem.intra_edge_ratio=3 problem.number_of_variables=\"7, 10, 15,20, 25\" problem.number_of_samples=\"50, 100, 250, 500, 1000\" solver=\"lingam\" problem.p=\"1\" solver.lambda1=\"0.03\" problem.seed=\"range(0,10)\"\n","\n","# SF-3-1\n","${CMD} experiment=\"EXDBN\" problem=\"dynamic\" problem.variant=\"sf\" problem.generator=\"notears\" problem.w_min_inter=0.2 problem.w_max_inter=0.4  problem.intra_edge_ratio=3 problem.number_of_variables=\"${vars}\" problem.number_of_samples=\"50, 100, 250, 500, 1000\" solver=\"lingam\" problem.p=\"1\" solver.lambda1=\"0.03\" problem.seed=\"range(0,10)\"\n","${CMD} experiment=\"EXDBN\" problem=\"dynamic\" problem.generator=\"notears\" problem.variant=\"sf\" problem.w_min_inter=0.2 problem.w_max_inter=0.4  problem.intra_edge_ratio=3 problem.number_of_variables=\"${vars}\" problem.number_of_samples=\"50, 100, 250, 500, 1000\" solver=\"milp\"  solver.time_limit=\"7200\"  problem.p=\"1\" solver.lambda1=\"2,1\" solver.lambda2=\"0.1,0.5\" solver.a_reg_type=\"l1,l2\" problem.seed=\"range(0,10)\"\n","${CMD} experiment=\"EXDBN\" problem=\"dynamic\" problem.variant=\"sf\" problem.noise_scale_variance=0.4 problem.noise_scale=0.7  problem.normalize=\"false\"  problem.generator=\"notears\" problem.w_min_inter=0.2 problem.w_max_inter=0.4  problem.intra_edge_ratio=3 problem.number_of_variables=\"${vars}\" problem.number_of_samples=\"50, 100, 250, 500, 1000\" solver=\"dynotears\" problem.p=\"1\" solver.lambda1=\"0.03\" problem.seed=\"range(0,10)\"\n","\n","# ER-2-1-1\n","\n","${CMD} experiment=\"EXDBN\" problem=\"dynamic\" problem.generator=\"notears\" problem.variant=\"er\" problem.normalize=\"false\" problem.noise_scale=0.7 problem.noise_scale_variance=0.4 problem.intra_edge_ratio=2 problem.w_min_inter=0.3 problem.w_max_inter=0.5  problem.number_of_variables=\"5, 10, 15, 20, 25\" problem.number_of_samples=\"50, 100, 250, 500, 1000\" solver=\"milp\"  problem.p=\"2\" problem.w_decay=3 solver.lambda1=\"3,1, 0.3, 0.1,0.01\" solver.time_limit=\"7200\"  solver.lambda2=\"0.1,0.01\" solver.a_reg_type=\"l1,l2\" problem.seed=\"range(0,10)\"\n","${CMD} experiment=\"EXDBN\" problem=\"dynamic\" problem.variant=\"er\" problem.generator=\"notears\" problem.w_min_inter=0.3 problem.w_max_inter=0.5  problem.intra_edge_ratio=2 problem.number_of_variables=\"5,10,15,20,25\" problem.number_of_samples=\"50, 100, 250, 500, 1000\" solver=\"dynotears\" problem.p=\"2\" problem.normalize=\"false\" problem.noise_scale=0.7 problem.noise_scale_variance=0.4  problem.w_decay=3 solver.lambda1=\"0.03\" problem.seed=\"range(0,10)\"\n","\n","\n","# ER-3\n","${CMD} experiment=\"EXDBN\" problem=\"dynamic\" problem.generator=\"notears\" problem.normalize=\"false\"  problem.variant=\"er\" problem.w_min_inter=0.2 problem.w_max_inter=0.4  problem.intra_edge_ratio=3 problem.noise_scale=0.8 problem.noise_scale_variance=0.4  problem.number_of_variables=\"${vars}\" problem.number_of_samples=\"50, 100, 250, 500, 1000\" solver=\"milp\" solver.target_mip_gap=\"0.00001\" solver.time_limit=\"7200\"  problem.p=\"1\" solver.lambda1=\"2,1,0.1\" solver.lambda2=\"0.1,0.5, 0.01\" solver.a_reg_type=\"l1,l2\" problem.seed=\"0,1,2\"\n","${CMD} experiment=\"EXDBN\" problem=\"dynamic\" problem.variant=\"er\" problem.normalize=\"false\" problem.noise_scale=0.8 problem.noise_scale_variance=0.4  problem.generator=\"notears\" problem.w_min_inter=0.2 problem.w_max_inter=0.4  problem.intra_edge_ratio=3 problem.number_of_variables=\"${vars}\" problem.number_of_samples=\"50, 100, 250, 500, 1000\" solver=\"dynotears\" problem.p=\"1\" solver.lambda1=\"0.03\" problem.seed=\"range(0,10)\"\n","\n","\n","# convergence\n","${CMD} experiment=\"EXDBN\" problem=\"dynamic\"  problem.normalize=\"false\" problem.generator=\"notears\" problem.variant=\"sf\" problem.w_min_inter=0.2 problem.w_max_inter=0.4  problem.intra_edge_ratio=3 problem.number_of_variables=\"25\" problem.number_of_samples=\"250\" solver=\"milp\"  solver.time_limit=\"60, 120, 300, 600, 1200, 1800, 2700, 3600, 5400, 7200\"  problem.p=\"1\" solver.lambda1=\"1\" solver.lambda2=\"0.1\" solver.loss_type=\"l2\" solver.a_reg_type=\"l1\" problem.seed=\"0\""]},{"cell_type":"markdown","metadata":{"id":"Asx5hn5iNP3c"},"source":["## Test ExMAG"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iGxq-L6cNQCt"},"outputs":[],"source":["%%shell\n","\n","export PYTHONPATH=$PYTHONPATH:../\n","export  KMP_DUPLICATE_LIB_OK=TRUE\n","\n","CMD=\"python3 run_experiments.py --multirun --config-name=config-cluster\"\n","\n","vars=\"5, 10, 15, 20, 25\"\n","samples=\"20, 50, 100, 500, 1000\"\n","seed_range=10\n","\n","${CMD} experiment=\"EXMAG\" problem=\"bowfree_admg\" problem.number_of_variables=\"${vars}\" problem.number_of_samples=\"${samples}\" solver=\"exmag, milp\" problem.seed=\"range(0,${seed_range})\"\n","\n","python3 cluster_computing/extract_experiments_data.py EXMAG EXMAG.csv"]},{"cell_type":"markdown","metadata":{"id":"gBxhnNkNNjuH"},"source":["## Test Admission"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VyHAQ6UFNj5Y"},"outputs":[],"source":["%%shell\n","\n","# run in dagsolvers in directory\n","\n","export PYTHONPATH=$PYTHONPATH:../\n","\n","CMD=\"python3 run_experiments.py --multirun\" # --config-name=config-cluster\"\n","\n","\n","${CMD} experiment=\"EXMAG\" problem=\"admissions\" solver=\"exmag, milp\""]}],"metadata":{"colab":{"provenance":[{"file_id":"12ytOLOgNyrJyu4sGcn97mfW83w7prZ1P","timestamp":1746026989270},{"file_id":"1qM4Rtk3e6qLVuQvLZjKtyrygDvFINxPG","timestamp":1746026475965},{"file_id":"1ppojgk9tgXjnV7GQ5PGAXtH6iNviqa-7","timestamp":1740859698624}],"toc_visible":true,"authorship_tag":"ABX9TyNJUl+Sca2mhiwW0tuRfnPw"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}